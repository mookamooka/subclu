{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49f23116",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "Use this notebook to vectorize the text of combined Post + Comments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca0a23b",
   "metadata": {},
   "source": [
    "# Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da02639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05954694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\t\tv 3.7.10\n",
      "===\n",
      "numpy\t\tv: 1.18.5\n",
      "pandas\t\tv: 1.2.5\n",
      "subclu\t\tv: 0.6.0\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import subclu\n",
    "from subclu.utils.eda import (\n",
    "    setup_logging, counts_describe, value_counts_and_pcts,\n",
    "    notebook_display_config, print_lib_versions,\n",
    "    style_df_numeric\n",
    ")\n",
    "\n",
    "\n",
    "print_lib_versions([np, pd, subclu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e6c0593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:42:12 | INFO | \"loggging ready\"\n"
     ]
    }
   ],
   "source": [
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.dates as mdates\n",
    "plt.style.use('default')\n",
    "\n",
    "setup_logging()\n",
    "notebook_display_config()\n",
    "logging.info('loggging ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6905a7fa",
   "metadata": {},
   "source": [
    "# Auth note\n",
    "This notebook assumes you have authenticated using the gcloud CLI. Example</br>\n",
    "```bash\n",
    "gcloud auth application-default login\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e38888",
   "metadata": {},
   "source": [
    "# Load data AND Vectorize \n",
    "\n",
    "When we call the vectorizing function, it calls the data loader under the hood.\n",
    "See the configs in:\n",
    "- `subclu2/config`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47710e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/david.bermejo/repos/subreddit_clustering_i18n/\n",
      "subclu.i18n_topic_model_batch.subclu2.get_embeddings.vectorize_text_tf\n",
      "vectorize_post_and_comments_combined_seed_v0.6.0\n"
     ]
    }
   ],
   "source": [
    "path_djb_repo = '/home/david.bermejo/repos/subreddit_clustering_i18n/' \n",
    "path_djb_models = '/home/david.bermejo/repos/subreddit_clustering_i18n/subclu/models' \n",
    "file_vectorize_py = 'subclu.i18n_topic_model_batch.subclu2.get_embeddings.vectorize_text_tf'\n",
    "\n",
    "config_vectorize = 'vectorize_post_and_comments_combined_seed_v0.6.0'\n",
    "\n",
    "print(path_djb_repo)\n",
    "print(file_vectorize_py)\n",
    "print(config_vectorize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e998eae",
   "metadata": {},
   "source": [
    "## Run in bucket owned by i18n\n",
    "This bucket retains data longer than the gazette temp bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70354e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CFG keys:\n",
      "  dict_keys(['data_text_and_metadata', 'config_description', 'local_cache_path', 'local_model_path', 'output_bucket', 'gcs_path_text_key', 'data_loader_name', 'data_loader_kwargs', 'n_sample_files', 'n_files_slice_start', 'n_files_slice_end', 'process_individual_files', 'col_text_for_embeddings', 'model_name', 'batch_inference_rows', 'limit_first_n_chars', 'limit_first_n_chars_retry', 'get_embeddings_verbose', 'cols_index'])\n",
      "Data Loader kwags:\n",
      "  columns: ['subreddit_id', 'subreddit_name', 'post_id', 'post_and_comment_text_clean']\n",
      "  df_format: pandas\n",
      "  unique_check: False\n",
      "  verbose: True\n",
      "  bucket_name: i18n-subreddit-clustering\n",
      "  gcs_path: i18n_topic_model_batch/runs/20220811/post_and_comment_text_combined/text_all\n",
      "  local_cache_path: /home/jupyter/subreddit_clustering_i18n/data/local_cache/\n",
      "  n_sample_files: None\n",
      "  n_files_slice_start: None\n",
      "  n_files_slice_end: None\n",
      "`2022-08-11 08:42:18,382` | `INFO` | `Using hydra's path`\n",
      "`2022-08-11 08:42:18,382` | `INFO` | `  Log file created at: /home/jupyter/subreddit_clustering_i18n/hydra_runs/outputs/2022-08-11/08-42-18/logs/2022-08-11_08-42-18_vectorize_text.log`\n",
      "`2022-08-11 08:42:18,382` | `INFO` | `Start vectorize function`\n",
      "`2022-08-11 08:42:18,382` | `INFO` | `Loading model: use_multilingual_3`\n",
      "`2022-08-11 08:42:19,997` | `INFO` | `Using /tmp/tfhub_modules to cache modules.`\n",
      "`2022-08-11 08:42:24,405` | `INFO` | `Model loaded`\n",
      "`2022-08-11 08:42:24,405` | `INFO` | `  Loading & Processing each file independently`\n",
      "`2022-08-11 08:42:25,737` | `INFO` | `  Local folder to download artifact(s):\n",
      "  /home/jupyter/subreddit_clustering_i18n/data/local_cache/i18n-subreddit-clustering/i18n_topic_model_batch/runs/20220811/post_and_comment_text_combined/text_all`\n",
      "`2022-08-11 08:42:25,819` | `INFO` | `  193 <- Files matching prefix`\n",
      "`2022-08-11 08:42:25,820` | `INFO` | `  193 <- Files to check`\n",
      "`2022-08-11 08:45:59,441` | `INFO` | `  Files already cached: 0`\n",
      "`2022-08-11 08:45:59,441` | `INFO` | `0:03:35.035499  <- Downloading files elapsed time`\n",
      "`2022-08-11 08:45:59,443` | `INFO` | `  Files already downloaded.`\n",
      "`2022-08-11 08:46:00,204` | `INFO` | `  Processing: 000000000000.parquet`\n",
      "`2022-08-11 08:46:00,204` | `INFO` | `Vectorizing column: post_and_comment_text_clean`\n",
      "`2022-08-11 08:46:00,411` | `INFO` | `Getting embeddings in batches of size: 1350`\n",
      "`2022-08-11 08:46:12,905` | `INFO` | `  Vectorizing:   9%|##3                        | 17/196 [00:12<02:11,  1.36it/s]`\n",
      "`2022-08-11 08:46:25,360` | `INFO` | `  Vectorizing:  17%|####6                      | 34/196 [00:24<01:58,  1.36it/s]`\n",
      "`2022-08-11 08:46:37,765` | `INFO` | `  Vectorizing:  28%|#######4                   | 54/196 [00:37<01:36,  1.48it/s]`\n",
      "`2022-08-11 08:46:49,621` | `INFO` | `  Vectorizing:  28%|#######4                   | 54/196 [00:49<01:36,  1.48it/s]`\n",
      "`2022-08-11 08:46:50,493` | `INFO` | `  Vectorizing:  37%|##########                 | 73/196 [00:50<01:22,  1.48it/s]`\n",
      "`2022-08-11 08:47:02,953` | `INFO` | `  Vectorizing:  47%|############8              | 93/196 [01:02<01:07,  1.53it/s]`\n",
      "`2022-08-11 08:47:16,017` | `INFO` | `  Vectorizing:  58%|##############9           | 113/196 [01:15<00:54,  1.53it/s]`\n",
      "`2022-08-11 08:47:28,570` | `INFO` | `  Vectorizing:  67%|#################5        | 132/196 [01:28<00:42,  1.52it/s]`\n",
      "`2022-08-11 08:47:39,750` | `INFO` | `  Vectorizing:  67%|#################5        | 132/196 [01:39<00:42,  1.52it/s]`\n",
      "`2022-08-11 08:47:41,238` | `INFO` | `  Vectorizing:  81%|####################9     | 158/196 [01:40<00:22,  1.69it/s]`\n",
      "`2022-08-11 08:47:53,361` | `INFO` | `  Vectorizing:  93%|########################2 | 183/196 [01:52<00:07,  1.80it/s]`\n",
      "`2022-08-11 08:48:00,839` | `INFO` | `  Vectorizing: 100%|##########################| 196/196 [02:00<00:00,  1.63it/s]`\n",
      "\n",
      "`2022-08-11 08:48:01,928` | `INFO` | `Saving df_embeddings to: gcs://i18n-subreddit-clustering/i18n_topic_model_batch/runs/20220811/post_and_comment_text_combined/text_all/embedding/2022-08-11_084218/000000000000-264431_by_515.parquet`\n",
      "`2022-08-11 08:48:22,791` | `INFO` | `Files in batch:   1%|              | 1/193 [02:23<7:38:42, 143.35s/it]`\n",
      "`2022-08-11 08:48:23,669` | `INFO` | `  Processing: 000000000001.parquet`\n",
      "`2022-08-11 08:48:23,670` | `INFO` | `Vectorizing column: post_and_comment_text_clean`\n",
      "`2022-08-11 08:48:23,891` | `INFO` | `Getting embeddings in batches of size: 1350`\n",
      "`2022-08-11 08:48:36,241` | `INFO` | `  Vectorizing:  13%|###5                       | 24/185 [00:12<01:22,  1.94it/s]`\n",
      "`2022-08-11 08:48:49,981` | `INFO` | `  Vectorizing:  13%|###5                       | 24/185 [00:26<01:22,  1.94it/s]`\n",
      "`2022-08-11 08:48:51,278` | `INFO` | `  Vectorizing:  26%|#######                    | 48/185 [00:27<01:19,  1.72it/s]`\n",
      "`2022-08-11 08:49:08,746` | `INFO` | `  Vectorizing:  37%|#########9                 | 68/185 [00:44<01:22,  1.43it/s]`\n",
      "`2022-08-11 08:49:19,985` | `INFO` | `  Vectorizing:  37%|#########9                 | 68/185 [00:56<01:22,  1.43it/s]`\n",
      "`2022-08-11 08:49:21,488` | `INFO` | `  Vectorizing:  46%|############4              | 85/185 [00:57<01:11,  1.39it/s]`\n",
      "`2022-08-11 08:49:33,665` | `INFO` | `  Vectorizing:  56%|##############6           | 104/185 [01:09<00:55,  1.45it/s]`\n",
      "`2022-08-11 08:49:46,180` | `INFO` | `  Vectorizing:  67%|#################4        | 124/185 [01:22<00:40,  1.50it/s]`\n",
      "`2022-08-11 08:50:00,085` | `INFO` | `  Vectorizing:  67%|#################4        | 124/185 [01:36<00:40,  1.50it/s]`\n",
      "`2022-08-11 08:50:00,514` | `INFO` | `  Vectorizing:  77%|####################      | 143/185 [01:36<00:29,  1.44it/s]`\n",
      "`2022-08-11 08:50:13,194` | `INFO` | `  Vectorizing:  88%|######################9   | 163/185 [01:49<00:14,  1.48it/s]`\n",
      "`2022-08-11 08:50:26,073` | `INFO` | `  Vectorizing:  98%|#########################5| 182/185 [02:02<00:02,  1.48it/s]`\n",
      "`2022-08-11 08:50:28,885` | `INFO` | `  Vectorizing: 100%|##########################| 185/185 [02:04<00:00,  1.48it/s]`\n",
      "\n",
      "`2022-08-11 08:50:29,936` | `INFO` | `Saving df_embeddings to: gcs://i18n-subreddit-clustering/i18n_topic_model_batch/runs/20220811/post_and_comment_text_combined/text_all/embedding/2022-08-11_084218/000000000001-249532_by_515.parquet`\n",
      "`2022-08-11 08:50:50,792` | `INFO` | `Files in batch:   1%|1             | 2/193 [04:51<7:45:02, 146.09s/it]`\n",
      "`2022-08-11 08:50:51,691` | `INFO` | `  Processing: 000000000002.parquet`\n",
      "`2022-08-11 08:50:51,692` | `INFO` | `Vectorizing column: post_and_comment_text_clean`\n",
      "`2022-08-11 08:50:51,944` | `INFO` | `Getting embeddings in batches of size: 1350`\n",
      "`2022-08-11 08:51:04,392` | `INFO` | `  Vectorizing:   7%|#8                         | 16/229 [00:12<02:45,  1.29it/s]`\n",
      "`2022-08-11 08:51:16,536` | `INFO` | `  Vectorizing:  17%|####4                      | 38/229 [00:24<01:59,  1.59it/s]`\n",
      "`2022-08-11 08:51:29,273` | `INFO` | `  Vectorizing:  26%|#######                    | 60/229 [00:37<01:42,  1.65it/s]`\n",
      "`2022-08-11 08:51:40,247` | `INFO` | `  Vectorizing:  26%|#######                    | 60/229 [00:48<01:42,  1.65it/s]`\n",
      "`2022-08-11 08:51:42,119` | `INFO` | `  Vectorizing:  35%|#########4                 | 80/229 [00:50<01:32,  1.62it/s]`\n",
      "`2022-08-11 08:51:56,096` | `INFO` | `  Vectorizing:  43%|###########6               | 99/229 [01:04<01:25,  1.52it/s]`\n",
      "`2022-08-11 08:52:08,145` | `INFO` | `  Vectorizing:  53%|#############7            | 121/229 [01:16<01:06,  1.62it/s]`\n",
      "`2022-08-11 08:52:20,474` | `INFO` | `  Vectorizing:  53%|#############7            | 121/229 [01:28<01:06,  1.62it/s]`\n",
      "`2022-08-11 08:52:20,475` | `INFO` | `  Vectorizing:  63%|################4         | 145/229 [01:28<00:48,  1.72it/s]`\n",
      "`2022-08-11 08:52:30,475` | `INFO` | `  Vectorizing:  63%|################4         | 145/229 [01:38<00:48,  1.72it/s]`\n",
      "`2022-08-11 08:52:32,892` | `INFO` | `  Vectorizing:  75%|###################4      | 171/229 [01:40<00:31,  1.84it/s]`\n",
      "`2022-08-11 08:52:50,546` | `INFO` | `  Vectorizing:  75%|###################4      | 171/229 [01:58<00:31,  1.84it/s]`\n",
      "`2022-08-11 08:52:50,547` | `INFO` | `  Vectorizing:  85%|######################    | 194/229 [01:58<00:21,  1.63it/s]`\n",
      "`2022-08-11 08:53:00,547` | `INFO` | `  Vectorizing:  85%|######################    | 194/229 [02:08<00:21,  1.63it/s]`\n",
      "`2022-08-11 08:53:03,109` | `INFO` | `  Vectorizing:  92%|#######################9  | 211/229 [02:11<00:11,  1.55it/s]`\n",
      "`2022-08-11 08:53:12,903` | `INFO` | `  Vectorizing: 100%|##########################| 229/229 [02:20<00:00,  1.62it/s]`\n",
      "\n",
      "`2022-08-11 08:53:14,156` | `INFO` | `Saving df_embeddings to: gcs://i18n-subreddit-clustering/i18n_topic_model_batch/runs/20220811/post_and_comment_text_combined/text_all/embedding/2022-08-11_084218/000000000002-308094_by_515.parquet`\n",
      "`2022-08-11 08:53:40,154` | `INFO` | `Files in batch:   2%|2             | 3/193 [07:40<8:16:15, 156.71s/it]`\n",
      "`2022-08-11 08:53:41,040` | `INFO` | `  Processing: 000000000003.parquet`\n",
      "`2022-08-11 08:53:41,041` | `INFO` | `Vectorizing column: post_and_comment_text_clean`\n",
      "`2022-08-11 08:53:41,271` | `INFO` | `Getting embeddings in batches of size: 1350`\n",
      "`2022-08-11 08:53:53,595` | `INFO` | `  Vectorizing:   9%|##3                        | 21/246 [00:12<02:12,  1.70it/s]`\n",
      "`2022-08-11 08:54:10,973` | `INFO` | `  Vectorizing:   9%|##3                        | 21/246 [00:29<02:12,  1.70it/s]`\n",
      "`2022-08-11 08:54:11,229` | `INFO` | `  Vectorizing:  17%|####6                      | 42/246 [00:29<02:30,  1.36it/s]`\n",
      "`2022-08-11 08:54:24,392` | `INFO` | `  Vectorizing:  24%|######4                    | 59/246 [00:43<02:20,  1.33it/s]`\n",
      "`2022-08-11 08:54:36,735` | `INFO` | `  Vectorizing:  33%|########7                  | 80/246 [00:55<01:53,  1.46it/s]`\n",
      "`2022-08-11 08:54:49,729` | `INFO` | `  Vectorizing:  41%|##########6               | 101/246 [01:08<01:35,  1.52it/s]`\n",
      "`2022-08-11 08:55:01,017` | `INFO` | `  Vectorizing:  41%|##########6               | 101/246 [01:19<01:35,  1.52it/s]`\n",
      "`2022-08-11 08:55:02,067` | `INFO` | `  Vectorizing:  51%|#############2            | 125/246 [01:20<01:13,  1.66it/s]`\n",
      "`2022-08-11 08:55:14,528` | `INFO` | `  Vectorizing:  61%|###############7          | 149/246 [01:33<00:55,  1.74it/s]`\n",
      "`2022-08-11 08:55:28,366` | `INFO` | `  Vectorizing:  70%|##################2       | 173/246 [01:47<00:41,  1.74it/s]`\n",
      "`2022-08-11 08:55:41,074` | `INFO` | `  Vectorizing:  70%|##################2       | 173/246 [01:59<00:41,  1.74it/s]`\n",
      "`2022-08-11 08:55:41,353` | `INFO` | `  Vectorizing:  78%|####################2     | 192/246 [02:00<00:32,  1.65it/s]`\n",
      "`2022-08-11 08:55:53,675` | `INFO` | `  Vectorizing:  86%|######################3   | 211/246 [02:12<00:21,  1.62it/s]`\n",
      "`2022-08-11 08:56:06,396` | `INFO` | `  Vectorizing:  97%|#########################2| 239/246 [02:25<00:03,  1.80it/s]`\n",
      "`2022-08-11 08:56:09,620` | `INFO` | `  Vectorizing: 100%|##########################| 246/246 [02:28<00:00,  1.66it/s]`\n",
      "\n",
      "`2022-08-11 08:56:10,955` | `INFO` | `Saving df_embeddings to: gcs://i18n-subreddit-clustering/i18n_topic_model_batch/runs/20220811/post_and_comment_text_combined/text_all/embedding/2022-08-11_084218/000000000003-331082_by_515.parquet`\n",
      "`2022-08-11 08:56:34,201` | `INFO` | `Files in batch:   2%|2             | 4/193 [10:34<8:35:12, 163.56s/it]`\n",
      "`2022-08-11 08:56:34,982` | `INFO` | `  Processing: 000000000004.parquet`\n",
      "`2022-08-11 08:56:34,982` | `INFO` | `Vectorizing column: post_and_comment_text_clean`\n",
      "`2022-08-11 08:56:35,228` | `INFO` | `Getting embeddings in batches of size: 1350`\n",
      "`2022-08-11 08:56:47,351` | `INFO` | `  Vectorizing:   6%|#6                         | 16/265 [00:12<03:08,  1.32it/s]`\n",
      "`2022-08-11 08:56:59,411` | `INFO` | `  Vectorizing:  15%|###9                       | 39/265 [00:24<02:15,  1.66it/s]`\n",
      "`2022-08-11 08:57:11,247` | `INFO` | `  Vectorizing:  15%|###9                       | 39/265 [00:36<02:15,  1.66it/s]`\n",
      "`2022-08-11 08:57:11,452` | `INFO` | `  Vectorizing:  24%|######5                    | 64/265 [00:36<01:48,  1.85it/s]`\n",
      "`2022-08-11 08:57:26,815` | `INFO` | `  Vectorizing:  34%|#########                  | 89/265 [00:51<01:40,  1.75it/s]`\n",
      "`2022-08-11 08:57:39,244` | `INFO` | `  Vectorizing:  42%|##########8               | 111/265 [01:04<01:27,  1.76it/s]`\n",
      "`2022-08-11 08:57:51,301` | `INFO` | `  Vectorizing:  42%|##########8               | 111/265 [01:16<01:27,  1.76it/s]`\n",
      "`2022-08-11 08:57:51,431` | `INFO` | `  Vectorizing:  50%|#############             | 133/265 [01:16<01:14,  1.77it/s]`\n",
      "`2022-08-11 08:58:05,334` | `INFO` | `  Vectorizing:  58%|###############2          | 155/265 [01:30<01:04,  1.71it/s]`\n",
      "`2022-08-11 08:58:17,552` | `INFO` | `  Vectorizing:  68%|#################5        | 179/265 [01:42<00:48,  1.78it/s]`\n",
      "`2022-08-11 08:58:31,302` | `INFO` | `  Vectorizing:  68%|#################5        | 179/265 [01:56<00:48,  1.78it/s]`\n",
      "`2022-08-11 08:58:31,599` | `INFO` | `  Vectorizing:  77%|###################9      | 203/265 [01:56<00:35,  1.76it/s]`\n",
      "`2022-08-11 08:58:47,908` | `INFO` | `  Vectorizing:  85%|#####################9    | 224/265 [02:12<00:25,  1.59it/s]`\n",
      "2022-08-11 08:58:58.512746: W tensorflow/core/common_runtime/bfc_allocator.cc:431] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.69GiB (rounded to 2892672000)requested by op StatefulPartitionedCall/StatefulPartitionedCall/EncoderDNN/CNN_layers/ngram_order_5/Ngram-5-Conv/concat_2\n",
      "Current allocation summary follows.\n",
      "2022-08-11 08:58:58.513455: W tensorflow/core/common_runtime/bfc_allocator.cc:439] ***********************_______*****______*****___*********************************__________________\n",
      "2022-08-11 08:58:58.513537: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at concat_op.cc:161 : Resource exhausted: OOM when allocating tensor with shape[564975,1280] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "`2022-08-11 08:58:58,515` | `WARNING` | `\n",
      "ResourceExhausted, lowering character limit\n",
      " OOM when allocating tensor with shape[564975,1280] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node StatefulPartitionedCall/StatefulPartitionedCall/EncoderDNN/CNN_layers/ngram_order_5/Ngram-5-Conv/concat_2}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      " [Op:__inference_restored_function_body_15375]\n",
      "\n",
      "Function call stack:\n",
      "restored_function_body\n",
      "\n",
      "`\n",
      "`2022-08-11 08:59:01,381` | `INFO` | `  Vectorizing:  85%|#####################9    | 224/265 [02:26<00:25,  1.59it/s]`\n",
      "2022-08-11 08:59:10.082824: W tensorflow/core/common_runtime/bfc_allocator.cc:431] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.75GiB (rounded to 2948172800)requested by op StatefulPartitionedCall/StatefulPartitionedCall/EncoderDNN/CNN_layers/ngram_order_5/Ngram-5-Conv/concat_2\n",
      "Current allocation summary follows.\n",
      "2022-08-11 08:59:10.083404: W tensorflow/core/common_runtime/bfc_allocator.cc:439] ***********************_______*****_______*****___*********************************_________________\n",
      "2022-08-11 08:59:10.083445: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at concat_op.cc:161 : Resource exhausted: OOM when allocating tensor with shape[575815,1280] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "`2022-08-11 08:59:10,084` | `WARNING` | `\n",
      "ResourceExhausted, lowering character limit\n",
      " OOM when allocating tensor with shape[575815,1280] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node StatefulPartitionedCall/StatefulPartitionedCall/EncoderDNN/CNN_layers/ngram_order_5/Ngram-5-Conv/concat_2}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      " [Op:__inference_restored_function_body_15375]\n",
      "\n",
      "Function call stack:\n",
      "restored_function_body\n",
      "\n",
      "`\n",
      "`2022-08-11 08:59:11,471` | `INFO` | `  Vectorizing:  86%|######################2   | 227/265 [02:36<00:39,  1.03s/it]`\n",
      "`2022-08-11 08:59:21,471` | `INFO` | `  Vectorizing:  86%|######################2   | 227/265 [02:46<00:39,  1.03s/it]`\n",
      "2022-08-11 08:59:21.681056: W tensorflow/core/common_runtime/bfc_allocator.cc:431] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.68GiB (rounded to 2878807040)requested by op StatefulPartitionedCall/StatefulPartitionedCall/EncoderDNN/CNN_layers/ngram_order_5/Ngram-5-Conv/concat_2\n",
      "Current allocation summary follows.\n",
      "2022-08-11 08:59:21.681727: W tensorflow/core/common_runtime/bfc_allocator.cc:439] ***********************______*****_______*****___********************************___________________\n",
      "2022-08-11 08:59:21.681769: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at concat_op.cc:161 : Resource exhausted: OOM when allocating tensor with shape[562267,1280] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "`2022-08-11 08:59:21,683` | `WARNING` | `\n",
      "ResourceExhausted, lowering character limit\n",
      " OOM when allocating tensor with shape[562267,1280] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node StatefulPartitionedCall/StatefulPartitionedCall/EncoderDNN/CNN_layers/ngram_order_5/Ngram-5-Conv/concat_2}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      " [Op:__inference_restored_function_body_15375]\n",
      "\n",
      "Function call stack:\n",
      "restored_function_body\n",
      "\n",
      "`\n",
      "`2022-08-11 08:59:23,717` | `INFO` | `  Vectorizing:  86%|######################4   | 229/265 [02:48<00:46,  1.28s/it]`\n",
      "`2022-08-11 08:59:36,200` | `INFO` | `  Vectorizing:  96%|########################9 | 254/265 [03:00<00:10,  1.09it/s]`\n",
      "`2022-08-11 08:59:42,216` | `INFO` | `  Vectorizing: 100%|##########################| 265/265 [03:06<00:00,  1.42it/s]`\n",
      "\n",
      "`2022-08-11 08:59:43,664` | `INFO` | `Saving df_embeddings to: gcs://i18n-subreddit-clustering/i18n_topic_model_batch/runs/20220811/post_and_comment_text_combined/text_all/embedding/2022-08-11_084218/000000000004-356401_by_515.parquet`\n",
      "`2022-08-11 09:00:08,380` | `INFO` | `Files in batch:   3%|3             | 5/193 [14:08<9:29:40, 181.81s/it]`\n",
      "`2022-08-11 09:00:09,096` | `INFO` | `  Processing: 000000000005.parquet`\n",
      "`2022-08-11 09:00:09,097` | `INFO` | `Vectorizing column: post_and_comment_text_clean`\n",
      "`2022-08-11 09:00:09,327` | `INFO` | `Getting embeddings in batches of size: 1350`\n",
      "`2022-08-11 09:00:21,893` | `INFO` | `  Vectorizing:   7%|#8                         | 17/246 [00:12<02:49,  1.35it/s]`\n",
      "`2022-08-11 09:00:34,292` | `INFO` | `  Vectorizing:  16%|####3                      | 40/246 [00:24<02:05,  1.65it/s]`\n",
      "`2022-08-11 09:00:48,433` | `INFO` | `  Vectorizing:  26%|######9                    | 63/246 [00:39<01:51,  1.64it/s]`\n",
      "`2022-08-11 09:01:00,486` | `INFO` | `  Vectorizing:  35%|#########3                 | 85/246 [00:51<01:34,  1.71it/s]`\n",
      "`2022-08-11 09:01:11,729` | `INFO` | `  Vectorizing:  35%|#########3                 | 85/246 [01:02<01:34,  1.71it/s]`\n",
      "`2022-08-11 09:01:12,900` | `INFO` | `  Vectorizing:  43%|###########               | 105/246 [01:03<01:24,  1.67it/s]`\n",
      "`2022-08-11 09:01:27,085` | `INFO` | `  Vectorizing:  51%|#############2            | 125/246 [01:17<01:16,  1.58it/s]`\n",
      "`2022-08-11 09:01:39,511` | `INFO` | `  Vectorizing:  60%|###############5          | 147/246 [01:30<01:00,  1.64it/s]`\n",
      "`2022-08-11 09:01:51,865` | `INFO` | `  Vectorizing:  60%|###############5          | 147/246 [01:42<01:00,  1.64it/s]`\n",
      "`2022-08-11 09:01:52,211` | `INFO` | `  Vectorizing:  65%|################9         | 160/246 [01:42<00:59,  1.44it/s]`\n",
      "`2022-08-11 09:02:04,211` | `INFO` | `  Vectorizing:  76%|###################6      | 186/246 [01:54<00:36,  1.66it/s]`\n",
      "`2022-08-11 09:02:17,883` | `INFO` | `  Vectorizing:  86%|######################4   | 212/246 [02:08<00:19,  1.74it/s]`\n",
      "`2022-08-11 09:02:30,612` | `INFO` | `  Vectorizing:  96%|########################8 | 235/246 [02:21<00:06,  1.76it/s]`\n",
      "`2022-08-11 09:02:38,860` | `INFO` | `  Vectorizing: 100%|##########################| 246/246 [02:29<00:00,  1.65it/s]`\n",
      "\n",
      "`2022-08-11 09:02:40,196` | `INFO` | `Saving df_embeddings to: gcs://i18n-subreddit-clustering/i18n_topic_model_batch/runs/20220811/post_and_comment_text_combined/text_all/embedding/2022-08-11_084218/000000000005-331679_by_515.parquet`\n",
      "`2022-08-11 09:03:06,493` | `INFO` | `Files in batch:   3%|4             | 6/193 [17:07<9:22:43, 180.55s/it]`\n",
      "`2022-08-11 09:03:07,053` | `INFO` | `  Processing: 000000000006.parquet`\n",
      "`2022-08-11 09:03:07,055` | `INFO` | `Vectorizing column: post_and_comment_text_clean`\n",
      "`2022-08-11 09:03:07,260` | `INFO` | `Getting embeddings in batches of size: 1350`\n",
      "`2022-08-11 09:03:20,004` | `INFO` | `  Vectorizing:   7%|##                         | 14/189 [00:12<02:39,  1.10it/s]`\n",
      "`2022-08-11 09:03:31,912` | `INFO` | `  Vectorizing:   7%|##                         | 14/189 [00:24<02:39,  1.10it/s]`\n",
      "`2022-08-11 09:03:32,225` | `INFO` | `  Vectorizing:  20%|#####2                     | 37/189 [00:24<01:37,  1.55it/s]`\n",
      "`2022-08-11 09:03:44,768` | `INFO` | `  Vectorizing:  32%|########7                  | 61/189 [00:37<01:14,  1.72it/s]`\n",
      "`2022-08-11 09:04:02,030` | `INFO` | `  Vectorizing:  32%|########7                  | 61/189 [00:54<01:14,  1.72it/s]`\n",
      "`2022-08-11 09:04:02,030` | `INFO` | `  Vectorizing:  44%|############               | 84/189 [00:54<01:08,  1.53it/s]`\n",
      "`2022-08-11 09:04:12,086` | `INFO` | `  Vectorizing:  44%|############               | 84/189 [01:04<01:08,  1.53it/s]`\n",
      "`2022-08-11 09:04:14,069` | `INFO` | `  Vectorizing:  56%|##############5           | 106/189 [01:06<00:50,  1.63it/s]`\n",
      "`2022-08-11 09:04:26,070` | `INFO` | `  Vectorizing:  68%|#################7        | 129/189 [01:18<00:34,  1.72it/s]`\n",
      "`2022-08-11 09:04:42,197` | `INFO` | `  Vectorizing:  68%|#################7        | 129/189 [01:34<00:34,  1.72it/s]`\n",
      "`2022-08-11 09:04:42,459` | `INFO` | `  Vectorizing:  80%|####################7     | 151/189 [01:35<00:24,  1.58it/s]`\n",
      "`2022-08-11 09:04:54,531` | `INFO` | `  Vectorizing:  90%|#######################5  | 171/189 [01:47<00:11,  1.60it/s]`\n",
      "`2022-08-11 09:05:04,346` | `INFO` | `  Vectorizing: 100%|##########################| 189/189 [01:57<00:00,  1.61it/s]`\n",
      "\n",
      "`2022-08-11 09:05:05,407` | `INFO` | `Saving df_embeddings to: gcs://i18n-subreddit-clustering/i18n_topic_model_batch/runs/20220811/post_and_comment_text_combined/text_all/embedding/2022-08-11_084218/000000000006-253861_by_515.parquet`\n",
      "`2022-08-11 09:05:28,547` | `INFO` | `Files in batch:   4%|5             | 7/193 [19:29<8:40:41, 167.97s/it]`\n",
      "`2022-08-11 09:05:29,307` | `INFO` | `  Processing: 000000000007.parquet`\n",
      "`2022-08-11 09:05:29,308` | `INFO` | `Vectorizing column: post_and_comment_text_clean`\n",
      "`2022-08-11 09:05:29,530` | `INFO` | `Getting embeddings in batches of size: 1350`\n",
      "`2022-08-11 09:05:41,965` | `INFO` | `  Vectorizing:   6%|#5                         | 16/271 [00:12<03:18,  1.29it/s]`\n",
      "`2022-08-11 09:05:52,201` | `INFO` | `  Vectorizing:   6%|#5                         | 16/271 [00:22<03:18,  1.29it/s]`\n",
      "`2022-08-11 09:05:54,138` | `INFO` | `  Vectorizing:  13%|###3                       | 34/271 [00:24<02:49,  1.40it/s]`\n",
      "`2022-08-11 09:06:06,728` | `INFO` | `  Vectorizing:  22%|#####8                     | 59/271 [00:37<02:06,  1.67it/s]`\n",
      "`2022-08-11 09:06:21,536` | `INFO` | `  Vectorizing:  31%|########2                  | 83/271 [00:52<01:54,  1.65it/s]`\n",
      "`2022-08-11 09:06:32,251` | `INFO` | `  Vectorizing:  31%|########2                  | 83/271 [01:02<01:54,  1.65it/s]`\n",
      "`2022-08-11 09:06:33,537` | `INFO` | `  Vectorizing:  40%|##########4               | 109/271 [01:04<01:28,  1.82it/s]`\n",
      "`2022-08-11 09:06:47,363` | `INFO` | `  Vectorizing:  50%|############9             | 135/271 [01:17<01:13,  1.84it/s]`\n",
      "`2022-08-11 09:06:59,454` | `INFO` | `  Vectorizing:  58%|###############1          | 158/271 [01:29<01:00,  1.86it/s]`\n",
      "`2022-08-11 09:07:12,327` | `INFO` | `  Vectorizing:  58%|###############1          | 158/271 [01:42<01:00,  1.86it/s]`\n",
      "`2022-08-11 09:07:12,581` | `INFO` | `  Vectorizing:  66%|#################1        | 179/271 [01:43<00:51,  1.78it/s]`\n",
      "`2022-08-11 09:07:30,969` | `INFO` | `  Vectorizing:  73%|###################       | 199/271 [02:01<00:47,  1.51it/s]`\n",
      "`2022-08-11 09:07:42,426` | `INFO` | `  Vectorizing:  73%|###################       | 199/271 [02:12<00:47,  1.51it/s]`\n",
      "`2022-08-11 09:07:43,312` | `INFO` | `  Vectorizing:  82%|#####################2    | 221/271 [02:13<00:31,  1.58it/s]`\n",
      "`2022-08-11 09:07:55,615` | `INFO` | `  Vectorizing:  90%|#######################4  | 244/271 [02:26<00:16,  1.66it/s]`\n",
      "`2022-08-11 09:08:07,749` | `INFO` | `  Vectorizing:  99%|#########################7| 268/271 [02:38<00:01,  1.75it/s]`\n",
      "`2022-08-11 09:08:09,953` | `INFO` | `  Vectorizing: 100%|##########################| 271/271 [02:40<00:00,  1.69it/s]`\n",
      "\n",
      "`2022-08-11 09:08:11,470` | `INFO` | `Saving df_embeddings to: gcs://i18n-subreddit-clustering/i18n_topic_model_batch/runs/20220811/post_and_comment_text_combined/text_all/embedding/2022-08-11_084218/000000000007-365498_by_515.parquet`\n",
      "`2022-08-11 09:08:36,430` | `INFO` | `Files in batch:   4%|5             | 8/193 [22:36<8:57:26, 174.31s/it]`\n",
      "`2022-08-11 09:08:37,184` | `INFO` | `  Processing: 000000000008.parquet`\n",
      "`2022-08-11 09:08:37,185` | `INFO` | `Vectorizing column: post_and_comment_text_clean`\n",
      "`2022-08-11 09:08:37,400` | `INFO` | `Getting embeddings in batches of size: 1350`\n",
      "`2022-08-11 09:08:49,774` | `INFO` | `  Vectorizing:   9%|##5                        | 19/202 [00:12<01:59,  1.54it/s]`\n",
      "`2022-08-11 09:09:02,470` | `INFO` | `  Vectorizing:   9%|##5                        | 19/202 [00:25<01:59,  1.54it/s]`\n",
      "`2022-08-11 09:09:02,471` | `INFO` | `  Vectorizing:  17%|####6                      | 35/202 [00:25<02:01,  1.37it/s]`\n",
      "`2022-08-11 09:09:12,471` | `INFO` | `  Vectorizing:  17%|####6                      | 35/202 [00:35<02:01,  1.37it/s]`\n",
      "`2022-08-11 09:09:14,804` | `INFO` | `  Vectorizing:  30%|########                   | 60/202 [00:37<01:25,  1.67it/s]`\n",
      "`2022-08-11 09:09:28,500` | `INFO` | `  Vectorizing:  42%|###########3               | 85/202 [00:51<01:07,  1.73it/s]`\n",
      "`2022-08-11 09:09:41,038` | `INFO` | `  Vectorizing:  53%|#############7            | 107/202 [01:03<00:54,  1.74it/s]`\n",
      "`2022-08-11 09:09:52,610` | `INFO` | `  Vectorizing:  53%|#############7            | 107/202 [01:15<00:54,  1.74it/s]`\n",
      "`2022-08-11 09:09:53,688` | `INFO` | `  Vectorizing:  61%|###############8          | 123/202 [01:16<00:49,  1.58it/s]`\n",
      "`2022-08-11 09:10:05,939` | `INFO` | `  Vectorizing:  75%|###################4      | 151/202 [01:28<00:28,  1.80it/s]`\n",
      "`2022-08-11 09:10:21,764` | `INFO` | `  Vectorizing:  89%|#######################   | 179/202 [01:44<00:12,  1.79it/s]`\n",
      "`2022-08-11 09:10:32,709` | `INFO` | `  Vectorizing:  89%|#######################   | 179/202 [01:55<00:12,  1.79it/s]`\n",
      "`2022-08-11 09:10:33,855` | `INFO` | `  Vectorizing:  97%|######################### | 195/202 [01:56<00:04,  1.66it/s]`\n",
      "`2022-08-11 09:10:37,905` | `INFO` | `  Vectorizing: 100%|##########################| 202/202 [02:00<00:00,  1.68it/s]`\n",
      "\n",
      "`2022-08-11 09:10:39,001` | `INFO` | `Saving df_embeddings to: gcs://i18n-subreddit-clustering/i18n_topic_model_batch/runs/20220811/post_and_comment_text_combined/text_all/embedding/2022-08-11_084218/000000000008-271629_by_515.parquet`\n",
      "`2022-08-11 09:11:00,943` | `INFO` | `Files in batch:   5%|6             | 9/193 [25:01<8:25:58, 164.99s/it]`\n",
      "`2022-08-11 09:11:01,678` | `INFO` | `  Processing: 000000000009.parquet`\n",
      "`2022-08-11 09:11:01,679` | `INFO` | `Vectorizing column: post_and_comment_text_clean`\n",
      "`2022-08-11 09:11:01,937` | `INFO` | `Getting embeddings in batches of size: 1350`\n",
      "`2022-08-11 09:11:13,956` | `INFO` | `  Vectorizing:   9%|##4                        | 24/264 [00:12<02:00,  2.00it/s]`\n",
      "`2022-08-11 09:11:26,059` | `INFO` | `  Vectorizing:  19%|#####1                     | 50/264 [00:24<01:42,  2.09it/s]`\n",
      "`2022-08-11 09:11:39,382` | `INFO` | `  Vectorizing:  29%|#######7                   | 76/264 [00:37<01:33,  2.02it/s]`\n",
      "`2022-08-11 09:11:52,881` | `INFO` | `  Vectorizing:  29%|#######7                   | 76/264 [00:50<01:33,  2.02it/s]`\n",
      "`2022-08-11 09:11:53,101` | `INFO` | `  Vectorizing:  38%|##########1                | 99/264 [00:51<01:27,  1.88it/s]`\n",
      "`2022-08-11 09:12:05,690` | `INFO` | `  Vectorizing:  45%|###########8              | 120/264 [01:03<01:19,  1.80it/s]`\n",
      "`2022-08-11 09:12:18,101` | `INFO` | `  Vectorizing:  54%|##############            | 143/264 [01:16<01:06,  1.82it/s]`\n",
      "`2022-08-11 09:12:30,420` | `INFO` | `  Vectorizing:  63%|################4         | 167/264 [01:28<00:52,  1.86it/s]`\n",
      "`2022-08-11 09:12:42,972` | `INFO` | `  Vectorizing:  63%|################4         | 167/264 [01:41<00:52,  1.86it/s]`\n",
      "`2022-08-11 09:12:43,564` | `INFO` | `  Vectorizing:  72%|##################8       | 191/264 [01:41<00:39,  1.85it/s]`\n",
      "`2022-08-11 09:12:55,805` | `INFO` | `  Vectorizing:  81%|####################9     | 213/264 [01:53<00:27,  1.83it/s]`\n",
      "`2022-08-11 09:13:07,955` | `INFO` | `  Vectorizing:  89%|#######################2  | 236/264 [02:06<00:15,  1.85it/s]`\n",
      "`2022-08-11 09:13:20,573` | `INFO` | `  Vectorizing:  98%|#########################6| 260/264 [02:18<00:02,  1.87it/s]`\n",
      "`2022-08-11 09:13:22,467` | `INFO` | `  Vectorizing: 100%|##########################| 264/264 [02:20<00:00,  1.88it/s]`\n",
      "\n",
      "`2022-08-11 09:13:23,968` | `INFO` | `Saving df_embeddings to: gcs://i18n-subreddit-clustering/i18n_topic_model_batch/runs/20220811/post_and_comment_text_combined/text_all/embedding/2022-08-11_084218/000000000009-355342_by_515.parquet`\n",
      "`2022-08-11 09:13:47,672` | `INFO` | `Files in batch:   5%|6            | 10/193 [27:48<8:24:51, 165.53s/it]`\n",
      "`2022-08-11 09:13:48,467` | `INFO` | `  Processing: 000000000010.parquet`\n",
      "`2022-08-11 09:13:48,468` | `INFO` | `Vectorizing column: post_and_comment_text_clean`\n",
      "`2022-08-11 09:13:48,688` | `INFO` | `Getting embeddings in batches of size: 1350`\n",
      "`2022-08-11 09:14:00,718` | `INFO` | `  Vectorizing:  11%|##8                        | 28/265 [00:12<01:41,  2.33it/s]`\n",
      "`2022-08-11 09:14:13,156` | `INFO` | `  Vectorizing:  11%|##8                        | 28/265 [00:24<01:41,  2.33it/s]`\n",
      "`2022-08-11 09:14:13,485` | `INFO` | `  Vectorizing:  20%|#####4                     | 53/265 [00:24<01:40,  2.10it/s]`\n",
      "`2022-08-11 09:14:32,015` | `INFO` | `  Vectorizing:  29%|#######8                   | 77/265 [00:43<01:53,  1.66it/s]`\n",
      "`2022-08-11 09:14:43,294` | `INFO` | `  Vectorizing:  29%|#######8                   | 77/265 [00:54<01:53,  1.66it/s]`\n",
      "`2022-08-11 09:14:44,330` | `INFO` | `  Vectorizing:  36%|#########7                 | 96/265 [00:55<01:44,  1.62it/s]`\n",
      "`2022-08-11 09:14:56,778` | `INFO` | `  Vectorizing:  46%|###########8              | 121/265 [01:08<01:22,  1.75it/s]`\n",
      "`2022-08-11 09:15:11,904` | `INFO` | `  Vectorizing:  55%|##############3           | 146/265 [01:23<01:09,  1.71it/s]`\n",
      "`2022-08-11 09:15:23,466` | `INFO` | `  Vectorizing:  55%|##############3           | 146/265 [01:34<01:09,  1.71it/s]`\n",
      "`2022-08-11 09:15:24,262` | `INFO` | `  Vectorizing:  64%|################5         | 169/265 [01:35<00:54,  1.76it/s]`\n",
      "`2022-08-11 09:15:36,829` | `INFO` | `  Vectorizing:  72%|##################8       | 192/265 [01:48<00:41,  1.78it/s]`\n",
      "`2022-08-11 09:15:49,104` | `INFO` | `  Vectorizing:  81%|####################9     | 214/265 [02:00<00:28,  1.78it/s]`\n",
      "`2022-08-11 09:16:01,573` | `INFO` | `  Vectorizing:  90%|#######################3  | 238/265 [02:12<00:14,  1.83it/s]`\n",
      "`2022-08-11 09:16:13,586` | `INFO` | `  Vectorizing:  90%|#######################3  | 238/265 [02:24<00:14,  1.83it/s]`\n",
      "`2022-08-11 09:16:13,731` | `INFO` | `  Vectorizing:  99%|#########################7| 262/265 [02:25<00:01,  1.87it/s]`\n",
      "`2022-08-11 09:16:14,775` | `INFO` | `  Vectorizing: 100%|##########################| 265/265 [02:26<00:00,  1.81it/s]`\n",
      "\n",
      "`2022-08-11 09:16:16,252` | `INFO` | `Saving df_embeddings to: gcs://i18n-subreddit-clustering/i18n_topic_model_batch/runs/20220811/post_and_comment_text_combined/text_all/embedding/2022-08-11_084218/000000000010-356760_by_515.parquet`\n",
      "`2022-08-11 09:16:40,313` | `INFO` | `Files in batch:   6%|7            | 11/193 [30:40<8:28:42, 167.71s/it]`\n",
      "`2022-08-11 09:16:41,024` | `INFO` | `  Processing: 000000000011.parquet`\n",
      "`2022-08-11 09:16:41,025` | `INFO` | `Vectorizing column: post_and_comment_text_clean`\n",
      "`2022-08-11 09:16:41,275` | `INFO` | `Getting embeddings in batches of size: 1350`\n",
      "`2022-08-11 09:16:53,342` | `INFO` | `  Vectorizing:  10%|##6                        | 27/275 [00:12<01:50,  2.24it/s]`\n",
      "`2022-08-11 09:17:03,605` | `INFO` | `  Vectorizing:  10%|##6                        | 27/275 [00:22<01:50,  2.24it/s]`\n",
      "`2022-08-11 09:17:05,465` | `INFO` | `  Vectorizing:  19%|#####2                     | 53/275 [00:24<01:41,  2.18it/s]`\n",
      "`2022-08-11 09:17:17,839` | `INFO` | `  Vectorizing:  29%|#######7                   | 79/275 [00:36<01:31,  2.15it/s]`\n",
      "`2022-08-11 09:17:31,783` | `INFO` | `  Vectorizing:  38%|#########9                | 105/275 [00:50<01:23,  2.03it/s]`\n",
      "`2022-08-11 09:17:43,814` | `INFO` | `  Vectorizing:  38%|#########9                | 105/275 [01:02<01:23,  2.03it/s]`\n",
      "`2022-08-11 09:17:44,214` | `INFO` | `  Vectorizing:  46%|###########9              | 126/275 [01:02<01:18,  1.91it/s]`\n",
      "`2022-08-11 09:17:56,245` | `INFO` | `  Vectorizing:  55%|##############1           | 150/275 [01:14<01:04,  1.94it/s]`\n",
      "`2022-08-11 09:18:08,475` | `INFO` | `  Vectorizing:  63%|################4         | 174/275 [01:27<00:51,  1.94it/s]`\n",
      "`2022-08-11 09:18:22,121` | `INFO` | `  Vectorizing:  72%|##################7       | 198/275 [01:40<00:40,  1.88it/s]`\n",
      "`2022-08-11 09:18:34,013` | `INFO` | `  Vectorizing:  72%|##################7       | 198/275 [01:52<00:40,  1.88it/s]`\n",
      "`2022-08-11 09:18:34,731` | `INFO` | `  Vectorizing:  80%|####################8     | 220/275 [01:53<00:29,  1.84it/s]`\n",
      "`2022-08-11 09:18:46,963` | `INFO` | `  Vectorizing:  88%|######################7   | 241/275 [02:05<00:18,  1.80it/s]`\n",
      "`2022-08-11 09:18:59,160` | `INFO` | `  Vectorizing:  97%|#########################1| 266/275 [02:17<00:04,  1.88it/s]`\n",
      "`2022-08-11 09:19:03,358` | `INFO` | `  Vectorizing: 100%|##########################| 275/275 [02:22<00:00,  1.94it/s]`\n",
      "\n",
      "`2022-08-11 09:19:04,877` | `INFO` | `Saving df_embeddings to: gcs://i18n-subreddit-clustering/i18n_topic_model_batch/runs/20220811/post_and_comment_text_combined/text_all/embedding/2022-08-11_084218/000000000011-370490_by_515.parquet`\n",
      "`2022-08-11 09:19:28,945` | `INFO` | `Files in batch:   6%|8            | 12/193 [33:29<8:26:45, 167.99s/it]`\n",
      "`2022-08-11 09:19:29,693` | `INFO` | `  Processing: 000000000012.parquet`\n",
      "`2022-08-11 09:19:29,694` | `INFO` | `Vectorizing column: post_and_comment_text_clean`\n",
      "`2022-08-11 09:19:29,916` | `INFO` | `Getting embeddings in batches of size: 1350`\n",
      "`2022-08-11 09:19:42,258` | `INFO` | `  Vectorizing:   6%|#5                         | 15/265 [00:12<03:25,  1.22it/s]`\n",
      "`2022-08-11 09:19:54,143` | `INFO` | `  Vectorizing:   6%|#5                         | 15/265 [00:24<03:25,  1.22it/s]`\n",
      "`2022-08-11 09:19:55,138` | `INFO` | `  Vectorizing:  17%|####4                      | 44/265 [00:25<02:00,  1.84it/s]`\n",
      "`2022-08-11 09:20:10,718` | `INFO` | `  Vectorizing:  27%|#######3                   | 72/265 [00:40<01:46,  1.82it/s]`\n",
      "`2022-08-11 09:20:22,885` | `INFO` | `  Vectorizing:  37%|##########                 | 99/265 [00:52<01:24,  1.96it/s]`\n",
      "`2022-08-11 09:20:34,221` | `INFO` | `  Vectorizing:  37%|##########                 | 99/265 [01:04<01:24,  1.96it/s]`\n",
      "`2022-08-11 09:20:35,176` | `INFO` | `  Vectorizing:  47%|############1             | 124/265 [01:05<01:10,  1.99it/s]`\n",
      "`2022-08-11 09:20:50,240` | `INFO` | `  Vectorizing:  56%|##############6           | 149/265 [01:20<01:02,  1.86it/s]`\n",
      "`2022-08-11 09:21:02,578` | `INFO` | `  Vectorizing:  64%|################5         | 169/265 [01:32<00:53,  1.79it/s]`\n",
      "`2022-08-11 09:21:14,251` | `INFO` | `  Vectorizing:  64%|################5         | 169/265 [01:44<00:53,  1.79it/s]`\n",
      "`2022-08-11 09:21:14,831` | `INFO` | `  Vectorizing:  72%|##################7       | 191/265 [01:44<00:41,  1.79it/s]`\n",
      "`2022-08-11 09:21:26,909` | `INFO` | `  Vectorizing:  81%|#####################     | 215/265 [01:56<00:27,  1.85it/s]`\n",
      "`2022-08-11 09:21:44,430` | `INFO` | `  Vectorizing:  81%|#####################     | 215/265 [02:14<00:27,  1.85it/s]`\n",
      "`2022-08-11 09:21:44,595` | `INFO` | `  Vectorizing:  89%|#######################2  | 237/265 [02:14<00:17,  1.62it/s]`\n",
      "`2022-08-11 09:21:58,818` | `INFO` | `  Vectorizing:  95%|########################7 | 252/265 [02:28<00:08,  1.44it/s]`\n",
      "`2022-08-11 09:22:07,500` | `INFO` | `  Vectorizing: 100%|##########################| 265/265 [02:37<00:00,  1.68it/s]`\n",
      "\n",
      "`2022-08-11 09:22:08,963` | `INFO` | `Saving df_embeddings to: gcs://i18n-subreddit-clustering/i18n_topic_model_batch/runs/20220811/post_and_comment_text_combined/text_all/embedding/2022-08-11_084218/000000000012-357532_by_515.parquet`\n",
      "`2022-08-11 09:22:34,605` | `INFO` | `Files in batch:   7%|8            | 13/193 [36:35<8:40:01, 173.34s/it]`\n",
      "`2022-08-11 09:22:35,135` | `INFO` | `  Processing: 000000000013.parquet`\n",
      "`2022-08-11 09:22:35,136` | `INFO` | `Vectorizing column: post_and_comment_text_clean`\n",
      "`2022-08-11 09:22:35,356` | `INFO` | `Getting embeddings in batches of size: 1350`\n",
      "`2022-08-11 09:22:47,414` | `INFO` | `  Vectorizing:  14%|###9                       | 25/173 [00:12<01:11,  2.07it/s]`\n",
      "`2022-08-11 09:23:00,981` | `INFO` | `  Vectorizing:  29%|#######8                   | 50/173 [00:25<01:03,  1.93it/s]`\n",
      "`2022-08-11 09:23:13,731` | `INFO` | `  Vectorizing:  42%|###########3               | 73/173 [00:38<00:53,  1.87it/s]`\n",
      "`2022-08-11 09:23:24,536` | `INFO` | `  Vectorizing:  42%|###########3               | 73/173 [00:49<00:53,  1.87it/s]`\n",
      "`2022-08-11 09:23:25,968` | `INFO` | `  Vectorizing:  55%|##############9            | 96/173 [00:50<00:41,  1.88it/s]`\n",
      "`2022-08-11 09:23:41,919` | `INFO` | `  Vectorizing:  69%|#################8        | 119/173 [01:06<00:31,  1.70it/s]`\n",
      "`2022-08-11 09:23:54,668` | `INFO` | `  Vectorizing:  69%|#################8        | 119/173 [01:19<00:31,  1.70it/s]`\n",
      "`2022-08-11 09:23:54,669` | `INFO` | `  Vectorizing:  79%|####################5     | 137/173 [01:19<00:22,  1.60it/s]`\n",
      "`2022-08-11 09:24:04,781` | `INFO` | `  Vectorizing:  79%|####################5     | 137/173 [01:29<00:22,  1.60it/s]`\n",
      "`2022-08-11 09:24:06,885` | `INFO` | `  Vectorizing:  86%|######################3   | 149/173 [01:31<00:16,  1.41it/s]`\n",
      "`2022-08-11 09:24:19,016` | `INFO` | `  Vectorizing:  95%|########################6 | 164/173 [01:43<00:06,  1.36it/s]`\n",
      "`2022-08-11 09:24:28,140` | `INFO` | `  Vectorizing: 100%|##########################| 173/173 [01:52<00:00,  1.53it/s]`\n",
      "\n",
      "`2022-08-11 09:24:29,101` | `INFO` | `Saving df_embeddings to: gcs://i18n-subreddit-clustering/i18n_topic_model_batch/runs/20220811/post_and_comment_text_combined/text_all/embedding/2022-08-11_084218/000000000013-233247_by_515.parquet`\n",
      "`2022-08-11 09:24:49,419` | `INFO` | `Files in batch:   7%|9            | 14/193 [38:49<8:02:24, 161.70s/it]`\n",
      "`2022-08-11 09:24:49,969` | `INFO` | `  Processing: 000000000014.parquet`\n",
      "`2022-08-11 09:24:49,970` | `INFO` | `Vectorizing column: post_and_comment_text_clean`\n",
      "`2022-08-11 09:24:50,182` | `INFO` | `Getting embeddings in batches of size: 1350`\n",
      "`2022-08-11 09:25:02,808` | `INFO` | `  Vectorizing:  15%|####                       | 15/100 [00:12<01:11,  1.19it/s]`\n",
      "`2022-08-11 09:25:15,027` | `INFO` | `  Vectorizing:  15%|####                       | 15/100 [00:24<01:11,  1.19it/s]`\n",
      "`2022-08-11 09:25:15,753` | `INFO` | `  Vectorizing:  28%|#######5                   | 28/100 [00:25<01:06,  1.08it/s]`\n",
      "`2022-08-11 09:25:28,077` | `INFO` | `  Vectorizing:  43%|###########6               | 43/100 [00:37<00:49,  1.14it/s]`\n",
      "`2022-08-11 09:25:45,029` | `INFO` | `  Vectorizing:  43%|###########6               | 43/100 [00:54<00:49,  1.14it/s]`\n",
      "`2022-08-11 09:25:45,846` | `INFO` | `  Vectorizing:  55%|##############8            | 55/100 [00:55<00:49,  1.09s/it]`\n",
      "`2022-08-11 09:25:58,778` | `INFO` | `  Vectorizing:  71%|###################1       | 71/100 [01:08<00:28,  1.02it/s]`\n",
      "`2022-08-11 09:26:15,166` | `INFO` | `  Vectorizing:  71%|###################1       | 71/100 [01:24<00:28,  1.02it/s]`\n",
      "`2022-08-11 09:26:16,520` | `INFO` | `  Vectorizing:  84%|######################6    | 84/100 [01:26<00:17,  1.10s/it]`\n",
      "`2022-08-11 09:26:29,152` | `INFO` | `  Vectorizing:  94%|#########################3 | 94/100 [01:38<00:06,  1.14s/it]`\n",
      "`2022-08-11 09:26:35,610` | `INFO` | `  Vectorizing: 100%|##########################| 100/100 [01:45<00:00,  1.05s/it]`\n",
      "\n",
      "`2022-08-11 09:26:36,132` | `INFO` | `Saving df_embeddings to: gcs://i18n-subreddit-clustering/i18n_topic_model_batch/runs/20220811/post_and_comment_text_combined/text_all/embedding/2022-08-11_084218/000000000014-134434_by_515.parquet`\n",
      "`2022-08-11 09:26:49,816` | `INFO` | `Files in batch:   8%|#            | 15/193 [40:50<7:22:47, 149.25s/it]`\n",
      "`2022-08-11 09:26:50,877` | `INFO` | `  Processing: 000000000015.parquet`\n",
      "`2022-08-11 09:26:50,879` | `INFO` | `Vectorizing column: post_and_comment_text_clean`\n",
      "`2022-08-11 09:26:51,123` | `INFO` | `Getting embeddings in batches of size: 1350`\n",
      "`2022-08-11 09:27:03,196` | `INFO` | `  Vectorizing:   5%|#4                         | 10/186 [00:12<03:32,  1.21s/it]`\n",
      "`2022-08-11 09:27:15,232` | `INFO` | `  Vectorizing:   5%|#4                         | 10/186 [00:24<03:32,  1.21s/it]`\n",
      "`2022-08-11 09:27:15,801` | `INFO` | `  Vectorizing:  13%|###6                       | 25/186 [00:24<02:34,  1.04it/s]`\n",
      "`2022-08-11 09:27:34,319` | `INFO` | `  Vectorizing:  22%|#####8                     | 40/186 [00:43<02:39,  1.09s/it]`\n",
      "`2022-08-11 09:27:45,237` | `INFO` | `  Vectorizing:  22%|#####8                     | 40/186 [00:54<02:39,  1.09s/it]`\n",
      "`2022-08-11 09:27:46,322` | `INFO` | `  Vectorizing:  27%|#######4                   | 51/186 [00:55<02:27,  1.09s/it]`\n",
      "`2022-08-11 09:27:58,984` | `INFO` | `  Vectorizing:  38%|##########3                | 71/186 [01:07<01:40,  1.14it/s]`\n",
      "`2022-08-11 09:28:15,305` | `INFO` | `  Vectorizing:  38%|##########3                | 71/186 [01:24<01:40,  1.14it/s]`\n",
      "`2022-08-11 09:28:15,817` | `INFO` | `  Vectorizing:  48%|############9              | 89/186 [01:24<01:27,  1.11it/s]`\n",
      "`2022-08-11 09:28:31,617` | `INFO` | `  Vectorizing:  55%|##############2           | 102/186 [01:40<01:22,  1.01it/s]`\n",
      "`2022-08-11 09:28:43,805` | `INFO` | `  Vectorizing:  61%|###############7          | 113/186 [01:52<01:14,  1.02s/it]`\n",
      "`2022-08-11 09:28:55,363` | `INFO` | `  Vectorizing:  61%|###############7          | 113/186 [02:04<01:14,  1.02s/it]`\n",
      "`2022-08-11 09:28:55,862` | `INFO` | `  Vectorizing:  72%|##################7       | 134/186 [02:04<00:43,  1.19it/s]`\n",
      "`2022-08-11 09:29:15,476` | `INFO` | `  Vectorizing:  72%|##################7       | 134/186 [02:24<00:43,  1.19it/s]`\n",
      "`2022-08-11 09:29:16,488` | `INFO` | `  Vectorizing:  83%|#####################5    | 154/186 [02:25<00:29,  1.10it/s]`\n",
      "`2022-08-11 09:29:28,596` | `INFO` | `  Vectorizing:  89%|#######################2  | 166/186 [02:37<00:18,  1.07it/s]`\n",
      "`2022-08-11 09:29:41,515` | `INFO` | `  Vectorizing:  97%|#########################1| 180/186 [02:50<00:05,  1.08it/s]`\n",
      "`2022-08-11 09:29:47,035` | `INFO` | `  Vectorizing: 100%|##########################| 186/186 [02:55<00:00,  1.06it/s]`\n",
      "\n",
      "`2022-08-11 09:29:48,108` | `INFO` | `Saving df_embeddings to: gcs://i18n-subreddit-clustering/i18n_topic_model_batch/runs/20220811/post_and_comment_text_combined/text_all/embedding/2022-08-11_084218/000000000015-250143_by_515.parquet`\n",
      "`2022-08-11 09:30:08,842` | `INFO` | `Files in batch:   8%|#            | 16/193 [44:09<8:04:29, 164.23s/it]`\n",
      "`2022-08-11 09:30:09,445` | `INFO` | `  Processing: 000000000016.parquet`\n",
      "`2022-08-11 09:30:09,446` | `INFO` | `Vectorizing column: post_and_comment_text_clean`\n",
      "`2022-08-11 09:30:09,684` | `INFO` | `Getting embeddings in batches of size: 1350`\n",
      "`2022-08-11 09:30:22,308` | `INFO` | `  Vectorizing:  10%|##6                        | 10/102 [00:12<01:56,  1.26s/it]`\n",
      "2022-08-11 09:30:32.525171: W tensorflow/core/common_runtime/bfc_allocator.cc:431] Allocator (GPU_0_bfc) ran out of memory trying to allocate 937.14MiB (rounded to 982666240)requested by op StatefulPartitionedCall/StatefulPartitionedCall/EncoderDNN/CNN_layers/ngram_order_5/Ngram-5-Conv/Window-3/Select\n",
      "Current allocation summary follows.\n",
      "2022-08-11 09:30:32.525813: W tensorflow/core/common_runtime/bfc_allocator.cc:439] *************************************************************************************************___\n",
      "2022-08-11 09:30:32.525874: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at cwise_op_select.cc:105 : Resource exhausted: OOM when allocating tensor with shape[959635,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "`2022-08-11 09:30:35,542` | `INFO` | `  Vectorizing:  10%|##6                        | 10/102 [00:25<01:56,  1.26s/it]`\n",
      "2022-08-11 09:30:42.527977: W tensorflow/core/common_runtime/bfc_allocator.cc:431] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.83GiB (rounded to 1965332480)requested by op StatefulPartitionedCall/StatefulPartitionedCall/EncoderDNN/CNN_layers/ngram_order_2/Ngram-2-Conv/concat_2\n",
      "Current allocation summary follows.\n",
      "2022-08-11 09:30:42.528561: W tensorflow/core/common_runtime/bfc_allocator.cc:439] *************************************************************************************************___\n",
      "2022-08-11 09:30:42.528602: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at concat_op.cc:161 : Resource exhausted: OOM when allocating tensor with shape[959635,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "2022-08-11 09:30:52.528865: W tensorflow/core/common_runtime/bfc_allocator.cc:431] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.75GiB (rounded to 2947998720)requested by op StatefulPartitionedCall/StatefulPartitionedCall/EncoderDNN/CNN_layers/ngram_order_3/Ngram-3-Conv/concat_2\n",
      "Current allocation summary follows.\n",
      "2022-08-11 09:30:52.529492: W tensorflow/core/common_runtime/bfc_allocator.cc:439] *************************************_____***************_____***********************************___\n",
      "2022-08-11 09:30:52.529532: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at concat_op.cc:161 : Resource exhausted: OOM when allocating tensor with shape[959635,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "`2022-08-11 09:30:52,530` | `WARNING` | `\n",
      "ResourceExhausted, lowering character limit\n",
      " OOM when allocating tensor with shape[959635,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node StatefulPartitionedCall/StatefulPartitionedCall/EncoderDNN/CNN_layers/ngram_order_5/Ngram-5-Conv/Window-3/Select}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      " [Op:__inference_restored_function_body_15375]\n",
      "\n",
      "Function call stack:\n",
      "restored_function_body\n",
      "\n",
      "`\n",
      "2022-08-11 09:31:02.712511: W tensorflow/core/common_runtime/bfc_allocator.cc:431] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.12GiB (rounded to 2280569856)requested by op StatefulPartitionedCall/StatefulPartitionedCall/EncoderDNN/CNN_layers/ngram_order_3/Ngram-3-Conv/concat_2\n",
      "Current allocation summary follows.\n",
      "2022-08-11 09:31:02.713160: W tensorflow/core/common_runtime/bfc_allocator.cc:439] *****************************____***********_____******************************************_________\n",
      "2022-08-11 09:31:02.713208: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at concat_op.cc:161 : Resource exhausted: OOM when allocating tensor with shape[742373,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "2022-08-11 09:31:12.713680: W tensorflow/core/common_runtime/bfc_allocator.cc:431] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.54GiB (rounded to 3800949760)requested by op StatefulPartitionedCall/StatefulPartitionedCall/EncoderDNN/CNN_layers/ngram_order_5/Ngram-5-Conv/concat_2\n",
      "Current allocation summary follows.\n",
      "2022-08-11 09:31:12.714307: W tensorflow/core/common_runtime/bfc_allocator.cc:439] *****************************_________******__________******____***************************_________\n",
      "2022-08-11 09:31:12.714347: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at concat_op.cc:161 : Resource exhausted: OOM when allocating tensor with shape[742373,1280] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "`2022-08-11 09:31:12,715` | `INFO` | `  Vectorizing:  10%|##6                        | 10/102 [01:03<09:39,  6.30s/it]`\n",
      "\n",
      "`2022-08-11 09:31:12,715` | `ERROR` | `Failed to vectorize comments`\n",
      "`2022-08-11 09:31:12,715` | `ERROR` | ` OOM when allocating tensor with shape[742373,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node StatefulPartitionedCall/StatefulPartitionedCall/EncoderDNN/CNN_layers/ngram_order_3/Ngram-3-Conv/concat_2}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      " [Op:__inference_restored_function_body_15375]\n",
      "\n",
      "Function call stack:\n",
      "restored_function_body\n",
      "`\n",
      "`2022-08-11 09:31:12,716` | `INFO` | `*** Retrying with smaller batch size 1012***`\n",
      "`2022-08-11 09:31:12,937` | `INFO` | `Getting embeddings in batches of size: 1012`\n",
      "`2022-08-11 09:31:25,312` | `INFO` | `  Vectorizing:  10%|##6                        | 13/135 [00:12<01:56,  1.05it/s]`\n",
      "2022-08-11 09:31:35.499189: W tensorflow/core/common_runtime/bfc_allocator.cc:431] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.05GiB (rounded to 2202132480)requested by op StatefulPartitionedCall/StatefulPartitionedCall/EncoderDNN/CNN_layers/ngram_order_3/Ngram-3-Conv/concat_2\n",
      "Current allocation summary follows.\n",
      "2022-08-11 09:31:35.499829: W tensorflow/core/common_runtime/bfc_allocator.cc:439] ****************************____***********____*****************************************____________\n",
      "2022-08-11 09:31:35.499869: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at concat_op.cc:161 : Resource exhausted: OOM when allocating tensor with shape[716840,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "`2022-08-11 09:31:35,544` | `INFO` | `  Vectorizing:  10%|##6                        | 13/135 [00:22<01:56,  1.05it/s]`\n",
      "2022-08-11 09:31:45.500420: W tensorflow/core/common_runtime/bfc_allocator.cc:431] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.42GiB (rounded to 3670220800)requested by op StatefulPartitionedCall/StatefulPartitionedCall/EncoderDNN/CNN_layers/ngram_order_5/Ngram-5-Conv/concat_2\n",
      "Current allocation summary follows.\n",
      "2022-08-11 09:31:45.501105: W tensorflow/core/common_runtime/bfc_allocator.cc:439] ****************************_________******_________******____**************************____________\n",
      "2022-08-11 09:31:45.501154: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at concat_op.cc:161 : Resource exhausted: OOM when allocating tensor with shape[716840,1280] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "`2022-08-11 09:31:45,502` | `WARNING` | `\n",
      "ResourceExhausted, lowering character limit\n",
      " OOM when allocating tensor with shape[716840,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node StatefulPartitionedCall/StatefulPartitionedCall/EncoderDNN/CNN_layers/ngram_order_3/Ngram-3-Conv/concat_2}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      " [Op:__inference_restored_function_body_15375]\n",
      "\n",
      "Function call stack:\n",
      "restored_function_body\n",
      "\n",
      "`\n",
      "`2022-08-11 09:31:47,316` | `INFO` | `  Vectorizing:  10%|##8                        | 14/135 [00:34<06:07,  3.04s/it]`\n",
      "2022-08-11 09:31:57.505569: W tensorflow/core/common_runtime/bfc_allocator.cc:431] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.07GiB (rounded to 2217999360)requested by op StatefulPartitionedCall/StatefulPartitionedCall/EncoderDNN/CNN_layers/ngram_order_3/Ngram-3-Conv/concat_2\n",
      "Current allocation summary follows.\n",
      "2022-08-11 09:31:57.506198: W tensorflow/core/common_runtime/bfc_allocator.cc:439] ****************************____***********____******************************************___________\n",
      "2022-08-11 09:31:57.506236: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at concat_op.cc:161 : Resource exhausted: OOM when allocating tensor with shape[722005,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "2022-08-11 09:32:07.506725: W tensorflow/core/common_runtime/bfc_allocator.cc:431] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.44GiB (rounded to 3696665600)requested by op StatefulPartitionedCall/StatefulPartitionedCall/EncoderDNN/CNN_layers/ngram_order_5/Ngram-5-Conv/concat_2\n",
      "Current allocation summary follows.\n",
      "2022-08-11 09:32:07.507379: W tensorflow/core/common_runtime/bfc_allocator.cc:439] ****************************_________******_________******____***************************___________\n",
      "2022-08-11 09:32:07.507420: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at concat_op.cc:161 : Resource exhausted: OOM when allocating tensor with shape[722005,1280] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "`2022-08-11 09:32:07,508` | `WARNING` | `\n",
      "ResourceExhausted, lowering character limit\n",
      " OOM when allocating tensor with shape[722005,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node StatefulPartitionedCall/StatefulPartitionedCall/EncoderDNN/CNN_layers/ngram_order_3/Ngram-3-Conv/concat_2}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      " [Op:__inference_restored_function_body_15375]\n",
      "\n",
      "Function call stack:\n",
      "restored_function_body\n",
      "\n",
      "`\n",
      "`2022-08-11 09:32:09,352` | `INFO` | `  Vectorizing:  11%|###                        | 15/135 [00:56<10:46,  5.39s/it]`\n",
      "2022-08-11 09:32:19.535908: W tensorflow/core/common_runtime/bfc_allocator.cc:431] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.17GiB (rounded to 2329012224)requested by op StatefulPartitionedCall/StatefulPartitionedCall/EncoderDNN/CNN_layers/ngram_order_3/Ngram-3-Conv/concat_2\n",
      "Current allocation summary follows.\n",
      "2022-08-11 09:32:19.536508: W tensorflow/core/common_runtime/bfc_allocator.cc:439] *****************************_____***********_____*******************************************_______\n",
      "2022-08-11 09:32:19.536543: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at concat_op.cc:161 : Resource exhausted: OOM when allocating tensor with shape[758142,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "2022-08-11 09:32:29.536842: W tensorflow/core/common_runtime/bfc_allocator.cc:431] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.61GiB (rounded to 3881687040)requested by op StatefulPartitionedCall/StatefulPartitionedCall/EncoderDNN/CNN_layers/ngram_order_5/Ngram-5-Conv/concat_2\n",
      "Current allocation summary follows.\n",
      "2022-08-11 09:32:29.537479: W tensorflow/core/common_runtime/bfc_allocator.cc:439] *****************************__________******__________******____****************************_______\n",
      "2022-08-11 09:32:29.537518: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at concat_op.cc:161 : Resource exhausted: OOM when allocating tensor with shape[758142,1280] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "`2022-08-11 09:32:29,538` | `WARNING` | `\n",
      "ResourceExhausted, lowering character limit\n",
      " OOM when allocating tensor with shape[758142,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node StatefulPartitionedCall/StatefulPartitionedCall/EncoderDNN/CNN_layers/ngram_order_3/Ngram-3-Conv/concat_2}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      " [Op:__inference_restored_function_body_15375]\n",
      "\n",
      "Function call stack:\n",
      "restored_function_body\n",
      "\n",
      "`\n",
      "2022-08-11 09:32:39.748537: W tensorflow/core/common_runtime/bfc_allocator.cc:431] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.73GiB (rounded to 2931886080)requested by op StatefulPartitionedCall/StatefulPartitionedCall/EncoderDNN/CNN_layers/ngram_order_5/Ngram-5-Conv/concat_2\n",
      "Current allocation summary follows.\n",
      "2022-08-11 09:32:39.749148: W tensorflow/core/common_runtime/bfc_allocator.cc:439] ***********************_______*****_______*****___*********************************_________________\n",
      "2022-08-11 09:32:39.749189: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at concat_op.cc:161 : Resource exhausted: OOM when allocating tensor with shape[572634,1280] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "`2022-08-11 09:32:39,750` | `INFO` | `  Vectorizing:  11%|###                        | 15/135 [01:26<11:34,  5.79s/it]`\n",
      "\n",
      "`2022-08-11 09:32:39,750` | `ERROR` | `Failed to vectorize comments`\n",
      "`2022-08-11 09:32:39,750` | `ERROR` | ` OOM when allocating tensor with shape[572634,1280] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node StatefulPartitionedCall/StatefulPartitionedCall/EncoderDNN/CNN_layers/ngram_order_5/Ngram-5-Conv/concat_2}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      " [Op:__inference_restored_function_body_15375]\n",
      "\n",
      "Function call stack:\n",
      "restored_function_body\n",
      "`\n",
      "`2022-08-11 09:32:39,751` | `INFO` | `*** Retrying with smaller batch size 675***`\n",
      "`2022-08-11 09:32:39,967` | `INFO` | `Getting embeddings in batches of size: 675`\n",
      "`2022-08-11 09:32:52,555` | `INFO` | `  Vectorizing:   9%|##3                        | 18/203 [00:12<02:09,  1.43it/s]`\n",
      "`2022-08-11 09:33:05,623` | `INFO` | `  Vectorizing:   9%|##3                        | 18/203 [00:25<02:09,  1.43it/s]`\n",
      "`2022-08-11 09:33:06,024` | `INFO` | `  Vectorizing:  13%|###5                       | 27/203 [00:26<03:01,  1.03s/it]`\n",
      "`2022-08-11 09:33:18,317` | `INFO` | `  Vectorizing:  22%|#####9                     | 45/203 [00:38<02:13,  1.19it/s]`\n",
      "`2022-08-11 09:33:31,884` | `INFO` | `  Vectorizing:  31%|########3                  | 63/203 [00:51<01:52,  1.24it/s]`\n",
      "`2022-08-11 09:33:44,411` | `INFO` | `  Vectorizing:  44%|###########8               | 89/203 [01:04<01:14,  1.54it/s]`\n",
      "`2022-08-11 09:33:55,776` | `INFO` | `  Vectorizing:  44%|###########8               | 89/203 [01:15<01:14,  1.54it/s]`\n",
      "`2022-08-11 09:33:57,128` | `INFO` | `  Vectorizing:  55%|##############2           | 111/203 [01:17<00:57,  1.60it/s]`\n",
      "`2022-08-11 09:34:10,782` | `INFO` | `  Vectorizing:  65%|################9         | 132/203 [01:30<00:44,  1.58it/s]`\n",
      "`2022-08-11 09:34:23,043` | `INFO` | `  Vectorizing:  76%|###################7      | 154/203 [01:43<00:29,  1.65it/s]`\n"
     ]
    }
   ],
   "source": [
    "# run on full data\n",
    "\n",
    "!cd $path_djb_repo && python -m $file_vectorize_py \\\n",
    "    --config-name $config_vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da784e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
