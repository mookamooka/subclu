{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5af0500c",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "2021-07-28\n",
    "Let's install `\"tensorflow-text == 2.3.0\"` and see if the GPU is still detected after installing it.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Check whether GPUs are available/usable in current python environment.\n",
    "\n",
    "**UPDATE:** With a fresh VM/notebook, we could see GPUs. This notebook runs the same code AFTER stopping and re-starting the VM. Maybe it's a problem with the way GCP handles the VM and not a problem created by installing new libraries?\n",
    "\n",
    "Provenance:\n",
    "- djb_01.03-test_gpus_available-instance-djb-subclu-inference-tf-2-3-20210630\n",
    "- djb_01.031-test_gpus_available_AFTER_RESTART-instance-djb-subclu-inference-tf-2-3-20210630\n",
    "\n",
    "\n",
    "# Debugging notes\n",
    "## Make sure to set the correct venv/kernel in your notebook\n",
    "The default `python 3` might not have the correct drivers.\n",
    "<br>Instead, might need to manually set it to:\n",
    "<br>`Python [conda env:root]`\n",
    "\n",
    "## Sometimes the best fix is `sudo reboot`\n",
    "When in doubt, open a terminal and do `sudo reboot`.\n",
    "\n",
    "For some reason, the NVIDIA drivers might not be loaded properly after shutting down a VM instance from the GUI:\n",
    "- https://console.cloud.google.com/ai-platform/notebooks/list/instances?project=data-prod-165221\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c976d6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea68635",
   "metadata": {},
   "source": [
    "# Imports & notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28acfe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccd94b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\t\tv 3.7.10\n",
      "===\n",
      "tensorflow\tv: 2.3.4\n",
      "tensorflow_text\tv: 2.3.0\n",
      "subclu\t\tv: 0.4.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Set logging higher BEFORE import TF\n",
    "#   For some reason, this was broken in TF 2.3.4\n",
    "#   https://github.com/tensorflow/tensorflow/issues/37649#issuecomment-599796966\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "from pkg_resources import get_distribution\n",
    "\n",
    "import tensorflow_text\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "import subclu\n",
    "from subclu.utils.eda import (\n",
    "    setup_logging, notebook_display_config, print_lib_versions,\n",
    ")\n",
    "\n",
    "print_lib_versions([tf, tensorflow_text, subclu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0907011f",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be27b985",
   "metadata": {},
   "source": [
    "# Check GPUs/XLA_GPUs recognized by Tensorflow/python\n",
    "\n",
    "NOTE: `GPU`s and `XLA_GPU`s are recognized as two different device types.\n",
    "\n",
    "https://www.tensorflow.org/xla\n",
    "> **XLA: Optimizing Compiler for Machine Learning**\n",
    "> XLA (Accelerated Linear Algebra) is a domain-specific compiler for linear algebra that can accelerate TensorFlow models with potentially no source code changes.\n",
    "> \n",
    "> The results are improvements in speed and memory usage: e.g. in BERT MLPerf submission using 8 Volta V100 GPUs using XLA has achieved a ~7x performance improvement and ~5x batch size improvement\n",
    "\n",
    "Other sources\n",
    "- https://stackoverflow.com/questions/52943489/what-is-xla-gpu-and-xla-cpu-for-tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8f82dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## List devices\n",
    "\n",
    "Expected GPU output\n",
    "```\n",
    "Built with CUDA? True\n",
    "\n",
    "GPUs\n",
    "===\n",
    "Num GPUs Available: 2\n",
    "GPU details:\n",
    "[   PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
    "    PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU')]\n",
    "\n",
    "Built with CUDA? True\n",
    "\n",
    "All devices:\n",
    "===\n",
    "Num devices: 4\n",
    "Details:\n",
    "[   name: \"/device:CPU:0\"\n",
    "device_type: \"CPU\"\n",
    "\n",
    "...\n",
    "\n",
    ",\n",
    "    name: \"/device:XLA_GPU:0\"\n",
    "device_type: \"XLA_GPU\"\n",
    "memory_limit: 17179869184\n",
    "locality {\n",
    "}\n",
    "incarnation: 6215884038941287466\n",
    "physical_device_desc: \"device: XLA_GPU device\"\n",
    ",\n",
    "    name: \"/device:GPU:0\"\n",
    "device_type: \"GPU\"\n",
    "memory_limit: 14676252416\n",
    "locality {\n",
    "  bus_id: 1\n",
    "  links {\n",
    "  }\n",
    "}\n",
    "incarnation: 8485125904456880156\n",
    "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
    "]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c35c13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Built with CUDA? True\n",
      "\n",
      "GPUs\n",
      "===\n",
      "Num GPUs Available: 4\n",
      "GPU details:\n",
      "[   PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
      "    PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n",
      "    PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'),\n",
      "    PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "l_phys_gpus = (\n",
    "    tf.config.list_physical_devices('GPU')  # + tf.config.list_physical_devices('XLA_GPU')\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"\\nBuilt with CUDA? {tf.test.is_built_with_cuda()}\"\n",
    "    f\"\\n\\nGPUs\\n===\"\n",
    "    f\"\\nNum GPUs Available: {len(l_phys_gpus)}\"\n",
    "    f\"\\nGPU details:\"\n",
    ")\n",
    "pprint(l_phys_gpus, indent=4,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87e39b06-c213-4837-bfc5-740d711e26f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  4\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1e03df9-0816-465c-827a-cdc5ec04669a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "386a30a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l_all_local_devices = device_lib.list_local_devices()\n",
    "# print(\n",
    "#     f\"\\nBuilt with CUDA? {tf.test.is_built_with_cuda()}\"\n",
    "#     f\"\\n\\nAll devices:\\n===\"\n",
    "#     f\"\\nNum devices: {len(l_all_local_devices)}\"\n",
    "#     f\"\\nDetails:\"\n",
    "# )\n",
    "# pprint(l_all_local_devices, indent=4,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fd7001f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !dpkg -l | grep nvidia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586d18e0-22d9-446a-a1dd-e9a4d65df100",
   "metadata": {},
   "source": [
    "# Load config to test inference on a small batch\n",
    "\n",
    "Also use this to make sure that we have access to the i18n bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9c0e170-a6d8-4979-955b-5a027def8b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from subclu.utils.hydra_config_loader import LoadHydraConfig\n",
    "from subclu.data.data_loaders import LoadSubreddits, LoadPosts, LoadComments\n",
    "from subclu.models.vectorize_text_tf import get_embeddings_as_df\n",
    "\n",
    "\n",
    "config_data_v040 = LoadHydraConfig(\n",
    "    config_path=\"../config/data_text_and_metadata\",\n",
    "    config_name='v0.4.0_19k_top_subs_and_geo_relevant_2021_09_27',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ec87816-d694-45c4-999c-3fa2f8dd6202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_name': 'v0.4.0 inputs - Top Subreddits (no Geo) + Geo-relevant subs, comments: TBD',\n",
       " 'bucket_name': 'i18n-subreddit-clustering',\n",
       " 'folder_subreddits_text_and_meta': 'subreddits/top/2021-09-24',\n",
       " 'folder_posts_text_and_meta': 'posts/top/2021-09-27',\n",
       " 'folder_comments_text_and_meta': None}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_data_v040.config_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95746acf-dc28-44f8-873d-2c8933353cdf",
   "metadata": {},
   "source": [
    "## Load subreddit meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fea7cd91-85ec-456d-b3b3-6f182cb4ac73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:35:06 | INFO | \"Local folder to download artifact(s):\n",
      "  /home/jupyter/subreddit_clustering_i18n/data/local_cache/subreddits/top/2021-09-24\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e39da9466004d3787a1449519ee989e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 170 ms, sys: 129 ms, total: 298 ms\n",
      "Wall time: 414 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_sub_meta = LoadSubreddits(\n",
    "    bucket_name=config_data_v040.config_dict['bucket_name'],\n",
    "    folder_path=config_data_v040.config_dict['folder_subreddits_text_and_meta'],\n",
    "    folder_posts=None,\n",
    "    columns=None,\n",
    ").read_raw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff08df42-7f6f-4e2b-8be7-237691dd2490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19262, 36)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub_meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00cdbbbf-bfa4-4f75-a877-4581ab2c056b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AskReddit. \\nAsk Reddit.... \\nr AskReddit is the place to ask and answer thought provoking questions..',\n",
       "       'pics. \\nReddit Pics. \\nA place for pictures and photographs.. \\n[Rules](pics  index)\\n\\n1. No screenshots',\n",
       "       \"funny. \\nfunny. \\nWelcome to r Funny, Reddit's largest humour depository.. \\n**Welcome to r Funny:**\\n\\n\\n\",\n",
       "       'memes. \\n/r/Memes the original since 2008. \\nMemes!\\n\\nA way of describing cultural information being sh',\n",
       "       'interestingasfuck. \\nInteresting As Fuck. \\nFor anything that is InterestingAsFuck. \\nA place to share ',\n",
       "       \"HolUp. \\nwhen you're itching for a spicy hol. \\nFun for the whole family! ᵉˣᶜᵉᵖᵗ ᴬᵘⁿᵗ ˢᵘˢᵃⁿ. \\nHol' up\\n\",\n",
       "       'PublicFreakout. \\n/r/PublicFreakout. \\nA sub dedicated to people freaking out, melting down, losing th',\n",
       "       'facepalm. \\nA gallery of inexplicable stupidity. \\n*A sub for you to share the stupidity of individual',\n",
       "       'Unexpected. \\nUnexpected. \\nThis sub is for unexpected twists in videos and gifs. \\n[Join Discord Chat]',\n",
       "       'NoStupidQuestions. \\nNo such thing as stupid questions. \\nAsk away!. \\n###There is no such thing as a S'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub_meta['subreddit_name_title_and_clean_descriptions'].head(10).str[:100].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2637f4c1-985f-4671-bfe6-e38895ba35e8",
   "metadata": {},
   "source": [
    "### Load USE-multilingual\n",
    "\n",
    "NOTE: I had 2 notebooks running - the other notebook started first, and it caused an OOM (out of memory) error when trying to load the `large` version.\n",
    "\n",
    "Remember to shut down other scripts/notebooks!\n",
    "```\n",
    "2021-10-01 02:29:43.934252: W tensorflow/core/common_runtime/bfc_allocator.cc:431] Allocator (GPU_0_bfc) ran out of memory trying to allocate 14.71MiB (rounded to 15421440)requested by op Identity\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00181785-ef2a-45d3-a4c3-a3a351bdc6f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.87 s, sys: 1.79 s, total: 9.67 s\n",
      "Wall time: 8.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "use_multi_large = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4be87ced-7e0a-4b15-b563-6efd7421b5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.2 s, sys: 348 ms, total: 2.55 s\n",
      "Wall time: 2.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "use_multi = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dae12140-5732-4bdc-b28d-7b1c1cff3b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8f5218-293b-43e7-88d8-bed674b312c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test inference times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "598e7ba5-3c78-4b00-a66f-a2db85f2e63c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2700,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_char_limit_test = 750\n",
    "n_batch_test = 2700\n",
    "n_batch_test_large = 1000\n",
    "\n",
    "series_text = df_sub_meta['subreddit_name_title_and_clean_descriptions'].str[:n_char_limit_test].head(n_batch_test)\n",
    "series_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "faeb1d65-a98d-4b53-85bc-5b5155007acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    AskReddit. \\nAsk Reddit.... \\nr AskReddit is t...\n",
       "1    pics. \\nReddit Pics. \\nA place for pictures an...\n",
       "2    funny. \\nfunny. \\nWelcome to r Funny, Reddit's...\n",
       "3    memes. \\n/r/Memes the original since 2008. \\nM...\n",
       "4    interestingasfuck. \\nInteresting As Fuck. \\nFo...\n",
       "Name: subreddit_name_title_and_clean_descriptions, dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d02022-6176-4b0d-9efd-9b2a04647513",
   "metadata": {},
   "source": [
    "### Create 2 objects: embeddings and then convert to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e553b870-fea2-4d9d-8f1d-9a07851738f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.73 s ± 105 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "embeddings_test = use_multi_large(series_text[:n_batch_test_large])\n",
    "df_vect = pd.DataFrame(embeddings_test.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a57182da-7642-44fe-b8fb-310bdcdf6ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.48 s ± 23.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "embeddings_test = use_multi(series_text)\n",
    "df_vect = pd.DataFrame(embeddings_test.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87c023e6-2d88-4d1b-b01b-1a63d8d0fbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.47 s ± 14.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "embeddings_test = use_multi(series_text)\n",
    "df_vect = pd.DataFrame(embeddings_test.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac48144f-6251-45e6-9f38-70485a3b9493",
   "metadata": {},
   "source": [
    "### Create a single df object\n",
    "I'd expect this to be faster, but it looks like a wash, or maybe even worse than creating an intermediate embeddings object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3042d66d-8ac1-43e7-ad95-f1da007ed3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.47 s ± 5.14 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "df_vect = pd.DataFrame(use_multi(series_text).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bfd0e5f-7ea7-4142-8bba-9ce2ab1fd7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.47 s ± 5.16 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "df_vect = pd.DataFrame(use_multi(series_text).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63699b1c-106c-497a-99e5-4cf68dbe0721",
   "metadata": {},
   "source": [
    "#### Use `np.array()` instead of TF's `.numpy()` method\n",
    "\n",
    "I'd expect this to be a little slower, but it looks like if it is slower, it's not by much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab6600eb-fcc0-43d6-9b21-aa4bfebf624b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.48 s ± 4.73 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "df_vect = pd.DataFrame(np.array(use_multi(series_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ea528c9-4b41-44c9-bc11-d0860b07077a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.49 s ± 5.68 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "df_vect = pd.DataFrame(np.array(use_multi(series_text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bab545-e1bb-443b-addf-406812dc58bf",
   "metadata": {},
   "source": [
    "### Convert the dataframe to a list before creating embeddings\n",
    "\n",
    "In most examples, it looks like the expected input is a list of embeddings. In previous versions of tf (e.g., 2.3.3), it looked like TF would process each row sequentially, so I used `.to_list()` because that was natively parallel.\n",
    "\n",
    "Even though `.to_list()` now doesn't seem to be faster, I'll keep it for backwards compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f89c4367-6b94-4258-8ecf-248c73ceb4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.49 s ± 3.11 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "embeddings_test2 = pd.DataFrame(\n",
    "    use_multi(series_text.to_list()).numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "737e83a0-b52a-449d-8d29-6350ffa315bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.48 s ± 5.16 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "embeddings_test2 = pd.DataFrame(\n",
    "    use_multi(series_text.to_list()).numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12bb80e-9ad7-4769-ba9f-0b6293437e4f",
   "metadata": {},
   "source": [
    "### This was my old way... it's clearly slower so don't do it anymore\n",
    "I was creating a list comprehension that now seems to waste time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b89d7e2b-35a4-416e-917f-cfabcd5027ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.93 s ± 13.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "embeddings_test2 = pd.DataFrame(\n",
    "    np.array([emb.numpy() for emb in use_multi(series_text.to_list())])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed3c1414-99de-4d0b-8726-6165fafa7a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.94 s ± 22.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "embeddings_test2 = pd.DataFrame(\n",
    "    np.array([emb.numpy() for emb in use_multi(series_text.to_list())])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3658330d-b61a-49ca-8f7e-c470bb7453cc",
   "metadata": {},
   "source": [
    "## Inspect conversion example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0e6b984-16b5-4c4b-a3c4-3d30038f4e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.74 s, sys: 34 ms, total: 1.78 s\n",
      "Wall time: 1.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "embeddings_test = use_multi(series_text.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5fca4f97-b04b-4561-a7bd-ec1434676c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2700, 512])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4bb56e3d-32af-4de0-9769-05ddabf848ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2700, 512)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_test.numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "21903109-e51f-46dd-924f-72d2a59c0b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2700, 512)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(embeddings_test).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6058eecb-7cc8-4995-9061-61089ef15688",
   "metadata": {},
   "source": [
    "### Need to convert the raw embeddings output to make it a flat/df shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9fafdf5b-af64-4c3c-9eb9-e03ef1a3ee6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tf.Tensor(-0.0055558663, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.035515025, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.0022780034, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.036515567, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.07314272, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.036497936, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.049269363, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.04262645, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.0523665, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.0005845973, shape=(), dtype=float32)</td>\n",
       "      <td>...</td>\n",
       "      <td>tf.Tensor(0.069771625, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.020761905, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.021816198, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.04700967, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.010417417, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.057876956, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.059722144, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.0031177353, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.04763955, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.07449764, shape=(), dtype=float32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tf.Tensor(-0.05912168, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.0028184308, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.02198541, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.0032862264, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.044820715, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.046669677, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.046701834, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.067676745, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.052850373, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.023734221, shape=(), dtype=float32)</td>\n",
       "      <td>...</td>\n",
       "      <td>tf.Tensor(0.04174909, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.0035612562, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.05574649, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.05225738, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.008880128, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.019475382, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.040921874, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.01874695, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.027175335, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.056929246, shape=(), dtype=float32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tf.Tensor(0.06015646, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.04744803, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.02377507, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.03758738, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.07512383, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.06230174, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.021927327, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.052881956, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.03562096, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.006802066, shape=(), dtype=float32)</td>\n",
       "      <td>...</td>\n",
       "      <td>tf.Tensor(-0.04608957, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.0063478565, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.06315106, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.0035429779, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.035898563, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.036796335, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.048255075, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.0612688, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.007957812, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.061666816, shape=(), dtype=float32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tf.Tensor(-0.014804245, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.0065776324, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.053259037, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.018393569, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.06598462, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.06567661, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.06568842, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.040840585, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.042672247, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.04848014, shape=(), dtype=float32)</td>\n",
       "      <td>...</td>\n",
       "      <td>tf.Tensor(0.06505672, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.04214886, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.038975522, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.04867234, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.035740327, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.04875293, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.060423836, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.056467135, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.04734151, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.06562069, shape=(), dtype=float32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tf.Tensor(-0.02569435, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.074409544, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.043988932, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.014120724, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.07039471, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.05965422, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.040310733, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.006703761, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.0045451685, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.04671402, shape=(), dtype=float32)</td>\n",
       "      <td>...</td>\n",
       "      <td>tf.Tensor(-0.026356531, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.0027052928, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.07336133, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.033206973, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.0068020285, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.015830398, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.049823914, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.012888542, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(-0.047644023, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(0.08275503, shape=(), dtype=float32)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 0    \\\n",
       "0  tf.Tensor(-0.0055558663, shape=(), dtype=float32)   \n",
       "1    tf.Tensor(-0.05912168, shape=(), dtype=float32)   \n",
       "2     tf.Tensor(0.06015646, shape=(), dtype=float32)   \n",
       "3   tf.Tensor(-0.014804245, shape=(), dtype=float32)   \n",
       "4    tf.Tensor(-0.02569435, shape=(), dtype=float32)   \n",
       "\n",
       "                                                 1    \\\n",
       "0   tf.Tensor(-0.035515025, shape=(), dtype=float32)   \n",
       "1  tf.Tensor(-0.0028184308, shape=(), dtype=float32)   \n",
       "2    tf.Tensor(-0.04744803, shape=(), dtype=float32)   \n",
       "3   tf.Tensor(0.0065776324, shape=(), dtype=float32)   \n",
       "4    tf.Tensor(0.074409544, shape=(), dtype=float32)   \n",
       "\n",
       "                                                 2    \\\n",
       "0  tf.Tensor(-0.0022780034, shape=(), dtype=float32)   \n",
       "1     tf.Tensor(0.02198541, shape=(), dtype=float32)   \n",
       "2    tf.Tensor(-0.02377507, shape=(), dtype=float32)   \n",
       "3   tf.Tensor(-0.053259037, shape=(), dtype=float32)   \n",
       "4   tf.Tensor(-0.043988932, shape=(), dtype=float32)   \n",
       "\n",
       "                                                 3    \\\n",
       "0    tf.Tensor(0.036515567, shape=(), dtype=float32)   \n",
       "1  tf.Tensor(-0.0032862264, shape=(), dtype=float32)   \n",
       "2    tf.Tensor(-0.03758738, shape=(), dtype=float32)   \n",
       "3   tf.Tensor(-0.018393569, shape=(), dtype=float32)   \n",
       "4    tf.Tensor(0.014120724, shape=(), dtype=float32)   \n",
       "\n",
       "                                               4    \\\n",
       "0   tf.Tensor(0.07314272, shape=(), dtype=float32)   \n",
       "1  tf.Tensor(0.044820715, shape=(), dtype=float32)   \n",
       "2   tf.Tensor(0.07512383, shape=(), dtype=float32)   \n",
       "3   tf.Tensor(0.06598462, shape=(), dtype=float32)   \n",
       "4   tf.Tensor(0.07039471, shape=(), dtype=float32)   \n",
       "\n",
       "                                               5    \\\n",
       "0  tf.Tensor(0.036497936, shape=(), dtype=float32)   \n",
       "1  tf.Tensor(0.046669677, shape=(), dtype=float32)   \n",
       "2   tf.Tensor(0.06230174, shape=(), dtype=float32)   \n",
       "3   tf.Tensor(0.06567661, shape=(), dtype=float32)   \n",
       "4   tf.Tensor(0.05965422, shape=(), dtype=float32)   \n",
       "\n",
       "                                               6    \\\n",
       "0  tf.Tensor(0.049269363, shape=(), dtype=float32)   \n",
       "1  tf.Tensor(0.046701834, shape=(), dtype=float32)   \n",
       "2  tf.Tensor(0.021927327, shape=(), dtype=float32)   \n",
       "3  tf.Tensor(-0.06568842, shape=(), dtype=float32)   \n",
       "4  tf.Tensor(0.040310733, shape=(), dtype=float32)   \n",
       "\n",
       "                                                7    \\\n",
       "0   tf.Tensor(-0.04262645, shape=(), dtype=float32)   \n",
       "1  tf.Tensor(-0.067676745, shape=(), dtype=float32)   \n",
       "2   tf.Tensor(0.052881956, shape=(), dtype=float32)   \n",
       "3   tf.Tensor(0.040840585, shape=(), dtype=float32)   \n",
       "4   tf.Tensor(0.006703761, shape=(), dtype=float32)   \n",
       "\n",
       "                                                 8    \\\n",
       "0      tf.Tensor(0.0523665, shape=(), dtype=float32)   \n",
       "1    tf.Tensor(0.052850373, shape=(), dtype=float32)   \n",
       "2    tf.Tensor(-0.03562096, shape=(), dtype=float32)   \n",
       "3    tf.Tensor(0.042672247, shape=(), dtype=float32)   \n",
       "4  tf.Tensor(-0.0045451685, shape=(), dtype=float32)   \n",
       "\n",
       "                                                 9    ...  \\\n",
       "0  tf.Tensor(-0.0005845973, shape=(), dtype=float32)  ...   \n",
       "1   tf.Tensor(-0.023734221, shape=(), dtype=float32)  ...   \n",
       "2    tf.Tensor(0.006802066, shape=(), dtype=float32)  ...   \n",
       "3     tf.Tensor(0.04848014, shape=(), dtype=float32)  ...   \n",
       "4     tf.Tensor(0.04671402, shape=(), dtype=float32)  ...   \n",
       "\n",
       "                                                502  \\\n",
       "0   tf.Tensor(0.069771625, shape=(), dtype=float32)   \n",
       "1    tf.Tensor(0.04174909, shape=(), dtype=float32)   \n",
       "2   tf.Tensor(-0.04608957, shape=(), dtype=float32)   \n",
       "3    tf.Tensor(0.06505672, shape=(), dtype=float32)   \n",
       "4  tf.Tensor(-0.026356531, shape=(), dtype=float32)   \n",
       "\n",
       "                                                 503  \\\n",
       "0   tf.Tensor(-0.020761905, shape=(), dtype=float32)   \n",
       "1  tf.Tensor(-0.0035612562, shape=(), dtype=float32)   \n",
       "2  tf.Tensor(-0.0063478565, shape=(), dtype=float32)   \n",
       "3     tf.Tensor(0.04214886, shape=(), dtype=float32)   \n",
       "4  tf.Tensor(-0.0027052928, shape=(), dtype=float32)   \n",
       "\n",
       "                                                504  \\\n",
       "0   tf.Tensor(0.021816198, shape=(), dtype=float32)   \n",
       "1   tf.Tensor(-0.05574649, shape=(), dtype=float32)   \n",
       "2   tf.Tensor(-0.06315106, shape=(), dtype=float32)   \n",
       "3  tf.Tensor(-0.038975522, shape=(), dtype=float32)   \n",
       "4   tf.Tensor(-0.07336133, shape=(), dtype=float32)   \n",
       "\n",
       "                                                505  \\\n",
       "0   tf.Tensor(-0.04700967, shape=(), dtype=float32)   \n",
       "1   tf.Tensor(-0.05225738, shape=(), dtype=float32)   \n",
       "2  tf.Tensor(0.0035429779, shape=(), dtype=float32)   \n",
       "3   tf.Tensor(-0.04867234, shape=(), dtype=float32)   \n",
       "4  tf.Tensor(-0.033206973, shape=(), dtype=float32)   \n",
       "\n",
       "                                                 506  \\\n",
       "0    tf.Tensor(0.010417417, shape=(), dtype=float32)   \n",
       "1   tf.Tensor(-0.008880128, shape=(), dtype=float32)   \n",
       "2    tf.Tensor(0.035898563, shape=(), dtype=float32)   \n",
       "3   tf.Tensor(-0.035740327, shape=(), dtype=float32)   \n",
       "4  tf.Tensor(-0.0068020285, shape=(), dtype=float32)   \n",
       "\n",
       "                                                507  \\\n",
       "0   tf.Tensor(0.057876956, shape=(), dtype=float32)   \n",
       "1  tf.Tensor(-0.019475382, shape=(), dtype=float32)   \n",
       "2   tf.Tensor(0.036796335, shape=(), dtype=float32)   \n",
       "3    tf.Tensor(0.04875293, shape=(), dtype=float32)   \n",
       "4   tf.Tensor(0.015830398, shape=(), dtype=float32)   \n",
       "\n",
       "                                               508  \\\n",
       "0  tf.Tensor(0.059722144, shape=(), dtype=float32)   \n",
       "1  tf.Tensor(0.040921874, shape=(), dtype=float32)   \n",
       "2  tf.Tensor(0.048255075, shape=(), dtype=float32)   \n",
       "3  tf.Tensor(0.060423836, shape=(), dtype=float32)   \n",
       "4  tf.Tensor(0.049823914, shape=(), dtype=float32)   \n",
       "\n",
       "                                                 509  \\\n",
       "0  tf.Tensor(-0.0031177353, shape=(), dtype=float32)   \n",
       "1    tf.Tensor(-0.01874695, shape=(), dtype=float32)   \n",
       "2     tf.Tensor(-0.0612688, shape=(), dtype=float32)   \n",
       "3   tf.Tensor(-0.056467135, shape=(), dtype=float32)   \n",
       "4   tf.Tensor(-0.012888542, shape=(), dtype=float32)   \n",
       "\n",
       "                                                510  \\\n",
       "0   tf.Tensor(-0.04763955, shape=(), dtype=float32)   \n",
       "1   tf.Tensor(0.027175335, shape=(), dtype=float32)   \n",
       "2  tf.Tensor(-0.007957812, shape=(), dtype=float32)   \n",
       "3    tf.Tensor(0.04734151, shape=(), dtype=float32)   \n",
       "4  tf.Tensor(-0.047644023, shape=(), dtype=float32)   \n",
       "\n",
       "                                               511  \n",
       "0   tf.Tensor(0.07449764, shape=(), dtype=float32)  \n",
       "1  tf.Tensor(0.056929246, shape=(), dtype=float32)  \n",
       "2  tf.Tensor(0.061666816, shape=(), dtype=float32)  \n",
       "3   tf.Tensor(0.06562069, shape=(), dtype=float32)  \n",
       "4   tf.Tensor(0.08275503, shape=(), dtype=float32)  \n",
       "\n",
       "[5 rows x 512 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(embeddings_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3635a2cd-3b5d-4404-a151-26074bcc899a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.005556</td>\n",
       "      <td>-0.035515</td>\n",
       "      <td>-0.002278</td>\n",
       "      <td>0.036516</td>\n",
       "      <td>0.073143</td>\n",
       "      <td>0.036498</td>\n",
       "      <td>0.049269</td>\n",
       "      <td>-0.042626</td>\n",
       "      <td>0.052366</td>\n",
       "      <td>-0.000585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069772</td>\n",
       "      <td>-0.020762</td>\n",
       "      <td>0.021816</td>\n",
       "      <td>-0.047010</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.057877</td>\n",
       "      <td>0.059722</td>\n",
       "      <td>-0.003118</td>\n",
       "      <td>-0.047640</td>\n",
       "      <td>0.074498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.059122</td>\n",
       "      <td>-0.002818</td>\n",
       "      <td>0.021985</td>\n",
       "      <td>-0.003286</td>\n",
       "      <td>0.044821</td>\n",
       "      <td>0.046670</td>\n",
       "      <td>0.046702</td>\n",
       "      <td>-0.067677</td>\n",
       "      <td>0.052850</td>\n",
       "      <td>-0.023734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041749</td>\n",
       "      <td>-0.003561</td>\n",
       "      <td>-0.055746</td>\n",
       "      <td>-0.052257</td>\n",
       "      <td>-0.008880</td>\n",
       "      <td>-0.019475</td>\n",
       "      <td>0.040922</td>\n",
       "      <td>-0.018747</td>\n",
       "      <td>0.027175</td>\n",
       "      <td>0.056929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060156</td>\n",
       "      <td>-0.047448</td>\n",
       "      <td>-0.023775</td>\n",
       "      <td>-0.037587</td>\n",
       "      <td>0.075124</td>\n",
       "      <td>0.062302</td>\n",
       "      <td>0.021927</td>\n",
       "      <td>0.052882</td>\n",
       "      <td>-0.035621</td>\n",
       "      <td>0.006802</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046090</td>\n",
       "      <td>-0.006348</td>\n",
       "      <td>-0.063151</td>\n",
       "      <td>0.003543</td>\n",
       "      <td>0.035899</td>\n",
       "      <td>0.036796</td>\n",
       "      <td>0.048255</td>\n",
       "      <td>-0.061269</td>\n",
       "      <td>-0.007958</td>\n",
       "      <td>0.061667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.014804</td>\n",
       "      <td>0.006578</td>\n",
       "      <td>-0.053259</td>\n",
       "      <td>-0.018394</td>\n",
       "      <td>0.065985</td>\n",
       "      <td>0.065677</td>\n",
       "      <td>-0.065688</td>\n",
       "      <td>0.040841</td>\n",
       "      <td>0.042672</td>\n",
       "      <td>0.048480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065057</td>\n",
       "      <td>0.042149</td>\n",
       "      <td>-0.038976</td>\n",
       "      <td>-0.048672</td>\n",
       "      <td>-0.035740</td>\n",
       "      <td>0.048753</td>\n",
       "      <td>0.060424</td>\n",
       "      <td>-0.056467</td>\n",
       "      <td>0.047342</td>\n",
       "      <td>0.065621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.025694</td>\n",
       "      <td>0.074410</td>\n",
       "      <td>-0.043989</td>\n",
       "      <td>0.014121</td>\n",
       "      <td>0.070395</td>\n",
       "      <td>0.059654</td>\n",
       "      <td>0.040311</td>\n",
       "      <td>0.006704</td>\n",
       "      <td>-0.004545</td>\n",
       "      <td>0.046714</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026357</td>\n",
       "      <td>-0.002705</td>\n",
       "      <td>-0.073361</td>\n",
       "      <td>-0.033207</td>\n",
       "      <td>-0.006802</td>\n",
       "      <td>0.015830</td>\n",
       "      <td>0.049824</td>\n",
       "      <td>-0.012889</td>\n",
       "      <td>-0.047644</td>\n",
       "      <td>0.082755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.005556 -0.035515 -0.002278  0.036516  0.073143  0.036498  0.049269   \n",
       "1 -0.059122 -0.002818  0.021985 -0.003286  0.044821  0.046670  0.046702   \n",
       "2  0.060156 -0.047448 -0.023775 -0.037587  0.075124  0.062302  0.021927   \n",
       "3 -0.014804  0.006578 -0.053259 -0.018394  0.065985  0.065677 -0.065688   \n",
       "4 -0.025694  0.074410 -0.043989  0.014121  0.070395  0.059654  0.040311   \n",
       "\n",
       "        7         8         9    ...       502       503       504       505  \\\n",
       "0 -0.042626  0.052366 -0.000585  ...  0.069772 -0.020762  0.021816 -0.047010   \n",
       "1 -0.067677  0.052850 -0.023734  ...  0.041749 -0.003561 -0.055746 -0.052257   \n",
       "2  0.052882 -0.035621  0.006802  ... -0.046090 -0.006348 -0.063151  0.003543   \n",
       "3  0.040841  0.042672  0.048480  ...  0.065057  0.042149 -0.038976 -0.048672   \n",
       "4  0.006704 -0.004545  0.046714  ... -0.026357 -0.002705 -0.073361 -0.033207   \n",
       "\n",
       "        506       507       508       509       510       511  \n",
       "0  0.010417  0.057877  0.059722 -0.003118 -0.047640  0.074498  \n",
       "1 -0.008880 -0.019475  0.040922 -0.018747  0.027175  0.056929  \n",
       "2  0.035899  0.036796  0.048255 -0.061269 -0.007958  0.061667  \n",
       "3 -0.035740  0.048753  0.060424 -0.056467  0.047342  0.065621  \n",
       "4 -0.006802  0.015830  0.049824 -0.012889 -0.047644  0.082755  \n",
       "\n",
       "[5 rows x 512 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(embeddings_test.numpy()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "032b586d-b615-42bd-8961-a501269724fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(pd.DataFrame(embeddings_test.numpy()), pd.DataFrame(np.array(embeddings_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c88f38f-a6d8-49f8-8c63-e88b02f6e3ad",
   "metadata": {},
   "source": [
    "# Options for running in parallel\n",
    "\n",
    "Above tests weren't great... seems like TF will only use one core at a time for GPU inference........ UGH\n",
    "- This issue was opened in 2017 (and is still open w/o a solution)\n",
    "    - https://github.com/tensorflow/serving/issues/311 \n",
    "    \n",
    "    \n",
    "#### Multiprocessing\n",
    "So I would need to write custom code to manually split up the chunks and run the multi-process myself. This AWS blog post from 2 years ago provides a way to do it... but it might take some thinking to refactor.\n",
    "- blog post\n",
    "    - https://aws.amazon.com/blogs/machine-learning/parallelizing-across-multiple-cpu-gpus-to-speed-up-deep-learning-inference-at-the-edge/\n",
    "- github repo\n",
    "    - https://github.com/aws-samples/parallelize-ml-inference\n",
    "\n",
    "### Use `dask.delayed()` instead of multiprocessing?\n",
    "My mental model if `dask.delayed()` is better than `multiprocessing`, so maybe that's worth a shot?\n",
    "\n",
    "#### Manual Batching\n",
    "This one seems to use TF sessions (those might be deprecated, though).\n",
    "- https://medium.com/@sbp3624/tensorflow-multi-gpu-for-inferencing-test-time-58e952a2ed95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7a6e7a8-78e6-4cd4-97f7-1de47c1a80a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:50:26 | INFO | \"Getting embeddings in batches of size: 2200\"\n",
      "  0%|                                                     | 0/9 [00:00<?, ?it/s]05:50:36 | WARNING | \"\n",
      "ResourceExhausted, lowering character limit\n",
      " OOM when allocating tensor with shape[573337,1280] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node StatefulPartitionedCall/StatefulPartitionedCall/EncoderDNN/CNN_layers/ngram_order_5/Ngram-5-Conv/concat_2}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      " [Op:__inference_restored_function_body_66405]\n",
      "\n",
      "Function call stack:\n",
      "restored_function_body\n",
      "\n",
      "\"\n",
      "100%|#############################################| 9/9 [00:23<00:00,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.3 s, sys: 265 ms, total: 17.6 s\n",
      "Wall time: 23.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_embeddings = get_embeddings_as_df(\n",
    "    model=use_multi,\n",
    "    df=df_sub_meta,\n",
    "    col_text='subreddit_name_title_and_clean_descriptions',\n",
    "    cols_index='subreddit_default_',\n",
    "    limit_first_n_chars=1000,\n",
    "    batch_size=2200,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b53bbb2-46a6-4bb5-a550-d1124fd6c232",
   "metadata": {},
   "source": [
    "using `nvidia-smi` we see that the above was only using one core:\n",
    "```bash\n",
    "+-----------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\n",
    "|-------------------------------+----------------------+----------------------+\n",
    "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                               |                      |               MIG M. |\n",
    "|===============================+======================+======================|\n",
    "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
    "| N/A   81C    P0    68W /  70W |  14378MiB / 15109MiB |    100%      Default |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "|   1  Tesla T4            Off  | 00000000:00:05.0 Off |                    0 |\n",
    "| N/A   78C    P0    34W /  70W |    222MiB / 15109MiB |      0%      Default |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "|   2  Tesla T4            Off  | 00000000:00:06.0 Off |                    0 |\n",
    "| N/A   74C    P0    33W /  70W |    222MiB / 15109MiB |      0%      Default |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "|   3  Tesla T4            Off  | 00000000:00:07.0 Off |                    0 |\n",
    "| N/A   77C    P0    34W /  70W |    222MiB / 15109MiB |      0%      Default |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "\n",
    "+-----------------------------------------------------------------------------+\n",
    "| Processes:                                                                  |\n",
    "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
    "|        ID   ID                                                   Usage      |\n",
    "|=============================================================================|\n",
    "|    0   N/A  N/A     28693      C   /opt/conda/bin/python           14375MiB |\n",
    "|    1   N/A  N/A     28693      C   /opt/conda/bin/python             219MiB |\n",
    "|    2   N/A  N/A     28693      C   /opt/conda/bin/python             219MiB |\n",
    "|    3   N/A  N/A     28693      C   /opt/conda/bin/python             219MiB |\n",
    "+-----------------------------------------------------------------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831b645b-206e-4111-92c2-c57eed4aa692",
   "metadata": {},
   "source": [
    "# Try `dask.delayed()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d288a273-966e-4cbf-9107-32acd1dd2eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m80",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m80"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
