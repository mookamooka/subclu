{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "590ab5d8",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "\n",
    "2022-07-07:\n",
    "The data we pulled to build v0.5.0 model was in a temp table that was deleted. We have access to the post & comment text in GCS, but the metadata (vote counts, nsfw tag, ocr raw, etc.) is gone.\n",
    "\n",
    "Here we'll check the subreddit metadata to create a new table that includes the metadata needed for the posts used in the v0.5.0 model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647ac556",
   "metadata": {},
   "source": [
    "# Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9efa408a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0327505e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\t\tv 3.7.10\n",
      "===\n",
      "dask\t\tv: 2021.06.0\n",
      "hydra\t\tv: 1.1.0\n",
      "mlflow\t\tv: 1.16.0\n",
      "numpy\t\tv: 1.19.5\n",
      "pandas\t\tv: 1.2.4\n",
      "plotly\t\tv: 4.14.3\n",
      "seaborn\t\tv: 0.11.1\n",
      "subclu\t\tv: 0.5.0\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import gc\n",
    "import os\n",
    "import logging\n",
    "from logging import info\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "import dask\n",
    "from dask import dataframe as dd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import mlflow\n",
    "import hydra\n",
    "\n",
    "import subclu\n",
    "\n",
    "from subclu.utils import set_working_directory, get_project_subfolder\n",
    "from subclu.utils.eda import (\n",
    "    setup_logging, counts_describe, value_counts_and_pcts,\n",
    "    notebook_display_config, print_lib_versions,\n",
    "    style_df_numeric,\n",
    "    get_venn_sets2,\n",
    ")\n",
    "from subclu.utils.hydra_config_loader import LoadHydraConfig\n",
    "from subclu.i18n_topic_model_batch.subclu2.utils.data_loaders_gcs import (\n",
    "    LoadSubredditsGCS\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print_lib_versions([dask, hydra, mlflow, np, pd, plotly, sns, subclu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6788871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.dates as mdates\n",
    "plt.style.use('default')\n",
    "\n",
    "setup_logging()\n",
    "notebook_display_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb4d039",
   "metadata": {},
   "source": [
    "# Load config & set paths \n",
    "\n",
    "Let's use the config to make sure we're looking at the right data w/o having to hard-code paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e22aa0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_local_cache_ = \"/home/jupyter/subreddit_clustering_i18n/data/local_cache/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ba4de0c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_name': 'v0.5.0 inputs. ~80k seed subreddits, ~190k total subreddits',\n",
       " 'bucket_name': 'i18n-subreddit-clustering',\n",
       " 'folder_subreddits_text_and_meta': 'i18n_topic_model_batch/runs/20220629/subreddits/text',\n",
       " 'folder_subreddits_text_and_meta_alt': 'i18n_topic_model_batch/runs/20220707/subreddits/text',\n",
       " 'folder_posts_text_and_meta': 'i18n_topic_model_batch/runs/20220707/posts',\n",
       " 'folder_comments_text_and_meta': 'i18n_topic_model_batch/runs/20220707/comments',\n",
       " 'folder_post_and_comment_text_and_meta': 'i18n_topic_model_batch/runs/20220629/post_and_comment_text_combined/text_subreddit_seeds',\n",
       " 'folder_post_and_comment_text_and_meta_alt': 'i18n_topic_model_batch/runs/20220707/post_and_comment_text_combined/text_subreddit_seeds',\n",
       " 'folder_post_and_comment_text_and_meta_non_seed': 'i18n_topic_model_batch/runs/20220629/post_and_comment_text_combined/text_non_subreddit_seeds'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg_v050_text_and_meta = LoadHydraConfig(\n",
    "    config_name='v0.5.0_model.yaml',\n",
    "    config_path='../i18n_topic_model_batch/subclu2/config/data_text_and_metadata',\n",
    ")\n",
    "(cfg_v050_text_and_meta.config_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b6954f",
   "metadata": {},
   "source": [
    "# Load metadata + embeddings\n",
    "\n",
    "For v0.5.0 embeddings I didn't use mlflow to track the embeddings inference. We'll need to get them from these folders in GCS:\n",
    "\n",
    "- [Subreddit metadata](https://console.cloud.google.com/storage/browser/i18n-subreddit-clustering/i18n_topic_model_batch/runs/20220629/subreddits/text/embedding/2022-06-29_084555)\n",
    "    - `i18n-subreddit-clustering/i18n_topic_model_batch/runs/20220629/subreddits/text/embedding/2022-06-29_084555`\n",
    "- [Post + Comment Text (already combined)](https://console.cloud.google.com/storage/browser/i18n-subreddit-clustering/i18n_topic_model_batch/runs/20220629/post_and_comment_text_combined/text_subreddit_seeds/embedding/2022-06-29_091925)\n",
    "    - `i18n-subreddit-clustering/i18n_topic_model_batch/runs/20220629/post_and_comment_text_combined/text_subreddit_seeds/embedding/2022-06-29_091925`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4564b205",
   "metadata": {},
   "source": [
    "## Subreddit meta\n",
    "\n",
    "Here's where we should be able to retrieve the date-range needed to get the lost metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4ad3c7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:22:39 | INFO | \"  Local folder to download artifact(s):\n",
      "  /home/jupyter/subreddit_clustering_i18n/data/local_cache/i18n-subreddit-clustering/i18n_topic_model_batch/runs/20220629/subreddits/text\"\n",
      "21:22:39 | INFO | \"  6 <- Files matching prefix\"\n",
      "21:22:39 | INFO | \"  6 <- Files to check\"\n",
      "21:22:40 | INFO | \"  Files already cached: 0\"\n",
      "21:22:40 | INFO | \"0:00:02.697869  <- Downloading files elapsed time\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196371, 46)\n",
      "CPU times: user 1.62 s, sys: 1 s, total: 2.62 s\n",
      "Wall time: 3.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_meta_subs = LoadSubredditsGCS(\n",
    "    bucket_name=cfg_v050_text_and_meta.config_dict['bucket_name'],\n",
    "    gcs_path=cfg_v050_text_and_meta.config_dict['folder_subreddits_text_and_meta'],\n",
    "    local_cache_path=path_local_cache_,\n",
    "    df_format='pandas',\n",
    "    unique_check=False,\n",
    ").read_as_one_df()\n",
    "\n",
    "print(df_meta_subs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a62f4391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 196371 entries, 0 to 196370\n",
      "Data columns (total 46 columns):\n",
      " #   Column                                    Non-Null Count   Dtype  \n",
      "---  ------                                    --------------   -----  \n",
      " 0   i18n_type                                 163 non-null     object \n",
      " 1   subreddit_id                              196371 non-null  object \n",
      " 2   subreddit_name                            196371 non-null  object \n",
      " 3   subreddit_seed_for_clusters               196371 non-null  bool   \n",
      " 4   geo_relevant_country_count                36710 non-null   float64\n",
      " 5   geo_relevant_countries                    36710 non-null   object \n",
      " 6   geo_relevant_country_codes                36710 non-null   object \n",
      " 7   users_l7                                  196371 non-null  int64  \n",
      " 8   posts_not_removed_l28                     196371 non-null  int64  \n",
      " 9   subscribers                               196371 non-null  int64  \n",
      " 10  over_18                                   77560 non-null   object \n",
      " 11  rating_short                              89289 non-null   object \n",
      " 12  primary_topic                             84193 non-null   object \n",
      " 13  rating_name                               89289 non-null   object \n",
      " 14  allow_discovery                           13454 non-null   object \n",
      " 15  allow_top                                 194704 non-null  object \n",
      " 16  allow_trending                            52 non-null      object \n",
      " 17  video_whitelisted                         2506 non-null    object \n",
      " 18  whitelist_status                          51029 non-null   object \n",
      " 19  subreddit_language                        196371 non-null  object \n",
      " 20  posts_l7_submitted                        180276 non-null  float64\n",
      " 21  unique_posters_l7_submitted               180276 non-null  float64\n",
      " 22  activity_7_day                            196371 non-null  int64  \n",
      " 23  submits_7_day                             196371 non-null  int64  \n",
      " 24  comments_7_day                            196371 non-null  int64  \n",
      " 25  active                                    196371 non-null  bool   \n",
      " 26  highly_active                             196371 non-null  bool   \n",
      " 27  weekly_consumes                           140698 non-null  float64\n",
      " 28  weekly_consumes_bucket                    140698 non-null  object \n",
      " 29  verdict                                   3385 non-null    object \n",
      " 30  is_spam                                   196371 non-null  bool   \n",
      " 31  is_deleted                                196371 non-null  bool   \n",
      " 32  deleted                                   0 non-null       object \n",
      " 33  type                                      196371 non-null  object \n",
      " 34  pt                                        196371 non-null  object \n",
      " 35  successful_post_start_date                196371 non-null  object \n",
      " 36  subreddit_title                           196371 non-null  object \n",
      " 37  subreddit_public_description              154525 non-null  object \n",
      " 38  subreddits_in_descriptions                39765 non-null   object \n",
      " 39  subreddit_meta_for_embeddings_len         196371 non-null  int64  \n",
      " 40  subreddit_meta_for_embeddings_word_count  196371 non-null  int64  \n",
      " 41  description_equals_public_desc            101501 non-null  object \n",
      " 42  mature_themes_word_count                  196371 non-null  int64  \n",
      " 43  mature_themes_deduped_text                152143 non-null  object \n",
      " 44  subreddit_description                     106469 non-null  object \n",
      " 45  subreddit_meta_for_embeddings             196371 non-null  object \n",
      "dtypes: bool(5), float64(4), int64(9), object(28)\n",
      "memory usage: 62.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_meta_subs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9dc624e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_42c84_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >dtype</th>        <th class=\"col_heading level0 col1\" >count</th>        <th class=\"col_heading level0 col2\" >unique</th>        <th class=\"col_heading level0 col3\" >unique-percent</th>        <th class=\"col_heading level0 col4\" >null-count</th>        <th class=\"col_heading level0 col5\" >null-percent</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_42c84_level0_row0\" class=\"row_heading level0 row0\" >pt</th>\n",
       "                        <td id=\"T_42c84_row0_col0\" class=\"data row0 col0\" >object</td>\n",
       "                        <td id=\"T_42c84_row0_col1\" class=\"data row0 col1\" >196,371</td>\n",
       "                        <td id=\"T_42c84_row0_col2\" class=\"data row0 col2\" >1</td>\n",
       "                        <td id=\"T_42c84_row0_col3\" class=\"data row0 col3\" >0.00%</td>\n",
       "                        <td id=\"T_42c84_row0_col4\" class=\"data row0 col4\" >0</td>\n",
       "                        <td id=\"T_42c84_row0_col5\" class=\"data row0 col5\" >0.00%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_42c84_level0_row1\" class=\"row_heading level0 row1\" >successful_post_start_date</th>\n",
       "                        <td id=\"T_42c84_row1_col0\" class=\"data row1 col0\" >object</td>\n",
       "                        <td id=\"T_42c84_row1_col1\" class=\"data row1 col1\" >196,371</td>\n",
       "                        <td id=\"T_42c84_row1_col2\" class=\"data row1 col2\" >1</td>\n",
       "                        <td id=\"T_42c84_row1_col3\" class=\"data row1 col3\" >0.00%</td>\n",
       "                        <td id=\"T_42c84_row1_col4\" class=\"data row1 col4\" >0</td>\n",
       "                        <td id=\"T_42c84_row1_col5\" class=\"data row1 col5\" >0.00%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f72b4d44c10>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_dt_cols = [\n",
    "    'pt',\n",
    "    'successful_post_start_date'\n",
    "]\n",
    "counts_describe(df_meta_subs[l_dt_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b302e18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pt</th>\n",
       "      <th>successful_post_start_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>2022-05-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>2022-05-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>2022-05-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>2022-05-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>2022-05-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pt successful_post_start_date\n",
       "0  2022-06-27                 2022-05-29\n",
       "1  2022-06-27                 2022-05-29\n",
       "2  2022-06-27                 2022-05-29\n",
       "3  2022-06-27                 2022-05-29\n",
       "4  2022-06-27                 2022-05-29"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta_subs[l_dt_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbe1d0a",
   "metadata": {},
   "source": [
    "## Read post+comments combined text\n",
    "This is the data that was used to create the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c2e1adfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:24:24 | INFO | \"  Local folder to download artifact(s):\n",
      "  /home/jupyter/subreddit_clustering_i18n/data/local_cache/i18n-subreddit-clustering/i18n_topic_model_batch/runs/20220629/post_and_comment_text_combined/text_subreddit_seeds\"\n",
      "21:24:24 | INFO | \"  74 <- Files matching prefix\"\n",
      "21:24:24 | INFO | \"  74 <- Files to check\"\n",
      "21:25:34 | INFO | \"  Files already cached: 0\"\n",
      "21:25:34 | INFO | \"0:01:11.680874  <- Downloading files elapsed time\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16360314, 8)\n",
      "CPU times: user 1min 52s, sys: 1min 13s, total: 3min 5s\n",
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_pc_combined  = LoadSubredditsGCS(\n",
    "    bucket_name=cfg_v050_text_and_meta.config_dict['bucket_name'],\n",
    "    gcs_path=cfg_v050_text_and_meta.config_dict['folder_post_and_comment_text_and_meta'],\n",
    "    local_cache_path=path_local_cache_,\n",
    "    df_format='pandas',\n",
    "    unique_check=False,\n",
    ").read_as_one_df()\n",
    "\n",
    "print(df_pc_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6c9421ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16360314 entries, 0 to 643615\n",
      "Data columns (total 8 columns):\n",
      " #   Column                           Dtype  \n",
      "---  ------                           -----  \n",
      " 0   subreddit_seed_for_clusters      bool   \n",
      " 1   subreddit_id                     object \n",
      " 2   subreddit_name                   object \n",
      " 3   post_id                          object \n",
      " 4   net_upvotes_lookup               int64  \n",
      " 5   comment_for_embedding_count      float64\n",
      " 6   post_and_comment_text_clean_len  int64  \n",
      " 7   post_and_comment_text_clean      object \n",
      "dtypes: bool(1), float64(1), int64(2), object(4)\n",
      "memory usage: 1014.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_pc_combined.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4316990e",
   "metadata": {},
   "source": [
    "# Compare subreddit meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0bab1d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:28:22 | INFO | \"  Local folder to download artifact(s):\n",
      "  /home/jupyter/subreddit_clustering_i18n/data/local_cache/i18n-subreddit-clustering/i18n_topic_model_batch/runs/20220707/subreddits/text\"\n",
      "21:28:22 | INFO | \"  1 <- Files matching prefix\"\n",
      "21:28:22 | INFO | \"  1 <- Files to check\"\n",
      "21:28:24 | INFO | \"  Files already cached: 0\"\n",
      "21:28:24 | INFO | \"0:00:04.129538  <- Downloading files elapsed time\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(202889, 46)\n",
      "CPU times: user 1.7 s, sys: 1.29 s, total: 2.99 s\n",
      "Wall time: 4.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_meta_subs_alt = LoadSubredditsGCS(\n",
    "    bucket_name=cfg_v050_text_and_meta.config_dict['bucket_name'],\n",
    "    gcs_path=cfg_v050_text_and_meta.config_dict['folder_subreddits_text_and_meta_alt'],\n",
    "    local_cache_path=path_local_cache_,\n",
    "    df_format='pandas',\n",
    "    unique_check=False,\n",
    ").read_as_one_df()\n",
    "\n",
    "print(df_meta_subs_alt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ca96f3",
   "metadata": {},
   "source": [
    "## Compare subreddit meta for new run & old run\n",
    "\n",
    "Looks like the new run contains more subreddits. Maybe there were more posts created around the datetime cut-off last time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "88109a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202889, 46)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta_subs_alt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f17493df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196371, 46)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta_subs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4aaa407f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta_subs_alt.equals(df_meta_subs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb350e1",
   "metadata": {},
   "source": [
    "### What's overlap between new & old run?\n",
    "\n",
    "Looks like over 6k subreddits are in the new, but not the old.\n",
    "Unclear if there was a rating change or something else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "40067424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  196,371 <- old\n",
      "  202,889 <- new\n",
      "  202,889 <- old + new\n",
      "        0 <- old_only\n",
      "  196,371 <- old_and_new\n",
      "    6,518 <- new_only\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['old_only', 'old_and_new', 'new_only'])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_v_subs = get_venn_sets2(\n",
    "    df_meta_subs['subreddit_id'].unique(),\n",
    "    df_meta_subs_alt['subreddit_id'].unique(),\n",
    "    a_name='old',\n",
    "    b_name='new',\n",
    ")\n",
    "d_v_subs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "be6ed3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115, 46)\n"
     ]
    }
   ],
   "source": [
    "df_meta_subs_explore = df_meta_subs_alt[\n",
    "    (df_meta_subs_alt['subreddit_id'].isin(d_v_subs['new_only'])) &\n",
    "    (df_meta_subs_alt['posts_not_removed_l28'] >= 5) &\n",
    "    (df_meta_subs_alt['subscribers'] >= 5)\n",
    "]\n",
    "print(df_meta_subs_explore.shape)\n",
    "# df_meta_subs_explore.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928bffe2",
   "metadata": {},
   "source": [
    "### Let's check diff for only the seed subreddits\n",
    "Since these are the most important ones for the model.\n",
    "\n",
    "The good news is that the new run includes more subreddits and is not missing any of the old ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d18425d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_5c479_row0_col1,#T_5c479_row1_col2{\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#95cff5 100.0%, transparent 100.0%);\n",
       "        }#T_5c479_row0_col2,#T_5c479_row1_col1{\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }</style><table id=\"T_5c479_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >subreddit_seed_for_clusters-count</th>        <th class=\"col_heading level0 col1\" >subreddit_seed_for_clusters-percent</th>        <th class=\"col_heading level0 col2\" >subreddit_seed_for_clusters-pct_cumulative_sum</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_5c479_level0_row0\" class=\"row_heading level0 row0\" >False</th>\n",
       "                        <td id=\"T_5c479_row0_col0\" class=\"data row0 col0\" >114,397</td>\n",
       "                        <td id=\"T_5c479_row0_col1\" class=\"data row0 col1\" >58.3%</td>\n",
       "                        <td id=\"T_5c479_row0_col2\" class=\"data row0 col2\" >58.3%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5c479_level0_row1\" class=\"row_heading level0 row1\" >True</th>\n",
       "                        <td id=\"T_5c479_row1_col0\" class=\"data row1 col0\" >81,974</td>\n",
       "                        <td id=\"T_5c479_row1_col1\" class=\"data row1 col1\" >41.7%</td>\n",
       "                        <td id=\"T_5c479_row1_col2\" class=\"data row1 col2\" >100.0%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f68543b0990>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_counts_and_pcts(\n",
    "    df_meta_subs['subreddit_seed_for_clusters']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2c4ea426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_22d32_row0_col1,#T_22d32_row1_col2{\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#95cff5 100.0%, transparent 100.0%);\n",
       "        }#T_22d32_row0_col2,#T_22d32_row1_col1{\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }</style><table id=\"T_22d32_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >subreddit_seed_for_clusters-count</th>        <th class=\"col_heading level0 col1\" >subreddit_seed_for_clusters-percent</th>        <th class=\"col_heading level0 col2\" >subreddit_seed_for_clusters-pct_cumulative_sum</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_22d32_level0_row0\" class=\"row_heading level0 row0\" >False</th>\n",
       "                        <td id=\"T_22d32_row0_col0\" class=\"data row0 col0\" >119,939</td>\n",
       "                        <td id=\"T_22d32_row0_col1\" class=\"data row0 col1\" >59.1%</td>\n",
       "                        <td id=\"T_22d32_row0_col2\" class=\"data row0 col2\" >59.1%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_22d32_level0_row1\" class=\"row_heading level0 row1\" >True</th>\n",
       "                        <td id=\"T_22d32_row1_col0\" class=\"data row1 col0\" >82,950</td>\n",
       "                        <td id=\"T_22d32_row1_col1\" class=\"data row1 col1\" >40.9%</td>\n",
       "                        <td id=\"T_22d32_row1_col2\" class=\"data row1 col2\" >100.0%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f73b8f7b510>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_counts_and_pcts(\n",
    "    df_meta_subs_alt['subreddit_seed_for_clusters']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5f654a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   81,974 <- old\n",
      "   82,950 <- new\n",
      "   82,950 <- old + new\n",
      "        0 <- old_only\n",
      "   81,974 <- old_and_new\n",
      "      976 <- new_only\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['old_only', 'old_and_new', 'new_only'])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_seed_subs_ = df_meta_subs['subreddit_seed_for_clusters'] == True \n",
    "mask_seed_subs_alt_ = df_meta_subs_alt['subreddit_seed_for_clusters'] == True\n",
    "\n",
    "d_v_subs_seeds = get_venn_sets2(\n",
    "    df_meta_subs[mask_seed_subs_]['subreddit_id'].unique(),\n",
    "    df_meta_subs_alt[mask_seed_subs_alt_]['subreddit_id'].unique(),\n",
    "    a_name='old',\n",
    "    b_name='new',\n",
    ")\n",
    "d_v_subs_seeds.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd7c190",
   "metadata": {},
   "source": [
    "# Compare post+comments files\n",
    "The text could be slightly different (e.g., new comments), but at least we should be looking at 99%+ of the same post-IDs b/c we need the metadata to filter NSFW for indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ccf17fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:58:35 | INFO | \"  Local folder to download artifact(s):\n",
      "  /home/jupyter/subreddit_clustering_i18n/data/local_cache/i18n-subreddit-clustering/i18n_topic_model_batch/runs/20220707/post_and_comment_text_combined/text_subreddit_seeds\"\n",
      "21:58:35 | INFO | \"  36 <- Files matching prefix\"\n",
      "21:58:35 | INFO | \"  36 <- Files to check\"\n",
      "21:59:50 | INFO | \"  Files already cached: 0\"\n",
      "21:59:50 | INFO | \"0:01:16.524619  <- Downloading files elapsed time\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16874763, 8)\n",
      "CPU times: user 2min, sys: 1min 22s, total: 3min 23s\n",
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_pc_combined_alt  = LoadSubredditsGCS(\n",
    "    bucket_name=cfg_v050_text_and_meta.config_dict['bucket_name'],\n",
    "    gcs_path=cfg_v050_text_and_meta.config_dict['folder_post_and_comment_text_and_meta_alt'],\n",
    "    local_cache_path=path_local_cache_,\n",
    "    df_format='pandas',\n",
    "    unique_check=False,\n",
    ").read_as_one_df()\n",
    "\n",
    "print(df_pc_combined_alt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95200eb2",
   "metadata": {},
   "source": [
    "## Compare post+comments IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ea51fa31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16874763, 8)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pc_combined_alt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "90d8e22b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16360314, 8)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pc_combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639a228f",
   "metadata": {},
   "source": [
    "### What's overlap between new & old run?\n",
    "\n",
    "For our use cases, it's ok for the new run to include more posts.\n",
    "\n",
    "However, it looks like there are 200k posts that are not in the new post+text table... hmmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "832de97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16,360,314 <- old\n",
      "16,874,763 <- new\n",
      "17,081,905 <- old + new\n",
      "  207,142 <- old_only\n",
      "16,153,172 <- old_and_new\n",
      "  721,591 <- new_only\n",
      "CPU times: user 1min 7s, sys: 1.86 s, total: 1min 9s\n",
      "Wall time: 1min 9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['old_only', 'old_and_new', 'new_only'])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "d_v_pc = get_venn_sets2(\n",
    "    df_pc_combined['post_id'].unique(),\n",
    "    df_pc_combined_alt['post_id'].unique(),\n",
    "    a_name='old',\n",
    "    b_name='new',\n",
    ")\n",
    "d_v_pc.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8326522",
   "metadata": {},
   "source": [
    "## Read posts meta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2eb8b516",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:08:01 | INFO | \"  Local folder to download artifact(s):\n",
      "  /home/jupyter/subreddit_clustering_i18n/data/local_cache/i18n-subreddit-clustering/i18n_topic_model_batch/runs/20220707/posts\"\n",
      "22:08:01 | INFO | \"  75 <- Files matching prefix\"\n",
      "22:08:01 | INFO | \"  75 <- Files to check\"\n",
      "22:10:10 | INFO | \"  Files already cached: 0\"\n",
      "22:10:10 | INFO | \"0:02:11.730905  <- Downloading files elapsed time\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17735766, 46)\n",
      "CPU times: user 4min 8s, sys: 2min 34s, total: 6min 42s\n",
      "Wall time: 3min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_posts  = LoadSubredditsGCS(\n",
    "    bucket_name=cfg_v050_text_and_meta.config_dict['bucket_name'],\n",
    "    gcs_path=cfg_v050_text_and_meta.config_dict['folder_posts_text_and_meta'],\n",
    "    local_cache_path=path_local_cache_,\n",
    "    df_format='pandas',\n",
    "    unique_check=False,\n",
    ").read_as_one_df()\n",
    "\n",
    "print(df_posts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "42372a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 17735766 entries, 0 to 280378\n",
      "Data columns (total 46 columns):\n",
      " #   Column                                      Dtype         \n",
      "---  ------                                      -----         \n",
      " 0   rank_post_in_sub                            int64         \n",
      " 1   subreddit_id                                object        \n",
      " 2   subreddit_name                              object        \n",
      " 3   post_id                                     object        \n",
      " 4   user_id                                     object        \n",
      " 5   submit_date                                 object        \n",
      " 6   endpoint_timestamp                          datetime64[ns]\n",
      " 7   geo_country_code                            object        \n",
      " 8   is_deleted                                  int64         \n",
      " 9   removed                                     int64         \n",
      " 10  neutered                                    bool          \n",
      " 11  content_category                            object        \n",
      " 12  upvotes_lookup                              int64         \n",
      " 13  downvotes_lookup                            int64         \n",
      " 14  net_upvotes_lookup                          int64         \n",
      " 15  upvotes                                     int64         \n",
      " 16  comments                                    int64         \n",
      " 17  successful                                  int64         \n",
      " 18  app_name                                    object        \n",
      " 19  post_type                                   object        \n",
      " 20  post_nsfw                                   object        \n",
      " 21  weighted_language                           object        \n",
      " 22  weighted_language_probability               float64       \n",
      " 23  post_language_preference                    object        \n",
      " 24  ocr_images_in_post_count                    float64       \n",
      " 25  ocr_text_clean_len                          float64       \n",
      " 26  ocr_text_word_count                         float64       \n",
      " 27  post_url                                    object        \n",
      " 28  post_url_path_raw                           object        \n",
      " 29  post_url_domain                             object        \n",
      " 30  post_url_path_to_concat_word_count          float64       \n",
      " 31  post_url_to_concat                          object        \n",
      " 32  post_url_for_standalone_embedding           object        \n",
      " 33  post_title_and_body_text_raw_same_as_clean  object        \n",
      " 34  post_title_and_body_text_clean_len          float64       \n",
      " 35  post_title_and_body_text_clean_word_count   float64       \n",
      " 36  flair_text                                  object        \n",
      " 37  flair_text_clean                            object        \n",
      " 38  post_title_and_body_text                    object        \n",
      " 39  post_title_and_body_text_clean              object        \n",
      " 40  sexually_explicit_image_pred_text           object        \n",
      " 41  post_text_for_embeddings                    object        \n",
      " 42  ocr_inferred_text_agg_clean                 object        \n",
      " 43  ocr_inferred_text_agg                       object        \n",
      " 44  post_text_for_embeddings_len                int64         \n",
      " 45  end_date                                    object        \n",
      "dtypes: bool(1), datetime64[ns](1), float64(7), int64(10), object(27)\n",
      "memory usage: 6.1+ GB\n"
     ]
    }
   ],
   "source": [
    "df_posts.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632b2b44",
   "metadata": {},
   "source": [
    "### It's possible that maybe posts didn't make the cutoff based on text length\n",
    "Maybe we still have the metadata in the post-only table??\n",
    "\n",
    "But in reality, there are still ~200k posts without text or meta in the new table... maybe they got removed/neutered/deleted since last time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8baf6217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16,360,314 <- pc_old\n",
      " 17,735,766 <- posts_new\n",
      " 17,942,903 <- pc_old + posts_new\n",
      "    207,137 <- pc_old_only\n",
      " 16,153,177 <- pc_old_and_posts_new\n",
      "  1,582,589 <- posts_new_only\n",
      "CPU times: user 1min 8s, sys: 2.76 s, total: 1min 10s\n",
      "Wall time: 1min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['pc_old_only', 'pc_old_and_posts_new', 'posts_new_only'])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "d_v_post_v_pc = get_venn_sets2(\n",
    "    df_pc_combined['post_id'].unique(),\n",
    "    df_posts['post_id'].unique(),\n",
    "    a_name='pc_old',\n",
    "    b_name='posts_new',\n",
    ")\n",
    "d_v_post_v_pc.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6ae31fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16,360,314 <- pc_old\n",
      " 17,735,766 <- posts_new\n",
      " 17,942,903 <- pc_old + posts_new\n",
      "    207,137 <- pc_old_only\n",
      " 16,153,177 <- pc_old_and_posts_new\n",
      "  1,582,589 <- posts_new_only\n",
      "CPU times: user 1min 8s, sys: 2.76 s, total: 1min 10s\n",
      "Wall time: 1min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['pc_old_only', 'pc_old_and_posts_new', 'posts_new_only'])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "d_v_post_v_pc = get_venn_sets2(\n",
    "    df_pc_combined['post_id'].unique(),\n",
    "    df_posts['post_id'].unique(),\n",
    "    a_name='pc_old',\n",
    "    b_name='posts_new',\n",
    ")\n",
    "d_v_post_v_pc.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac18308",
   "metadata": {},
   "source": [
    "\n",
    "## Read comments meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3a60594",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TODO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-2494f9b4f745>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'TODO' is not defined"
     ]
    }
   ],
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86994c92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m65"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
