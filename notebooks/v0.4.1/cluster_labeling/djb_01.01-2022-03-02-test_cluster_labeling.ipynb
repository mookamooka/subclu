{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb1b6965",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "2022-03\n",
    "One of the big challenges in using the current clusters is that they don't have names, only IDs. Not having labels (besides the generic primary topic) makes it harder for people to understand and use them.\n",
    "\n",
    "In this notebook we'll try a baseline TF-IDF approach to create cluster labels.  We could use them during QA and/or during curation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1459a885",
   "metadata": {},
   "source": [
    "# Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e24f9d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2debac2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\t\tv 3.7.10\n",
      "===\n",
      "hydra\t\tv: 1.1.0\n",
      "numpy\t\tv: 1.19.5\n",
      "pandas\t\tv: 1.2.4\n",
      "plotly\t\tv: 4.14.3\n",
      "seaborn\t\tv: 0.11.1\n",
      "subclu\t\tv: 0.4.1\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "import mlflow\n",
    "import hydra\n",
    "\n",
    "import subclu\n",
    "from subclu.eda.aggregates import compare_raw_v_weighted_language\n",
    "from subclu.utils import set_working_directory, get_project_subfolder\n",
    "from subclu.utils.eda import (\n",
    "    setup_logging, counts_describe, value_counts_and_pcts,\n",
    "    notebook_display_config, print_lib_versions,\n",
    "    style_df_numeric, reorder_array,\n",
    ")\n",
    "from subclu.utils.mlflow_logger import MlflowLogger\n",
    "from subclu.utils.hydra_config_loader import LoadHydraConfig\n",
    "from subclu.utils.data_irl_style import (\n",
    "    get_colormap, theme_dirl, \n",
    "    get_color_dict, base_colors_for_manual_labels,\n",
    "    check_colors_used,\n",
    ")\n",
    "from subclu.data.data_loaders import LoadPosts, LoadSubreddits, create_sub_level_aggregates\n",
    "\n",
    "\n",
    "# ===\n",
    "# imports specific to this notebook\n",
    "\n",
    "\n",
    "\n",
    "print_lib_versions([hydra, np, pd, plotly, sns, subclu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e21669e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.dates as mdates\n",
    "plt.style.use('default')\n",
    "\n",
    "setup_logging()\n",
    "notebook_display_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4502374f",
   "metadata": {},
   "source": [
    "# Set sqlite database as MLflow URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d33b3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sqlite:////home/jupyter/subreddit_clustering_i18n/mlflow_sync/djb-100-2021-04-28-djb-eda-german-subs/mlruns.db'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use new class to initialize mlflow\n",
    "mlf = MlflowLogger(tracking_uri='sqlite')\n",
    "mlflow.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818ee25a",
   "metadata": {},
   "source": [
    "## Get list of experiments with new function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7f008fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>name</th>\n",
       "      <th>artifact_location</th>\n",
       "      <th>lifecycle_stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>v0.4.0_use_multi_clustering_test</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/17</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>v0.4.0_use_multi_clustering</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/18</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>v0.4.1_mUSE_inference_test</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/19</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>v0.4.1_mUSE_inference</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/20</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>v0.4.1_mUSE_aggregates_test</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/21</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>v0.4.1_mUSE_aggregates</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/22</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>v0.4.1_mUSE_clustering_test</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/23</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>v0.4.1_mUSE_clustering</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/24</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>v0.4.1_mUSE_clustering_new_metrics</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/25</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   experiment_id                                name                                artifact_location lifecycle_stage\n",
       "17            17    v0.4.0_use_multi_clustering_test  gs://i18n-subreddit-clustering/mlflow/mlruns/17          active\n",
       "18            18         v0.4.0_use_multi_clustering  gs://i18n-subreddit-clustering/mlflow/mlruns/18          active\n",
       "19            19          v0.4.1_mUSE_inference_test  gs://i18n-subreddit-clustering/mlflow/mlruns/19          active\n",
       "20            20               v0.4.1_mUSE_inference  gs://i18n-subreddit-clustering/mlflow/mlruns/20          active\n",
       "21            21         v0.4.1_mUSE_aggregates_test  gs://i18n-subreddit-clustering/mlflow/mlruns/21          active\n",
       "22            22              v0.4.1_mUSE_aggregates  gs://i18n-subreddit-clustering/mlflow/mlruns/22          active\n",
       "23            23         v0.4.1_mUSE_clustering_test  gs://i18n-subreddit-clustering/mlflow/mlruns/23          active\n",
       "24            24              v0.4.1_mUSE_clustering  gs://i18n-subreddit-clustering/mlflow/mlruns/24          active\n",
       "25            25  v0.4.1_mUSE_clustering_new_metrics  gs://i18n-subreddit-clustering/mlflow/mlruns/25          active"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlf.list_experiment_meta(output_format='pandas').tail(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ac4294",
   "metadata": {},
   "source": [
    "## Get experiment ID's for models to check\n",
    "\n",
    "experiment ID 25 as the latest runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b346348a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.39 s, sys: 72.6 ms, total: 1.46 s\n",
      "Wall time: 1.46 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(132, 273)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_mlf = mlf.search_all_runs(experiment_ids=[25])\n",
    "df_mlf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e8e397d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>status</th>\n",
       "      <th>artifact_uri</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>metrics.primary_topic-2700_to_3000-f1_score-macro_avg</th>\n",
       "      <th>metrics.primary_topic-0250_to_0500-recall-weighted_avg</th>\n",
       "      <th>metrics.optimal_k-0010_to_0020</th>\n",
       "      <th>metrics.primary_topic-0750_to_1000-adjusted_rand_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a6ee2f75491d4449a05fad502d7b80c3</td>\n",
       "      <td>25</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/25/a6ee2f75491d4449a05fad502d7b80c3/artifacts</td>\n",
       "      <td>2022-01-20 19:50:19.553000+00:00</td>\n",
       "      <td>2022-01-20 19:54:40.237000+00:00</td>\n",
       "      <td>0.150180</td>\n",
       "      <td>0.398119</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.375685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4b246da72d254bf9888962d483ed49a3</td>\n",
       "      <td>25</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/25/4b246da72d254bf9888962d483ed49a3/artifacts</td>\n",
       "      <td>2022-01-20 19:49:26.745000+00:00</td>\n",
       "      <td>2022-01-20 20:02:40.384000+00:00</td>\n",
       "      <td>0.478527</td>\n",
       "      <td>0.268315</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.036430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>619e29db458a43e6ac726eac7145db89</td>\n",
       "      <td>25</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/25/619e29db458a43e6ac726eac7145db89/artifacts</td>\n",
       "      <td>2022-01-20 19:49:09.043000+00:00</td>\n",
       "      <td>2022-01-20 19:53:31.024000+00:00</td>\n",
       "      <td>0.154790</td>\n",
       "      <td>0.400613</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.384005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25c5dfaa03d34da88fdfb3a1850d7d44</td>\n",
       "      <td>25</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/25/25c5dfaa03d34da88fdfb3a1850d7d44/artifacts</td>\n",
       "      <td>2022-01-20 19:48:44.509000+00:00</td>\n",
       "      <td>2022-01-20 20:02:25.618000+00:00</td>\n",
       "      <td>0.471462</td>\n",
       "      <td>0.268139</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.012955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b29776a461994e00b00139ec1bb6270b</td>\n",
       "      <td>25</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/25/b29776a461994e00b00139ec1bb6270b/artifacts</td>\n",
       "      <td>2022-01-20 19:46:49.578000+00:00</td>\n",
       "      <td>2022-01-20 19:51:15.689000+00:00</td>\n",
       "      <td>0.145046</td>\n",
       "      <td>0.398264</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.382473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             run_id experiment_id    status                                                                                artifact_uri                       start_time                         end_time  metrics.primary_topic-2700_to_3000-f1_score-macro_avg  \\\n",
       "0  a6ee2f75491d4449a05fad502d7b80c3            25  FINISHED  gs://i18n-subreddit-clustering/mlflow/mlruns/25/a6ee2f75491d4449a05fad502d7b80c3/artifacts 2022-01-20 19:50:19.553000+00:00 2022-01-20 19:54:40.237000+00:00                                               0.150180   \n",
       "1  4b246da72d254bf9888962d483ed49a3            25  FINISHED  gs://i18n-subreddit-clustering/mlflow/mlruns/25/4b246da72d254bf9888962d483ed49a3/artifacts 2022-01-20 19:49:26.745000+00:00 2022-01-20 20:02:40.384000+00:00                                               0.478527   \n",
       "2  619e29db458a43e6ac726eac7145db89            25  FINISHED  gs://i18n-subreddit-clustering/mlflow/mlruns/25/619e29db458a43e6ac726eac7145db89/artifacts 2022-01-20 19:49:09.043000+00:00 2022-01-20 19:53:31.024000+00:00                                               0.154790   \n",
       "3  25c5dfaa03d34da88fdfb3a1850d7d44            25  FINISHED  gs://i18n-subreddit-clustering/mlflow/mlruns/25/25c5dfaa03d34da88fdfb3a1850d7d44/artifacts 2022-01-20 19:48:44.509000+00:00 2022-01-20 20:02:25.618000+00:00                                               0.471462   \n",
       "4  b29776a461994e00b00139ec1bb6270b            25  FINISHED  gs://i18n-subreddit-clustering/mlflow/mlruns/25/b29776a461994e00b00139ec1bb6270b/artifacts 2022-01-20 19:46:49.578000+00:00 2022-01-20 19:51:15.689000+00:00                                               0.145046   \n",
       "\n",
       "   metrics.primary_topic-0250_to_0500-recall-weighted_avg  metrics.optimal_k-0010_to_0020  metrics.primary_topic-0750_to_1000-adjusted_rand_score  \n",
       "0                                                0.398119                            11.0                                                0.375685  \n",
       "1                                                0.268315                            14.0                                                0.036430  \n",
       "2                                                0.400613                            10.0                                                0.384005  \n",
       "3                                                0.268139                            14.0                                                0.012955  \n",
       "4                                                0.398264                            17.0                                                0.382473  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlf.iloc[:5, :10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ff94fd",
   "metadata": {},
   "source": [
    "# Load labels from selected model\n",
    "This run was selected for model v0.4.1, so let's use its labels for our analysis\n",
    "\n",
    "`e37b0a2c3af54c588818e7efdde15df5`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a892bd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:56:43 | INFO | \"    93 <- Artifacts clean count\"\n",
      "18:56:43 | INFO | \"    12 <- Artifacts & folders at TOP LEVEL clean count\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['X_linkage',\n",
       " 'clustering.log',\n",
       " 'clustering_model',\n",
       " 'config',\n",
       " 'df_accel',\n",
       " 'df_classification_reports',\n",
       " 'df_labels',\n",
       " 'df_supervised_metrics',\n",
       " 'figures',\n",
       " 'hydra',\n",
       " 'optimal_ks',\n",
       " 'pipeline_params']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_uuid = 'e37b0a2c3af54c588818e7efdde15df5'\n",
    "mlf.list_run_artifacts(model_uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d637185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mmlf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_run_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrun_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0martifact_folder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0martifact_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mexperiment_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mread_function\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;32min\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'pd_parquet'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;32min\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcache_locally\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlocal_path_root\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/jupyter/subreddit_clustering_i18n/data/local_cache/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_sample_files\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mread_csv_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Example:\n",
       "df_v_sub = (\n",
       "    pd.read_parquet(f\"{artifact_uri}/{folder_vect_subs}\")\n",
       ")\n",
       "artifact_file:\n",
       "    if you only want to read a single file in the artifact_folder, pass this value\n",
       "\n",
       "WARNING! if a folder name is a subset of another name, it's possible that\n",
       "GCS will return files that are in the other similar folders.\n",
       "TODO(djb) Create a check to make sure that the parent of each file matches\n",
       " the input folder WITHOUT FUZZY MATCHES\n",
       "Example input: df_sub_level__sub_desc_similarity\n",
       " output will include:\n",
       "      - df_sub_level__sub_desc_similarity (expected)\n",
       "      - df_sub_level__sub_desc_similarity_pair (DO NOT WANT!)\n",
       "\u001b[0;31mFile:\u001b[0m      /home/david.bermejo/repos/subreddit_clustering_i18n/subclu/utils/mlflow_logger.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?mlf.read_run_artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96d5a687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:59:36 | INFO | \"Local folder to download artifact(s):\n",
      "  /home/jupyter/subreddit_clustering_i18n/data/local_cache/mlflow/mlruns/25/e37b0a2c3af54c588818e7efdde15df5/artifacts/df_labels\"\n",
      "100%|##########################################| 2/2 [00:00<00:00, 10034.22it/s]\n",
      "18:59:36 | INFO | \"  Parquet files found:     1\"\n",
      "18:59:36 | INFO | \"  Parquet files to use:     1\"\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jupyter/subreddit_clustering_i18n/data/local_cache/mlflow/mlruns/25/e37b0a2c3af54c588818e7efdde15df5/artifacts/df_labels/*.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/home/david.bermejo/repos/subreddit_clustering_i18n/subclu/utils/mlflow_logger.py\u001b[0m in \u001b[0;36mread_run_artifact\u001b[0;34m(self, run_id, artifact_folder, artifact_file, experiment_ids, read_function, columns, cache_locally, local_path_root, n_sample_files, verbose, read_csv_kwargs)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 return read_function(path_to_load,\n\u001b[0;32m--> 575\u001b[0;31m                                      columns=columns)\n\u001b[0m\u001b[1;32m    576\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[1;32m    459\u001b[0m     return impl.read(\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_nullable_dtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_nullable_dtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m     )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m             return self.api.parquet.read_table(\n\u001b[0;32m--> 222\u001b[0;31m                 \u001b[0mpath_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m             ).to_pandas(**to_pandas_kwargs)\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyarrow/parquet.py\u001b[0m in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, metadata, use_pandas_metadata, memory_map, read_dictionary, filesystem, filters, buffer_size, partitioning, use_legacy_dataset, ignore_prefixes)\u001b[0m\n\u001b[1;32m   1679\u001b[0m                 \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1680\u001b[0;31m                 \u001b[0mignore_prefixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_prefixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1681\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyarrow/parquet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_paths, filesystem, filters, partitioning, read_dictionary, buffer_size, memory_map, ignore_prefixes, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m                                    \u001b[0mpartitioning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1535\u001b[0;31m                                    ignore_prefixes=ignore_prefixes)\n\u001b[0m\u001b[1;32m   1536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyarrow/dataset.py\u001b[0m in \u001b[0;36mdataset\u001b[0;34m(source, schema, format, filesystem, partitioning, partition_base_dir, exclude_invalid_files, ignore_prefixes)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_filesystem_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyarrow/dataset.py\u001b[0m in \u001b[0;36m_filesystem_dataset\u001b[0;34m(source, schema, filesystem, partitioning, format, partition_base_dir, exclude_invalid_files, selector_ignore_prefixes)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyarrow/_dataset.pyx\u001b[0m in \u001b[0;36mpyarrow._dataset.DatasetFactory.finish\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Could not open parquet input source '/home/jupyter/subreddit_clustering_i18n/data/local_cache/mlflow/mlruns/25/e37b0a2c3af54c588818e7efdde15df5/artifacts/df_labels/df_labels.csv': Invalid: Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c84033543734>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mrun_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_uuid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0martifact_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'df_labels'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mread_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pd_parquet'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m/home/david.bermejo/repos/subreddit_clustering_i18n/subclu/utils/mlflow_logger.py\u001b[0m in \u001b[0;36mread_run_artifact\u001b[0;34m(self, run_id, artifact_folder, artifact_file, experiment_ids, read_function, columns, cache_locally, local_path_root, n_sample_files, verbose, read_csv_kwargs)\u001b[0m\n\u001b[1;32m    581\u001b[0m                 \u001b[0;31m# so we'll append `*.parquet` to try to read parquet files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m                 return read_function(f\"{path_to_load}/*.parquet\",\n\u001b[0;32m--> 583\u001b[0;31m                                      columns=columns)\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mread_function\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0mimpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     return impl.read(\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_nullable_dtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_nullable_dtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m     )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"filesystem\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         )\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;31m# fsspec resources can also point to directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;31m# this branch is used for example when reading from non-fsspec URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mhandles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mpath_or_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jupyter/subreddit_clustering_i18n/data/local_cache/mlflow/mlruns/25/e37b0a2c3af54c588818e7efdde15df5/artifacts/df_labels/*.parquet'"
     ]
    }
   ],
   "source": [
    "df_labels = mlf.read_run_artifact(\n",
    "    run_id=model_uuid,\n",
    "    artifact_folder='df_labels',\n",
    "    read_function='pd_parquet'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00a37fb",
   "metadata": {},
   "source": [
    "# Level 1 - only subreddit metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614aa920",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
