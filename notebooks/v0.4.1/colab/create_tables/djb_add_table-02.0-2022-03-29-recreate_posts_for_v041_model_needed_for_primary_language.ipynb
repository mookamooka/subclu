{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "djb_add_table-02.0-2022-03-29-recreate_posts_for_v041_model_needed_for_primary_language.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVZuLSOgZVC8"
      },
      "source": [
        "# Purpose\n",
        "\n",
        "### 2022-03-29\n",
        "The table with posts for v0.4.1 model was deleted. We need to re-create it so that we can get primary language, which is used for counterparts logic (DE/FR/MX to English/US)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2qXnQ5IV9Z7"
      },
      "source": [
        "# Imports & notebook setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCuWmkxaGYwm"
      },
      "source": [
        "%load_ext google.colab.data_table\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tS4ktaPaGwbh",
        "outputId": "71a230e2-2b8a-45ea-ff44-7dc3dfd7cff1"
      },
      "source": [
        "# colab auth for BigQuery & google drive\n",
        "from google.colab import auth, files, drive\n",
        "import sys  # need sys for mounting gdrive path\n",
        "\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authenticated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install libraries\n",
        "\n",
        "These might be necessary to read from GCS"
      ],
      "metadata": {
        "id": "5S4vyQQrwLzC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tpp8E6Njt7_C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8dcb5f5-16c7-49e0-bf96-4c4963108c35"
      },
      "source": [
        "# # install subclu & libraries needed to read parquet files from GCS & spreadsheets\n",
        "# #  make sure to use the [colab] `extra` because it includes colab-specific libraries\n",
        "# module_path = f\"{g_drive_root}/MyDrive/Colab Notebooks/subreddit_clustering_i18n/[colab]\"\n",
        "\n",
        "!pip install fsspec gcsfs"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (2022.2.0)\n",
            "Requirement already satisfied: gcsfs in /usr/local/lib/python3.7/dist-packages (2022.2.0)\n",
            "Requirement already satisfied: aiohttp<4 in /usr/local/lib/python3.7/dist-packages (from gcsfs) (3.8.1)\n",
            "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.7/dist-packages (from gcsfs) (4.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gcsfs) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.7/dist-packages (from gcsfs) (0.4.6)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.7/dist-packages (from gcsfs) (1.18.1)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.7/dist-packages (from gcsfs) (1.35.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4->gcsfs) (0.13.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4->gcsfs) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4->gcsfs) (1.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4->gcsfs) (1.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4->gcsfs) (1.7.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4->gcsfs) (2.0.12)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4->gcsfs) (21.4.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4->gcsfs) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4->gcsfs) (3.10.0.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (4.2.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (0.2.8)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (57.4.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.4.8)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp<4->gcsfs) (2.10)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.2.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (1.24.3)\n",
            "Requirement already satisfied: google-resumable-media<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage->gcsfs) (0.4.1)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage->gcsfs) (1.0.3)\n",
            "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->gcsfs) (1.26.3)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->gcsfs) (3.17.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->gcsfs) (1.56.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->gcsfs) (21.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->gcsfs) (2018.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->gcsfs) (3.0.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## General imports"
      ],
      "metadata": {
        "id": "KN2A7TI4wY6w"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TpWbXh5mzew"
      },
      "source": [
        "# Regular Imports\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "from google.cloud import bigquery\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from matplotlib_venn import venn2_unweighted, venn3_unweighted\n",
        "\n",
        "\n",
        "# Set env variable needed by some libraries to get datay from BigQuery\n",
        "# os.environ['GOOGLE_CLOUD_PROJECT'] = 'data-science-prod-218515'\n",
        "os.environ['GOOGLE_CLOUD_PROJECT'] = 'data-prod-165221'"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load df with comments [no longer needed]\n",
        "\n",
        "Colab can't handle loading all the parque files at once, so we need to loop through each file and append them to the table.\n",
        "\n",
        "File format:\n",
        "- `000000000000.parquet`\n",
        "- ...\n",
        "- `000000000038.parquet`\n"
      ],
      "metadata": {
        "id": "aP-I3R6MxTyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "gs_posts_folder = 'gs://i18n-subreddit-clustering/posts/top/2021-12-14_fix'\n",
        "\n",
        "# try to read all files fails because colab doesn't have enough RAM to load them in memory\n",
        "# df_posts = pd.read_parquet(gs_posts)\n",
        "# print(df_posts.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIy7FW0axe-F",
        "outputId": "f52f3cea-4077-4663-c786-5897216fd8df"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 6.2 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0A2qrQ4nbFO"
      },
      "source": [
        "# Save table to BigQuery\n",
        "\n",
        "NOTE: Sorting is not guaranteed in the final BigQuery table.\n",
        "\n",
        "With `pandas`, we can \"force\" sorting if we set `chunksize` to a number smaller than the full df size.\n",
        "\n",
        "ETA with `pandas` & ~9 columns:\n",
        "batch = 10k\n",
        "- 490k sub pairs = 3:30 minutes (3.5)\n",
        "- 4.9 Million sub pairs = ~37 minutes\n",
        "\n",
        "\n",
        "ETA with `bq` and ~39 columns:\n",
        "- 15 million posts = **48 SECONDS**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BREAK"
      ],
      "metadata": {
        "id": "QTUldUEpWAkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!bq load \\\n",
        "    --source_format=PARQUET \\\n",
        "    --project_id=reddit-employee-datasets \\\n",
        "    david_bermejo.subclu_posts_top_no_geo_20211214 \\\n",
        "    gs://i18n-subreddit-clustering/posts/top/2021-12-14_fix/*.parquet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSIhyctvApRW",
        "outputId": "870511a2-5822-4da4-ebf1-fac37f2b1066"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waiting on bqjob_r19c3d198671266f3_0000017fd66bb970_1 ... (48s) Current status: DONE   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # using pandas can take over 1 hour\n",
        "# #. use `bq` CLI tool instead because we're not adding any new columns\n",
        "# for i in tqdm(range(39)):\n",
        "#     f_name = f\"{i:0>12.0f}.parquet\"\n",
        "#     f_parquet = f\"{gs_posts_folder}/{f_name}\"\n",
        "#     df_i = pd.read_parquet(f_parquet)\n",
        "#     print(f\"\\n  {f_name} shape: {df_i.shape}\")\n",
        "#     (\n",
        "#         df_i\n",
        "#         .to_gbq(\n",
        "#             destination_table='david_bermejo.subclu_posts_top_no_geo_20211214',\n",
        "#             project_id='reddit-employee-datasets',\n",
        "#             chunksize=100000,\n",
        "#             if_exists='append'\n",
        "#         )\n",
        "#     )"
      ],
      "metadata": {
        "id": "bqjAN1sJUqEc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ROh7eGbPCRy-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}