{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d47de26f",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "\n",
    "Test a few more classification metrics to include to select the best models based on these."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a593c7",
   "metadata": {},
   "source": [
    "# Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "31f20abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a79e1970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\t\tv 3.7.10\n",
      "===\n",
      "mlflow\t\tv: 1.16.0\n",
      "numpy\t\tv: 1.19.5\n",
      "pandas\t\tv: 1.2.4\n",
      "plotly\t\tv: 4.14.3\n",
      "seaborn\t\tv: 0.11.1\n",
      "subclu\t\tv: 0.4.1\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import gc\n",
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import mlflow\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import subclu\n",
    "\n",
    "from subclu.utils import set_working_directory\n",
    "from subclu.utils.eda import (\n",
    "    setup_logging, counts_describe, value_counts_and_pcts,\n",
    "    notebook_display_config, print_lib_versions,\n",
    "    style_df_numeric\n",
    ")\n",
    "from subclu.utils.mlflow_logger import MlflowLogger, log_clf_report_and_conf_matrix\n",
    "\n",
    "from subclu.utils.data_irl_style import (\n",
    "    get_colormap, theme_dirl\n",
    ")\n",
    "\n",
    "\n",
    "print_lib_versions([mlflow, np, pd, plotly, sns, subclu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "601aea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.dates as mdates\n",
    "plt.style.use('default')\n",
    "\n",
    "setup_logging()\n",
    "notebook_display_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c410d77a",
   "metadata": {},
   "source": [
    "# Test additional classification metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03cb3619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    accuracy_score, precision_recall_fscore_support,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "from subclu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4d6ee5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_array_test = 99\n",
    "y_true = np.random.choice(['sports', 'politics', 'gaming', ], size=n_array_test, p=[.2, .3, .5])\n",
    "y_pred = [random.choice(['sports', 'politics', 'gaming', ] + [v] * 3) for v in y_true]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "94bf25c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      gaming      0.902     0.698     0.787        53\n",
      "    politics      0.571     0.714     0.635        28\n",
      "      sports      0.478     0.611     0.537        18\n",
      "\n",
      "    accuracy                          0.687        99\n",
      "   macro avg      0.651     0.675     0.653        99\n",
      "weighted avg      0.732     0.687     0.699        99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ea19d906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6868686868686869\n",
      "macro_avg (0.6507094884613442, 0.674503344314665, 0.6529133477758283, None)\n",
      "weighted_avg (0.7316966055036045, 0.6868686868686869, 0.6985830163481088, None)\n"
     ]
    }
   ],
   "source": [
    "print('accuracy', accuracy_score(y_true, y_pred))\n",
    "for avg_ in ['macro', 'weighted']:\n",
    "    print(f'{avg_}_avg', precision_recall_fscore_support(y_true, y_pred, beta=1, average=avg_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ade666e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.90243902, 0.57142857, 0.47826087]),\n",
       " array([0.69811321, 0.71428571, 0.61111111]),\n",
       " array([0.78723404, 0.63492063, 0.53658537]),\n",
       " array([53, 28, 18]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbls_ = ['gaming', 'politics', 'sports']\n",
    "precision_recall_fscore_support(y_true, y_pred, beta=1, labels=lbls_, average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee41ab50",
   "metadata": {},
   "source": [
    "If we supply the labels, the order of the arrays will match the labels and we can use this to create a dict, which we can then convert into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ea1c371b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gaming</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sports</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>politics</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.634921</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      class  precision    recall  f1_score  support\n",
       "0    gaming   0.902439  0.698113  0.787234       53\n",
       "1    sports   0.478261  0.611111  0.536585       18\n",
       "2  politics   0.571429  0.714286  0.634921       28"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision-gaming 0.9024390243902439\n",
      "precision-sports 0.4782608695652174\n",
      "precision-politics 0.5714285714285714\n",
      "recall-gaming 0.6981132075471698\n",
      "recall-sports 0.6111111111111112\n",
      "recall-politics 0.7142857142857143\n",
      "f1_score-gaming 0.7872340425531914\n",
      "f1_score-sports 0.5365853658536586\n",
      "f1_score-politics 0.634920634920635\n",
      "support-gaming 53\n",
      "support-sports 18\n",
      "support-politics 28\n"
     ]
    }
   ],
   "source": [
    "d_class_metrics = dict()\n",
    "col_class_labels = 'class'\n",
    "beta = 1\n",
    "d_class_metrics[col_class_labels] = ['gaming', 'sports', 'politics',]\n",
    "(\n",
    "    d_class_metrics['precision'],\n",
    "    d_class_metrics['recall'],\n",
    "    d_class_metrics[f'f{beta}_score'],\n",
    "    d_class_metrics['support']\n",
    ") = precision_recall_fscore_support(y_true, y_pred, beta=beta, labels=d_class_metrics[col_class_labels], average=None)\n",
    "display(pd.DataFrame(d_class_metrics))\n",
    "\n",
    "for metric_ in [k for k in d_class_metrics.keys() if k != col_class_labels]:\n",
    "    for class_, val_ in zip(d_class_metrics[col_class_labels], d_class_metrics[metric_]):\n",
    "        print(f\"{metric_}-{class_}\", val_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9ec8416c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:41:59 | INFO | \"Start processing K2 metrics for logging\"\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]05:41:59 | INFO | \" K2 gaming-f1_score: 0.816327\"\n",
      "05:41:59 | INFO | \" K2 gaming-support: 50\"\n",
      "05:41:59 | INFO | \" K2 politics-f1_score: 0.677419\"\n",
      "05:41:59 | INFO | \" K2 politics-support: 36\"\n",
      "05:41:59 | INFO | \" K2 sports-f1_score: 0.526316\"\n",
      "05:41:59 | INFO | \" K2 sports-support: 13\"\n",
      "05:41:59 | INFO | \" K2 accuracy: 0.717172\"\n",
      "05:41:59 | INFO | \" K2 precision_macro_avg: 0.680342\"\n",
      "05:41:59 | INFO | \" K2 recall_macro_avg: 0.717521\"\n",
      "05:41:59 | INFO | \" K2 f1_score_macro_avg: 0.673354\"\n",
      "05:41:59 | INFO | \" K2 support_macro_avg: 99\"\n",
      "05:41:59 | INFO | \" K2 precision_weighted_avg: 0.767107\"\n",
      "05:41:59 | INFO | \" K2 recall_weighted_avg: 0.717172\"\n",
      "05:41:59 | INFO | \" K2 f1_score_weighted_avg: 0.727733\"\n",
      "05:41:59 | INFO | \" K2 support_weighted_avg: 99\"\n",
      "100%|██████████| 15/15 [00:00<00:00, 1152.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision recall  f1-score  support\n",
      "class                                           \n",
      "gaming           0.833  0.800     0.816       50\n",
      "politics         0.808  0.583     0.677       36\n",
      "sports           0.400  0.769     0.526       13\n",
      "macro avg        0.680  0.718     0.673       99\n",
      "weighted avg     0.767  0.717     0.728       99\n",
      "accuracy                          0.717       99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "log_clf_report_and_conf_matrix(\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        data_fold_name='k2',\n",
    "        class_labels=['gaming', 'politics', 'sports'],\n",
    "        save_path=None,\n",
    "        log_metrics_to_mlflow=False,\n",
    "        log_artifacts_to_mlflow=False,\n",
    "        log_to_console=True,\n",
    "        remove_files_from_local_path=False,\n",
    "        print_clf_df=True,\n",
    "        return_confusion_mx=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ee9ff04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sports</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gaming</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>politics</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      class  precision    recall  f1_score  support\n",
       "0    sports   0.400000  0.769231  0.526316       13\n",
       "1    gaming   0.833333  0.800000  0.816327       50\n",
       "2  politics   0.807692  0.583333  0.677419       36"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_clf_report = dict()\n",
    "d_clf_report['class'] = ['sports', 'gaming', 'politics', ]\n",
    "(\n",
    "    d_clf_report['precision'],\n",
    "    d_clf_report['recall'],\n",
    "    d_clf_report['f1_score'],\n",
    "    d_clf_report['support']\n",
    ") = precision_recall_fscore_support(y_true, y_pred, beta=1, labels=d_clf_report['class'], average=None)\n",
    "pd.DataFrame(d_clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64565ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.66666667, 0.58823529, 0.8       ]),\n",
       " array([0.8       , 0.76923077, 0.58333333]),\n",
       " array([0.72727273, 0.66666667, 0.6746988 ]),\n",
       " array([25, 26, 48]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_true, y_pred, beta=1, labels=['politics', 'sports', 'gaming', ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ada9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m65"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
