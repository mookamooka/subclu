{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b2b8e84",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "\n",
    "2021-12-21:\n",
    "We're going back to pandas now that I have the VM machine with a ton of RAM.\n",
    "\n",
    "There might be some tweaks needed to batch a few subreddits at a time, but at least we can get more consistent state/progress than with `dask`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c8beca",
   "metadata": {},
   "source": [
    "# Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29a795d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7603fabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\t\tv 3.7.10\n",
      "===\n",
      "dask\t\tv: 2021.06.0\n",
      "hydra\t\tv: 1.1.0\n",
      "mlflow\t\tv: 1.16.0\n",
      "numpy\t\tv: 1.19.5\n",
      "pandas\t\tv: 1.2.4\n",
      "plotly\t\tv: 4.14.3\n",
      "seaborn\t\tv: 0.11.1\n",
      "subclu\t\tv: 0.4.1\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import gc\n",
    "import os\n",
    "import logging\n",
    "from logging import info\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "import dask\n",
    "from dask import dataframe as dd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import mlflow\n",
    "import hydra\n",
    "\n",
    "import subclu\n",
    "from subclu.models.aggregate_embeddings import (\n",
    "    AggregateEmbeddings, AggregateEmbeddingsConfig,\n",
    "    load_config_agg_jupyter, get_dask_df_shape,\n",
    ")\n",
    "from subclu.models import aggregate_embeddings_pd\n",
    "\n",
    "from subclu.utils import set_working_directory\n",
    "from subclu.utils.eda import (\n",
    "    setup_logging, counts_describe, value_counts_and_pcts,\n",
    "    notebook_display_config, print_lib_versions,\n",
    "    style_df_numeric\n",
    ")\n",
    "from subclu.utils.mlflow_logger import MlflowLogger, save_pd_df_to_parquet_in_chunks\n",
    "from subclu.eda.aggregates import (\n",
    "    compare_raw_v_weighted_language\n",
    ")\n",
    "from subclu.utils.data_irl_style import (\n",
    "    get_colormap, theme_dirl\n",
    ")\n",
    "\n",
    "\n",
    "print_lib_versions([dask, hydra, mlflow, np, pd, plotly, sns, subclu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16a7edff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.dates as mdates\n",
    "plt.style.use('default')\n",
    "\n",
    "setup_logging()\n",
    "notebook_display_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7186d8b",
   "metadata": {},
   "source": [
    "# Set sqlite database as MLflow URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82ef1251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sqlite:////home/jupyter/subreddit_clustering_i18n/mlflow_sync/djb-100-2021-04-28-djb-eda-german-subs/mlruns.db'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use new class to initialize mlflow\n",
    "mlf = MlflowLogger(tracking_uri='sqlite')\n",
    "mlflow.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ee15f4",
   "metadata": {},
   "source": [
    "## Get list of experiments with new function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8906a3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>name</th>\n",
       "      <th>artifact_location</th>\n",
       "      <th>lifecycle_stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>v0.4.0_use_multi_aggregates_test</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/15</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>v0.4.0_use_multi_aggregates</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/16</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>v0.4.0_use_multi_clustering_test</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/17</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>v0.4.0_use_multi_clustering</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/18</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>v0.4.1_mUSE_inference_test</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/19</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>v0.4.1_mUSE_inference</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/20</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>v0.4.1_mUSE_aggregates_test</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/21</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>v0.4.1_mUSE_aggregates</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/22</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>v0.4.1_mUSE_clustering_test</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/23</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>v0.4.1_mUSE_clustering</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/24</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   experiment_id                              name                                artifact_location lifecycle_stage\n",
       "15            15  v0.4.0_use_multi_aggregates_test  gs://i18n-subreddit-clustering/mlflow/mlruns/15          active\n",
       "16            16       v0.4.0_use_multi_aggregates  gs://i18n-subreddit-clustering/mlflow/mlruns/16          active\n",
       "17            17  v0.4.0_use_multi_clustering_test  gs://i18n-subreddit-clustering/mlflow/mlruns/17          active\n",
       "18            18       v0.4.0_use_multi_clustering  gs://i18n-subreddit-clustering/mlflow/mlruns/18          active\n",
       "19            19        v0.4.1_mUSE_inference_test  gs://i18n-subreddit-clustering/mlflow/mlruns/19          active\n",
       "20            20             v0.4.1_mUSE_inference  gs://i18n-subreddit-clustering/mlflow/mlruns/20          active\n",
       "21            21       v0.4.1_mUSE_aggregates_test  gs://i18n-subreddit-clustering/mlflow/mlruns/21          active\n",
       "22            22            v0.4.1_mUSE_aggregates  gs://i18n-subreddit-clustering/mlflow/mlruns/22          active\n",
       "23            23       v0.4.1_mUSE_clustering_test  gs://i18n-subreddit-clustering/mlflow/mlruns/23          active\n",
       "24            24            v0.4.1_mUSE_clustering  gs://i18n-subreddit-clustering/mlflow/mlruns/24          active"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlf_exp = mlf.list_experiment_meta(output_format='pandas')\n",
    "df_mlf_exp.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abe0e564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_mlf_exp.iloc[9:15, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8f9172",
   "metadata": {},
   "source": [
    "## Get runs that we can use for embeddings aggregation jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1fa3343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 78 ms, sys: 4.94 ms, total: 83 ms\n",
      "Wall time: 81.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(22, 55)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_mlf_runs =  mlf.search_all_runs(experiment_ids=[20])\n",
    "df_mlf_runs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97f8e1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 55)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_finished = df_mlf_runs['status'] == 'FINISHED'\n",
    "mask_output_over_1M_rows = (\n",
    "    (df_mlf_runs['metrics.df_vect_posts_rows'] >= 1e5) |\n",
    "    (df_mlf_runs['metrics.df_vect_comments'] >= 1e5)\n",
    ")\n",
    "# df_mlf_runs[mask_finished].shape\n",
    "\n",
    "df_mlf_use_for_agg = df_mlf_runs[mask_finished & mask_output_over_1M_rows]\n",
    "df_mlf_use_for_agg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fc59234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 <- columns with multiple values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_af0a1_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >run id</th>        <th class=\"col_heading level0 col1\" >start time</th>        <th class=\"col_heading level0 col2\" >metrics.vectorizing time minutes comments</th>        <th class=\"col_heading level0 col3\" >metrics.df vect comments</th>        <th class=\"col_heading level0 col4\" >metrics.vectorizing time minutes full function</th>        <th class=\"col_heading level0 col5\" >metrics.total comment files processed</th>        <th class=\"col_heading level0 col6\" >metrics.df vect posts cols</th>        <th class=\"col_heading level0 col7\" >metrics.vectorizing time minutes subreddit meta</th>        <th class=\"col_heading level0 col8\" >metrics.df vect posts</th>        <th class=\"col_heading level0 col9\" >metrics.df vect posts rows</th>        <th class=\"col_heading level0 col10\" >metrics.df vect subreddits description rows</th>        <th class=\"col_heading level0 col11\" >metrics.df vect subreddits description cols</th>        <th class=\"col_heading level0 col12\" >params.tokenize lowercase</th>        <th class=\"col_heading level0 col13\" >params.col post id</th>        <th class=\"col_heading level0 col14\" >params.n comment files slice start</th>        <th class=\"col_heading level0 col15\" >params.tf batch inference rows</th>        <th class=\"col_heading level0 col16\" >params.comments path</th>        <th class=\"col_heading level0 col17\" >params.subreddits path</th>        <th class=\"col_heading level0 col18\" >params.mlflow comments folder</th>        <th class=\"col_heading level0 col19\" >params.n comment files slice end</th>        <th class=\"col_heading level0 col20\" >params.col text comment</th>        <th class=\"col_heading level0 col21\" >params.cols index comment</th>        <th class=\"col_heading level0 col22\" >params.col comment id</th>        <th class=\"col_heading level0 col23\" >params.col text comment word count</th>        <th class=\"col_heading level0 col24\" >params.cols comment text to concat</th>        <th class=\"col_heading level0 col25\" >tags.mlflow.source.git.commit</th>        <th class=\"col_heading level0 col26\" >tags.mlflow.runName</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_af0a1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_af0a1_row0_col0\" class=\"data row0 col0\" >a69d1b259875458283124ffdaa6efbb6</td>\n",
       "                        <td id=\"T_af0a1_row0_col1\" class=\"data row0 col1\" >2021-12-21 12:27:00.341000+00:00</td>\n",
       "                        <td id=\"T_af0a1_row0_col2\" class=\"data row0 col2\" >53.09</td>\n",
       "                        <td id=\"T_af0a1_row0_col3\" class=\"data row0 col3\" >12,150,831.00</td>\n",
       "                        <td id=\"T_af0a1_row0_col4\" class=\"data row0 col4\" >60.64</td>\n",
       "                        <td id=\"T_af0a1_row0_col5\" class=\"data row0 col5\" >17.00</td>\n",
       "                        <td id=\"T_af0a1_row0_col6\" class=\"data row0 col6\" >-</td>\n",
       "                        <td id=\"T_af0a1_row0_col7\" class=\"data row0 col7\" >-</td>\n",
       "                        <td id=\"T_af0a1_row0_col8\" class=\"data row0 col8\" >-</td>\n",
       "                        <td id=\"T_af0a1_row0_col9\" class=\"data row0 col9\" >-</td>\n",
       "                        <td id=\"T_af0a1_row0_col10\" class=\"data row0 col10\" >-</td>\n",
       "                        <td id=\"T_af0a1_row0_col11\" class=\"data row0 col11\" >-</td>\n",
       "                        <td id=\"T_af0a1_row0_col12\" class=\"data row0 col12\" >False</td>\n",
       "                        <td id=\"T_af0a1_row0_col13\" class=\"data row0 col13\" >post_id</td>\n",
       "                        <td id=\"T_af0a1_row0_col14\" class=\"data row0 col14\" >57</td>\n",
       "                        <td id=\"T_af0a1_row0_col15\" class=\"data row0 col15\" >3600</td>\n",
       "                        <td id=\"T_af0a1_row0_col16\" class=\"data row0 col16\" >comments/top/2021-12-14</td>\n",
       "                        <td id=\"T_af0a1_row0_col17\" class=\"data row0 col17\" >None</td>\n",
       "                        <td id=\"T_af0a1_row0_col18\" class=\"data row0 col18\" >df_vect_comments</td>\n",
       "                        <td id=\"T_af0a1_row0_col19\" class=\"data row0 col19\" >76</td>\n",
       "                        <td id=\"T_af0a1_row0_col20\" class=\"data row0 col20\" >comment_body_text</td>\n",
       "                        <td id=\"T_af0a1_row0_col21\" class=\"data row0 col21\" >None</td>\n",
       "                        <td id=\"T_af0a1_row0_col22\" class=\"data row0 col22\" >comment_id</td>\n",
       "                        <td id=\"T_af0a1_row0_col23\" class=\"data row0 col23\" >comment_text_word_count</td>\n",
       "                        <td id=\"T_af0a1_row0_col24\" class=\"data row0 col24\" >None</td>\n",
       "                        <td id=\"T_af0a1_row0_col25\" class=\"data row0 col25\" >a02f187a9f0b0ed69ab646b1411b45fb8ec2152a</td>\n",
       "                        <td id=\"T_af0a1_row0_col26\" class=\"data row0 col26\" >comments_slice_3-2021-12-21_122659</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_af0a1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_af0a1_row1_col0\" class=\"data row1 col0\" >e7ed11ccdc0b45abbdf3bf19605d4498</td>\n",
       "                        <td id=\"T_af0a1_row1_col1\" class=\"data row1 col1\" >2021-12-21 11:16:11.807000+00:00</td>\n",
       "                        <td id=\"T_af0a1_row1_col2\" class=\"data row1 col2\" >61.66</td>\n",
       "                        <td id=\"T_af0a1_row1_col3\" class=\"data row1 col3\" >14,194,865.00</td>\n",
       "                        <td id=\"T_af0a1_row1_col4\" class=\"data row1 col4\" >70.80</td>\n",
       "                        <td id=\"T_af0a1_row1_col5\" class=\"data row1 col5\" >20.00</td>\n",
       "                        <td id=\"T_af0a1_row1_col6\" class=\"data row1 col6\" >-</td>\n",
       "                        <td id=\"T_af0a1_row1_col7\" class=\"data row1 col7\" >-</td>\n",
       "                        <td id=\"T_af0a1_row1_col8\" class=\"data row1 col8\" >-</td>\n",
       "                        <td id=\"T_af0a1_row1_col9\" class=\"data row1 col9\" >-</td>\n",
       "                        <td id=\"T_af0a1_row1_col10\" class=\"data row1 col10\" >-</td>\n",
       "                        <td id=\"T_af0a1_row1_col11\" class=\"data row1 col11\" >-</td>\n",
       "                        <td id=\"T_af0a1_row1_col12\" class=\"data row1 col12\" >False</td>\n",
       "                        <td id=\"T_af0a1_row1_col13\" class=\"data row1 col13\" >post_id</td>\n",
       "                        <td id=\"T_af0a1_row1_col14\" class=\"data row1 col14\" >38</td>\n",
       "                        <td id=\"T_af0a1_row1_col15\" class=\"data row1 col15\" >3600</td>\n",
       "                        <td id=\"T_af0a1_row1_col16\" class=\"data row1 col16\" >comments/top/2021-12-14</td>\n",
       "                        <td id=\"T_af0a1_row1_col17\" class=\"data row1 col17\" >None</td>\n",
       "                        <td id=\"T_af0a1_row1_col18\" class=\"data row1 col18\" >df_vect_comments</td>\n",
       "                        <td id=\"T_af0a1_row1_col19\" class=\"data row1 col19\" >57</td>\n",
       "                        <td id=\"T_af0a1_row1_col20\" class=\"data row1 col20\" >comment_body_text</td>\n",
       "                        <td id=\"T_af0a1_row1_col21\" class=\"data row1 col21\" >None</td>\n",
       "                        <td id=\"T_af0a1_row1_col22\" class=\"data row1 col22\" >comment_id</td>\n",
       "                        <td id=\"T_af0a1_row1_col23\" class=\"data row1 col23\" >comment_text_word_count</td>\n",
       "                        <td id=\"T_af0a1_row1_col24\" class=\"data row1 col24\" >None</td>\n",
       "                        <td id=\"T_af0a1_row1_col25\" class=\"data row1 col25\" >a02f187a9f0b0ed69ab646b1411b45fb8ec2152a</td>\n",
       "                        <td id=\"T_af0a1_row1_col26\" class=\"data row1 col26\" >comments_slice_2-2021-12-21_111611</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_af0a1_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_af0a1_row2_col0\" class=\"data row2 col0\" >54ba724869bf4ec9a2cad2a4f7eca048</td>\n",
       "                        <td id=\"T_af0a1_row2_col1\" class=\"data row2 col1\" >2021-12-21 10:08:28.099000+00:00</td>\n",
       "                        <td id=\"T_af0a1_row2_col2\" class=\"data row2 col2\" >58.32</td>\n",
       "                        <td id=\"T_af0a1_row2_col3\" class=\"data row2 col3\" >14,310,574.00</td>\n",
       "                        <td id=\"T_af0a1_row2_col4\" class=\"data row2 col4\" >67.72</td>\n",
       "                        <td id=\"T_af0a1_row2_col5\" class=\"data row2 col5\" >20.00</td>\n",
       "                        <td id=\"T_af0a1_row2_col6\" class=\"data row2 col6\" >-</td>\n",
       "                        <td id=\"T_af0a1_row2_col7\" class=\"data row2 col7\" >-</td>\n",
       "                        <td id=\"T_af0a1_row2_col8\" class=\"data row2 col8\" >-</td>\n",
       "                        <td id=\"T_af0a1_row2_col9\" class=\"data row2 col9\" >-</td>\n",
       "                        <td id=\"T_af0a1_row2_col10\" class=\"data row2 col10\" >-</td>\n",
       "                        <td id=\"T_af0a1_row2_col11\" class=\"data row2 col11\" >-</td>\n",
       "                        <td id=\"T_af0a1_row2_col12\" class=\"data row2 col12\" >False</td>\n",
       "                        <td id=\"T_af0a1_row2_col13\" class=\"data row2 col13\" >post_id</td>\n",
       "                        <td id=\"T_af0a1_row2_col14\" class=\"data row2 col14\" >19</td>\n",
       "                        <td id=\"T_af0a1_row2_col15\" class=\"data row2 col15\" >3600</td>\n",
       "                        <td id=\"T_af0a1_row2_col16\" class=\"data row2 col16\" >comments/top/2021-12-14</td>\n",
       "                        <td id=\"T_af0a1_row2_col17\" class=\"data row2 col17\" >None</td>\n",
       "                        <td id=\"T_af0a1_row2_col18\" class=\"data row2 col18\" >df_vect_comments</td>\n",
       "                        <td id=\"T_af0a1_row2_col19\" class=\"data row2 col19\" >38</td>\n",
       "                        <td id=\"T_af0a1_row2_col20\" class=\"data row2 col20\" >comment_body_text</td>\n",
       "                        <td id=\"T_af0a1_row2_col21\" class=\"data row2 col21\" >None</td>\n",
       "                        <td id=\"T_af0a1_row2_col22\" class=\"data row2 col22\" >comment_id</td>\n",
       "                        <td id=\"T_af0a1_row2_col23\" class=\"data row2 col23\" >comment_text_word_count</td>\n",
       "                        <td id=\"T_af0a1_row2_col24\" class=\"data row2 col24\" >None</td>\n",
       "                        <td id=\"T_af0a1_row2_col25\" class=\"data row2 col25\" >a02f187a9f0b0ed69ab646b1411b45fb8ec2152a</td>\n",
       "                        <td id=\"T_af0a1_row2_col26\" class=\"data row2 col26\" >comments_slice_1-2021-12-21_100827</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_af0a1_level0_row3\" class=\"row_heading level0 row3\" >8</th>\n",
       "                        <td id=\"T_af0a1_row3_col0\" class=\"data row3 col0\" >26c8fcf422a9403ba4a844c8e380bf7f</td>\n",
       "                        <td id=\"T_af0a1_row3_col1\" class=\"data row3 col1\" >2021-12-21 08:03:01.919000+00:00</td>\n",
       "                        <td id=\"T_af0a1_row3_col2\" class=\"data row3 col2\" >54.69</td>\n",
       "                        <td id=\"T_af0a1_row3_col3\" class=\"data row3 col3\" >13,751,054.00</td>\n",
       "                        <td id=\"T_af0a1_row3_col4\" class=\"data row3 col4\" >63.78</td>\n",
       "                        <td id=\"T_af0a1_row3_col5\" class=\"data row3 col5\" >20.00</td>\n",
       "                        <td id=\"T_af0a1_row3_col6\" class=\"data row3 col6\" >-</td>\n",
       "                        <td id=\"T_af0a1_row3_col7\" class=\"data row3 col7\" >-</td>\n",
       "                        <td id=\"T_af0a1_row3_col8\" class=\"data row3 col8\" >-</td>\n",
       "                        <td id=\"T_af0a1_row3_col9\" class=\"data row3 col9\" >-</td>\n",
       "                        <td id=\"T_af0a1_row3_col10\" class=\"data row3 col10\" >-</td>\n",
       "                        <td id=\"T_af0a1_row3_col11\" class=\"data row3 col11\" >-</td>\n",
       "                        <td id=\"T_af0a1_row3_col12\" class=\"data row3 col12\" >False</td>\n",
       "                        <td id=\"T_af0a1_row3_col13\" class=\"data row3 col13\" >post_id</td>\n",
       "                        <td id=\"T_af0a1_row3_col14\" class=\"data row3 col14\" >0</td>\n",
       "                        <td id=\"T_af0a1_row3_col15\" class=\"data row3 col15\" >3800</td>\n",
       "                        <td id=\"T_af0a1_row3_col16\" class=\"data row3 col16\" >comments/top/2021-12-14</td>\n",
       "                        <td id=\"T_af0a1_row3_col17\" class=\"data row3 col17\" >None</td>\n",
       "                        <td id=\"T_af0a1_row3_col18\" class=\"data row3 col18\" >df_vect_comments</td>\n",
       "                        <td id=\"T_af0a1_row3_col19\" class=\"data row3 col19\" >19</td>\n",
       "                        <td id=\"T_af0a1_row3_col20\" class=\"data row3 col20\" >comment_body_text</td>\n",
       "                        <td id=\"T_af0a1_row3_col21\" class=\"data row3 col21\" >None</td>\n",
       "                        <td id=\"T_af0a1_row3_col22\" class=\"data row3 col22\" >comment_id</td>\n",
       "                        <td id=\"T_af0a1_row3_col23\" class=\"data row3 col23\" >comment_text_word_count</td>\n",
       "                        <td id=\"T_af0a1_row3_col24\" class=\"data row3 col24\" >None</td>\n",
       "                        <td id=\"T_af0a1_row3_col25\" class=\"data row3 col25\" >a65c8a903d550ff5ba1f9d8ccd2f476b09bce6bb</td>\n",
       "                        <td id=\"T_af0a1_row3_col26\" class=\"data row3 col26\" >comments_slice_0-2021-12-21_080301</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_af0a1_level0_row4\" class=\"row_heading level0 row4\" >11</th>\n",
       "                        <td id=\"T_af0a1_row4_col0\" class=\"data row4 col0\" >e91b75b201c848db80a26f63f305ff35</td>\n",
       "                        <td id=\"T_af0a1_row4_col1\" class=\"data row4 col1\" >2021-12-21 04:34:31.422000+00:00</td>\n",
       "                        <td id=\"T_af0a1_row4_col2\" class=\"data row4 col2\" >-</td>\n",
       "                        <td id=\"T_af0a1_row4_col3\" class=\"data row4 col3\" >-</td>\n",
       "                        <td id=\"T_af0a1_row4_col4\" class=\"data row4 col4\" >-</td>\n",
       "                        <td id=\"T_af0a1_row4_col5\" class=\"data row4 col5\" >31.00</td>\n",
       "                        <td id=\"T_af0a1_row4_col6\" class=\"data row4 col6\" >515.00</td>\n",
       "                        <td id=\"T_af0a1_row4_col7\" class=\"data row4 col7\" >0.50</td>\n",
       "                        <td id=\"T_af0a1_row4_col8\" class=\"data row4 col8\" >11,715,818.00</td>\n",
       "                        <td id=\"T_af0a1_row4_col9\" class=\"data row4 col9\" >355,268.00</td>\n",
       "                        <td id=\"T_af0a1_row4_col10\" class=\"data row4 col10\" >49,705.00</td>\n",
       "                        <td id=\"T_af0a1_row4_col11\" class=\"data row4 col11\" >514.00</td>\n",
       "                        <td id=\"T_af0a1_row4_col12\" class=\"data row4 col12\" >True</td>\n",
       "                        <td id=\"T_af0a1_row4_col13\" class=\"data row4 col13\" >None</td>\n",
       "                        <td id=\"T_af0a1_row4_col14\" class=\"data row4 col14\" >None</td>\n",
       "                        <td id=\"T_af0a1_row4_col15\" class=\"data row4 col15\" >2450</td>\n",
       "                        <td id=\"T_af0a1_row4_col16\" class=\"data row4 col16\" >posts/top/2021-12-14</td>\n",
       "                        <td id=\"T_af0a1_row4_col17\" class=\"data row4 col17\" >subreddits/top/2021-12-14</td>\n",
       "                        <td id=\"T_af0a1_row4_col18\" class=\"data row4 col18\" >df_vect_posts_extra_text</td>\n",
       "                        <td id=\"T_af0a1_row4_col19\" class=\"data row4 col19\" >None</td>\n",
       "                        <td id=\"T_af0a1_row4_col20\" class=\"data row4 col20\" >text</td>\n",
       "                        <td id=\"T_af0a1_row4_col21\" class=\"data row4 col21\" >['subreddit_name', 'subreddit_id', 'post_id']</td>\n",
       "                        <td id=\"T_af0a1_row4_col22\" class=\"data row4 col22\" >post_id</td>\n",
       "                        <td id=\"T_af0a1_row4_col23\" class=\"data row4 col23\" >text_word_count</td>\n",
       "                        <td id=\"T_af0a1_row4_col24\" class=\"data row4 col24\" >['flair_text', 'post_url_for_embeddings', 'text', 'ocr_inferred_text_agg_clean']</td>\n",
       "                        <td id=\"T_af0a1_row4_col25\" class=\"data row4 col25\" >bb32d90d8f1c5b0cb8921141fe366019e991f238</td>\n",
       "                        <td id=\"T_af0a1_row4_col26\" class=\"data row4 col26\" >posts_as_comments_batch_concat_text_lowercase-2021-12-21_043430</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_af0a1_level0_row5\" class=\"row_heading level0 row5\" >12</th>\n",
       "                        <td id=\"T_af0a1_row5_col0\" class=\"data row5 col0\" >559a8f13264245b3923ab5699ef55bfe</td>\n",
       "                        <td id=\"T_af0a1_row5_col1\" class=\"data row5 col1\" >2021-12-20 23:35:19.466000+00:00</td>\n",
       "                        <td id=\"T_af0a1_row5_col2\" class=\"data row5 col2\" >103.77</td>\n",
       "                        <td id=\"T_af0a1_row5_col3\" class=\"data row5 col3\" >-</td>\n",
       "                        <td id=\"T_af0a1_row5_col4\" class=\"data row5 col4\" >209.57</td>\n",
       "                        <td id=\"T_af0a1_row5_col5\" class=\"data row5 col5\" >41.00</td>\n",
       "                        <td id=\"T_af0a1_row5_col6\" class=\"data row5 col6\" >515.00</td>\n",
       "                        <td id=\"T_af0a1_row5_col7\" class=\"data row5 col7\" >0.51</td>\n",
       "                        <td id=\"T_af0a1_row5_col8\" class=\"data row5 col8\" >15,629,958.00</td>\n",
       "                        <td id=\"T_af0a1_row5_col9\" class=\"data row5 col9\" >495,690.00</td>\n",
       "                        <td id=\"T_af0a1_row5_col10\" class=\"data row5 col10\" >49,705.00</td>\n",
       "                        <td id=\"T_af0a1_row5_col11\" class=\"data row5 col11\" >514.00</td>\n",
       "                        <td id=\"T_af0a1_row5_col12\" class=\"data row5 col12\" >False</td>\n",
       "                        <td id=\"T_af0a1_row5_col13\" class=\"data row5 col13\" >None</td>\n",
       "                        <td id=\"T_af0a1_row5_col14\" class=\"data row5 col14\" >None</td>\n",
       "                        <td id=\"T_af0a1_row5_col15\" class=\"data row5 col15\" >2450</td>\n",
       "                        <td id=\"T_af0a1_row5_col16\" class=\"data row5 col16\" >posts/top/2021-12-14</td>\n",
       "                        <td id=\"T_af0a1_row5_col17\" class=\"data row5 col17\" >subreddits/top/2021-12-14</td>\n",
       "                        <td id=\"T_af0a1_row5_col18\" class=\"data row5 col18\" >df_vect_posts_extra_text</td>\n",
       "                        <td id=\"T_af0a1_row5_col19\" class=\"data row5 col19\" >None</td>\n",
       "                        <td id=\"T_af0a1_row5_col20\" class=\"data row5 col20\" >text</td>\n",
       "                        <td id=\"T_af0a1_row5_col21\" class=\"data row5 col21\" >['subreddit_name', 'subreddit_id', 'post_id']</td>\n",
       "                        <td id=\"T_af0a1_row5_col22\" class=\"data row5 col22\" >post_id</td>\n",
       "                        <td id=\"T_af0a1_row5_col23\" class=\"data row5 col23\" >text_word_count</td>\n",
       "                        <td id=\"T_af0a1_row5_col24\" class=\"data row5 col24\" >['flair_text', 'post_url_for_embeddings', 'text', 'ocr_inferred_text_agg_clean']</td>\n",
       "                        <td id=\"T_af0a1_row5_col25\" class=\"data row5 col25\" >bb32d90d8f1c5b0cb8921141fe366019e991f238</td>\n",
       "                        <td id=\"T_af0a1_row5_col26\" class=\"data row5 col26\" >posts_as_comments_batch_concat_text-2021-12-20_233519</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fca70adbd50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_with_multiple_vals = df_mlf_use_for_agg.columns[df_mlf_use_for_agg.nunique(dropna=False) > 1]\n",
    "print(f\"{len(cols_with_multiple_vals):,.0f} <- columns with multiple values\")\n",
    "\n",
    "style_df_numeric(\n",
    "    df_mlf_use_for_agg\n",
    "    [cols_with_multiple_vals]\n",
    "    .drop(['artifact_uri', 'end_time',\n",
    "           # 'start_time',\n",
    "           ], \n",
    "          axis=1)\n",
    "    .dropna(axis='columns', how='all')\n",
    "    .iloc[:, :30]\n",
    "    ,\n",
    "    rename_cols_for_display=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1273b94a",
   "metadata": {},
   "source": [
    "# Load configs for aggregation jobs\n",
    "\n",
    "`n_sample_comments_files` and `n_sample_posts_files` allow us to only load a few files at a time (e.g., 2 instead of 50) to test the process end-to-end.\n",
    "\n",
    "---\n",
    "Note that by default `hydra` is a cli tool. If we want to call use it in jupyter, we need to manually initialize configs & compose the configuration. See my custom function `load_config_agg_jupyter`. Also see:\n",
    "- [Notebook with `Hydra` examples in a notebook](https://github.com/facebookresearch/hydra/blob/master/examples/jupyter_notebooks/compose_configs_in_notebook.ipynb).\n",
    "- [Hydra docs, Hydra in Jupyter](https://hydra.cc/docs/next/advanced/jupyter_notebooks/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6f5f20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'aggregate_params': { 'agg_comments_to_post_weight_col': None,\n",
      "                        'agg_post_comment_weight': 20,\n",
      "                        'agg_post_post_weight': 70,\n",
      "                        'agg_post_subreddit_desc_weight': 10,\n",
      "                        'agg_post_to_subreddit_weight_col': None,\n",
      "                        'min_comment_text_len': 4},\n",
      "  'calculate_similarites': True,\n",
      "  'data_embeddings_to_aggregate': { 'col_comment_id': 'comment_id',\n",
      "                                    'col_post_id': 'post_id',\n",
      "                                    'col_subreddit_id': 'subreddit_id',\n",
      "                                    'col_text_comment_word_count': 'comment_text_word_count',\n",
      "                                    'col_text_post_word_count': 'text_word_count',\n",
      "                                    'comments_folder_embeddings': 'df_vect_comments',\n",
      "                                    'comments_uuid': [ '26c8fcf422a9403ba4a844c8e380bf7f',\n",
      "                                                       '54ba724869bf4ec9a2cad2a4f7eca048',\n",
      "                                                       'e7ed11ccdc0b45abbdf3bf19605d4498',\n",
      "                                                       'a69d1b259875458283124ffdaa6efbb6'],\n",
      "                                    'posts_folder_embeddings': 'df_vect_posts_extra_text',\n",
      "                                    'posts_uuid': '559a8f13264245b3923ab5699ef55bfe',\n",
      "                                    'subreddit_desc_folder_embeddings': 'df_vect_subreddits_description',\n",
      "                                    'subreddit_desc_uuid': '559a8f13264245b3923ab5699ef55bfe'},\n",
      "  'data_text_and_metadata': { 'bucket_name': 'i18n-subreddit-clustering',\n",
      "                              'dataset_name': 'v0.4.1 inputs FIX remove dupe '\n",
      "                                              'posts - 50k subreddits - Active '\n",
      "                                              'Subreddits (no Geo) + '\n",
      "                                              'Geo-relevant users_l28>=100 & '\n",
      "                                              'posts_l28>=4',\n",
      "                              'folder_comments_text_and_meta': 'comments/top/2021-12-14',\n",
      "                              'folder_posts_text_and_meta': 'posts/top/2021-12-14_fix',\n",
      "                              'folder_subreddits_text_and_meta': 'subreddits/top/2021-12-14',\n",
      "                              'folder_subreddits_text_and_meta_filter': 'subreddits/top/2021-09-24'},\n",
      "  'mlflow_experiment': 'v0.4.1_mUSE_aggregates_test',\n",
      "  'mlflow_tracking_uri': 'sqlite',\n",
      "  'n_sample_comments_files': 4,\n",
      "  'n_sample_posts_files': 1}\n"
     ]
    }
   ],
   "source": [
    "mlflow_experiment_test = 'v0.4.1_mUSE_aggregates_test'\n",
    "mlflow_experiment_full = 'v0.4.1_mUSE_aggregates'\n",
    "\n",
    "root_agg_config_name = 'aggregate_embeddings_v0.4.1'\n",
    "\n",
    "config_test_sample_lc_false = AggregateEmbeddingsConfig(\n",
    "    config_path=\"../config\",\n",
    "    config_name=root_agg_config_name,\n",
    "    overrides=[f\"mlflow_experiment={mlflow_experiment_test}\",\n",
    "               'n_sample_posts_files=1',     # \n",
    "               'n_sample_comments_files=4',  # 6 is limit for logging unique counts at comment level\n",
    "               # 'data_embeddings_to_aggregate=top_subs-2021_07_16-use_multi_lower_case_false',\n",
    "              ]\n",
    ")\n",
    "\n",
    "config_full_lc_false = AggregateEmbeddingsConfig(\n",
    "    config_path=\"../config\",\n",
    "    config_name=root_agg_config_name,\n",
    "    overrides=[f\"mlflow_experiment={mlflow_experiment_full}\",\n",
    "               'n_sample_posts_files=null', \n",
    "               'n_sample_comments_files=null',\n",
    "               # 'data_embeddings_to_aggregate=top_subs-2021_07_16-use_multi_lower_case_false',\n",
    "              ]\n",
    ")\n",
    "\n",
    "pprint(config_test_sample_lc_false.config_dict, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "141cf605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_full_lc_false.config_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fd1d501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments_uuid</th>\n",
       "      <th>mlflow_experiment</th>\n",
       "      <th>n_sample_posts_files</th>\n",
       "      <th>n_sample_comments_files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[26c8fcf422a9403ba4a844c8e380bf7f, 54ba724869bf4ec9a2cad2a4f7eca048, e7ed11ccdc0b45abbdf3bf19605d4498, a69d1b259875458283124ffdaa6efbb6]</td>\n",
       "      <td>v0.4.1_mUSE_aggregates_test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[26c8fcf422a9403ba4a844c8e380bf7f, 54ba724869bf4ec9a2cad2a4f7eca048, e7ed11ccdc0b45abbdf3bf19605d4498, a69d1b259875458283124ffdaa6efbb6]</td>\n",
       "      <td>v0.4.1_mUSE_aggregates</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                              comments_uuid            mlflow_experiment  n_sample_posts_files  n_sample_comments_files\n",
       "0  [26c8fcf422a9403ba4a844c8e380bf7f, 54ba724869bf4ec9a2cad2a4f7eca048, e7ed11ccdc0b45abbdf3bf19605d4498, a69d1b259875458283124ffdaa6efbb6]  v0.4.1_mUSE_aggregates_test                   1.0                      4.0\n",
       "1  [26c8fcf422a9403ba4a844c8e380bf7f, 54ba724869bf4ec9a2cad2a4f7eca048, e7ed11ccdc0b45abbdf3bf19605d4498, a69d1b259875458283124ffdaa6efbb6]       v0.4.1_mUSE_aggregates                   NaN                      NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_configs = pd.DataFrame(\n",
    "    [\n",
    "        config_test_sample_lc_false.config_flat,\n",
    "        # config_test_full_lc_false.config_flat,\n",
    "        config_full_lc_false.config_flat,\n",
    "        # config_full_lc_true.config_flat,\n",
    "    ]\n",
    ")\n",
    "\n",
    "# We can't use (df_configs.nunique(dropna=False) > 1)\n",
    "#  because when a col's content is a list or something unhashable, we get an error\n",
    "#  so instead we'll check each column individually\n",
    "\n",
    "# cols_with_diffs_config = df_configs.columns[df_configs.nunique(dropna=False) > 1]\n",
    "cols_with_diffs_config = list()\n",
    "for c_ in df_configs.columns:\n",
    "    try:\n",
    "        if df_configs[c_].nunique(dropna=False) > 1:\n",
    "            cols_with_diffs_config.append(c_)\n",
    "    except TypeError:\n",
    "        cols_with_diffs_config.append(c_)\n",
    "        \n",
    "\n",
    "df_configs[cols_with_diffs_config]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5db7ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(config_test_sample_lc_false.config_flat, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39c80a4",
   "metadata": {},
   "source": [
    "# Compare python download v. gsutil\n",
    "\n",
    "It's much better to use `gsutil` because it can run jobs in parallel and reduce times by ~2x to 4x.\n",
    "```bash\n",
    "# gsutil done in ~1 minute\n",
    "gsutil -m cp -r -n $remote_gs_path $local_f\n",
    "# Download already complete for /home/jupyter/subreddit_clustering_i18n/data/local_cache/mlflow/mlruns/20/a69d1b259875458283124ffdaa6efbb6/artifacts/artifacts/df_vect_comments/000000000072-800764_by_516.parquet, skipping download but will run integrity checks.\n",
    "# CPU times: user 716 ms, sys: 529 ms, total: 1.24 s.4 MiB/s ETA 00:00:22         \n",
    "# Wall time: 52.6 s\n",
    "\n",
    "\n",
    "# GCS client in python + manual file checks: 4:22\n",
    "08:13:59 | INFO | \"Local folder to download artifact(s):\n",
    "  /home/jupyter/subreddit_clustering_i18n/data/local_cache/mlflow/mlruns/20/a69d1b259875458283124ffdaa6efbb6/artifacts/df_vect_comments\"\n",
    "100%|###########################################| 17/17 [04:22<00:00, 15.47s/it]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d955a34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # mlflow experiment artifacts \n",
    "# remote_key = \"mlflow/mlruns/20/a69d1b259875458283124ffdaa6efbb6/artifacts\"\n",
    "# local_f = f\"/home/jupyter/subreddit_clustering_i18n/data/local_cache/{remote_key}\"\n",
    "# remote_gs_path = f\"gs://i18n-subreddit-clustering/{remote_key}\"\n",
    "\n",
    "# !gsutil -m cp -r -n $remote_gs_path $local_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5b80a4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # POST text & meta\n",
    "# remote_key = config_full_lc_false.config_flat['folder_posts_text_and_meta']\n",
    "# print(remote_key)\n",
    "# # Need to remove the last part of the local path otherwise we'll get duplicate subfolders:\n",
    "# #. top/2021-12-14/2021-12-14 instead of top/2021-12-14\n",
    "# local_f = f\"/home/jupyter/subreddit_clustering_i18n/data/local_cache/{'/'.join(remote_key.split('/')[:-1])}\"\n",
    "# Path(local_f).mkdir(parents=True, exist_ok=True)\n",
    "# remote_gs_path = f\"gs://i18n-subreddit-clustering/{remote_key}\"\n",
    "\n",
    "# !gsutil -m cp -r -n $remote_gs_path $local_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "01ff52ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # comments Text & meta\n",
    "\n",
    "# remote_key = config_full_lc_false.config_flat['folder_comments_text_and_meta']\n",
    "# print(remote_key)\n",
    "# remote_gs_path = f\"gs://i18n-subreddit-clustering/{remote_key}\"\n",
    "# local_f = f\"/home/jupyter/subreddit_clustering_i18n/data/local_cache/{'/'.join(remote_key.split('/')[:-1])}\"\n",
    "\n",
    "\n",
    "# !gsutil -m cp -r -n $remote_gs_path $local_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "85e8a45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ac7c18",
   "metadata": {},
   "source": [
    "# Run test on data subset, `lower_case=False`\n",
    "\n",
    "9 minutes is such a long time... try .groupby().pipe() instead.\n",
    "We won't get a progress bar, but if it's much faster then it's worth the loss of progress bar.\n",
    "\n",
    "```bash\n",
    "# using old .groupby() with loop.\n",
    "09:59:49 | INFO | \"Comments per post summary:\n",
    "  comment_count_  posts_count  percent_of_posts  cumulative_percent_of_posts\n",
    "0            0.0       440953          0.966917                     0.966917\n",
    "1            1.0         2929          0.006423                     0.973340\n",
    "2            2.0         2202          0.004829                     0.978169\n",
    "3            3.0         1754          0.003846                     0.982015\n",
    "4             4+         8202          0.017985                     1.000000\"\n",
    "09:59:49 | INFO | \"Create df with weights for weighted-average calculation\"\n",
    "09:59:52 | INFO | \"Get weighted average for POST + COMMENT + SUBREDDIT-META\"\n",
    "100%|##################################| 456040/456040 [09:11<00:00, 826.25it/s]\n",
    "10:09:27 | INFO | \"  (456040, 512) <- df_agg_posts_w_sub.shape (only posts with comments)\"\n",
    "10:09:27 | INFO | \"Re-append multi-index so it's the same in original and new output\"\n",
    "10:09:35 | INFO | \"Check that post-ID is unique...\"\n",
    "10:09:36 | INFO | \"  (456040, 515) <- df_posts_agg_c shape after aggregation\"\n",
    "10:09:36 | INFO | \"  0:09:47.922873 <- Total posts+comments+subs agg time elapsed\"\n",
    "10:09:38 | INFO | \"RAM stats:\n",
    "{'memory_used_percent': '6.41%', 'memory_used': '124,093'}\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9fa8301",
   "metadata": {},
   "outputs": [],
   "source": [
    "BREAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2779ed1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:55:53 | INFO | \"Logging log-file to mlflow...\"\n",
      "09:55:54 | INFO | \"== Start run_aggregation() method ==\"\n",
      "09:55:54 | INFO | \"MLflow tracking URI: sqlite:////home/jupyter/subreddit_clustering_i18n/mlflow_sync/djb-100-2021-04-28-djb-eda-german-subs/mlruns.db\"\n",
      "09:55:55 | INFO | \"host_name: djb-100-2021-04-28-djb-eda-german-subs\"\n",
      "09:55:55 | INFO | \"cpu_count: 80\"\n",
      "09:55:57 | INFO | \"RAM stats:\n",
      "{'memory_used_percent': '5.32%', 'memory_total': '1,937,274', 'memory_used': '103,089', 'memory_free': '1,592,050'}\"\n",
      "09:55:57 | INFO | \"  Local model saving directory: /home/jupyter/subreddit_clustering_i18n/data/models/aggregate_embeddings/2021-12-23_095557-agg_test_lc_false_pd-2021-12-23_095553\"\n",
      "09:55:57 | INFO | \"  Saving config to local path...\"\n",
      "09:55:57 | INFO | \"  Logging config to mlflow with joblib...\"\n",
      "09:55:58 | INFO | \"  Logging config to mlflow with YAML...\"\n",
      "09:55:58 | INFO | \"-- Start _load_raw_embeddings() method --\"\n",
      "09:55:58 | INFO | \"Loading subreddit description embeddings...\"\n",
      "09:56:00 | INFO | \"Local folder to download artifact(s):\n",
      "  /home/jupyter/subreddit_clustering_i18n/data/local_cache/mlflow/mlruns/20/559a8f13264245b3923ab5699ef55bfe/artifacts/df_vect_subreddits_description\"\n",
      "100%|###########################################| 5/5 [00:00<00:00, 7842.75it/s]\n",
      "09:56:00 | INFO | \"  Parquet files found:     2\"\n",
      "09:56:00 | INFO | \"  Parquet files to use:     2\"\n",
      "09:56:01 | INFO | \"      49,705 | 514 <- Raw vectorized subreddit description shape\"\n",
      "09:56:01 | INFO | \"  Unique check for subreddit description...\"\n",
      "09:56:01 | INFO | \"Loading POSTS embeddings...\"\n",
      "09:56:01 | INFO | \"  Sampling POSTS FILES down to: 1\"\n",
      "09:56:02 | INFO | \"Local folder to download artifact(s):\n",
      "  /home/jupyter/subreddit_clustering_i18n/data/local_cache/mlflow/mlruns/20/559a8f13264245b3923ab5699ef55bfe/artifacts/df_vect_posts\"\n",
      "100%|########################################| 40/40 [00:00<00:00, 29921.91it/s]\n",
      "09:56:03 | INFO | \"  Parquet files found:    40\"\n",
      "09:56:03 | INFO | \"  Parquet files to use:     1\"\n",
      "09:56:08 | INFO | \"  Getting df_v_posts.shape ...\"\n",
      "09:56:08 | INFO | \"     456,040 |  515 <- Raw POSTS shape\"\n",
      "09:56:08 | INFO | \"  Checking that posts are unique...\"\n",
      "09:56:08 | INFO | \"Loading COMMENTS embeddings...\"\n",
      "09:56:08 | INFO | \"  Sampling COMMENTS FILES down to: 4\"\n",
      "09:56:08 | INFO | \"  Found 4 run UUIDs with COMMENT embeddings...\"\n",
      "09:56:08 | INFO | \"    Sampling 1 FILES per run UUID\"\n",
      "09:56:09 | INFO | \"Local folder to download artifact(s):\n",
      "  /home/jupyter/subreddit_clustering_i18n/data/local_cache/mlflow/mlruns/20/26c8fcf422a9403ba4a844c8e380bf7f/artifacts/df_vect_comments\"\n",
      "100%|########################################| 20/20 [00:00<00:00, 23230.71it/s]\n",
      "09:56:09 | INFO | \"  Parquet files found:    19\"\n",
      "09:56:09 | INFO | \"  Parquet files to use:     1\"\n",
      "09:56:19 | INFO | \"Local folder to download artifact(s):\n",
      "  /home/jupyter/subreddit_clustering_i18n/data/local_cache/mlflow/mlruns/20/54ba724869bf4ec9a2cad2a4f7eca048/artifacts/df_vect_comments\"\n",
      "100%|########################################| 20/20 [00:00<00:00, 23623.23it/s]\n",
      "09:56:19 | INFO | \"  Parquet files found:    19\"\n",
      "09:56:19 | INFO | \"  Parquet files to use:     1\"\n",
      "09:56:27 | INFO | \"Local folder to download artifact(s):\n",
      "  /home/jupyter/subreddit_clustering_i18n/data/local_cache/mlflow/mlruns/20/e7ed11ccdc0b45abbdf3bf19605d4498/artifacts/df_vect_comments\"\n",
      "100%|########################################| 20/20 [00:00<00:00, 22684.18it/s]\n",
      "09:56:28 | INFO | \"  Parquet files found:    19\"\n",
      "09:56:28 | INFO | \"  Parquet files to use:     1\"\n",
      "09:56:36 | INFO | \"Local folder to download artifact(s):\n",
      "  /home/jupyter/subreddit_clustering_i18n/data/local_cache/mlflow/mlruns/20/a69d1b259875458283124ffdaa6efbb6/artifacts/df_vect_comments\"\n",
      "100%|########################################| 17/17 [00:00<00:00, 21329.10it/s]\n",
      "09:56:36 | INFO | \"  Parquet files found:    16\"\n",
      "09:56:36 | INFO | \"  Parquet files to use:     1\"\n",
      "09:56:47 | INFO | \"   3,198,285 |  516 <- Raw COMMENTS shape\"\n",
      "09:56:47 | INFO | \"  Keep only comments for posts with embeddings\"\n",
      "09:56:48 | INFO | \"      70,852 |  516 <- COMMENTS shape, after keeping only comments to loaded posts\"\n",
      "09:56:48 | INFO | \"  0:00:49.752112 <- Total raw embeddings load time elapsed\"\n",
      "09:56:50 | INFO | \"RAM stats:\n",
      "{'memory_used_percent': '5.68%', 'memory_used': '109,955'}\"\n",
      "09:56:50 | INFO | \"-- Start _load_metadata() method --\"\n",
      "09:56:50 | INFO | \"Loading POSTS metadata...\"\n",
      "09:56:50 | INFO | \"Reading raw data...\"\n",
      "09:56:50 | INFO | \"  Local folder to download artifact(s):\n",
      "  /home/jupyter/subreddit_clustering_i18n/data/local_cache/posts/top/2021-12-14_fix\"\n",
      "100%|##############################| 39/39 [00:00<00:00, 35498.67it/s]\n",
      "09:57:17 | INFO | \"  Applying transformations...\"\n",
      "09:57:28 | ERROR | \"Error creating manual topic... 'combined_topic_and_rating'\"\n",
      "09:58:24 | INFO | \"  (15629958, 13) <- Raw META POSTS shape\"\n",
      "09:58:24 | INFO | \"Loading subs metadata...\"\n",
      "09:58:24 | INFO | \"  reading sub-level data & merging with aggregates...\"\n",
      "09:58:24 | INFO | \"Reading raw data...\"\n",
      "09:58:24 | INFO | \"  Local folder to download artifact(s):\n",
      "  /home/jupyter/subreddit_clustering_i18n/data/local_cache/subreddits/top/2021-12-14\"\n",
      "100%|#################################| 1/1 [00:00<00:00, 4549.14it/s]\n",
      "09:58:25 | INFO | \"  Applying transformations...\"\n",
      "09:58:25 | ERROR | \"Error creating manual topic... 'combined_topic_and_rating'\"\n",
      "09:59:02 | INFO | \"  (49705, 125) <- Raw META subreddit description shape\"\n",
      "09:59:02 | INFO | \"Loading COMMENTS metadata...\"\n",
      "09:59:02 | INFO | \"Reading raw data...\"\n",
      "09:59:02 | INFO | \"  Local folder to download artifact(s):\n",
      "  /home/jupyter/subreddit_clustering_i18n/data/local_cache/comments/top/2021-12-14\"\n",
      "100%|##############################| 73/73 [00:00<00:00, 37495.00it/s]\n",
      "09:59:43 | INFO | \"  (54407324, 8) <- Raw META COMMENTS shape\"\n",
      "09:59:43 | INFO | \"  0:02:53.297735 <- Total metadata loading time elapsed\"\n",
      "09:59:45 | INFO | \"RAM stats:\n",
      "{'memory_used_percent': '6.22%', 'memory_used': '120,438'}\"\n",
      "09:59:45 | INFO | \"4 <- Removing comments shorter than 4 characters.\"\n",
      "09:59:45 | INFO | \"  (70852, 516) <- df_v_comments.shape AFTER removing short comments\"\n",
      "09:59:45 | INFO | \"-- Start _agg_comments_to_post_level() method --\"\n",
      "09:59:46 | INFO | \"No column to weight comments, simple mean for comments at post level\"\n",
      "09:59:46 | INFO | \"  (15087, 515) <- df_v_com_agg shape after aggregation\"\n",
      "09:59:46 | WARNING | \"  TODO(djb): DELETE df_v_com (raw) to free up memory...\"\n",
      "09:59:46 | INFO | \"  0:00:00.565357 <- Total comments to post agg loading time elapsed\"\n",
      "09:59:48 | INFO | \"RAM stats:\n",
      "{'memory_used_percent': '6.22%', 'memory_used': '120,439'}\"\n",
      "09:59:48 | INFO | \"SKIPPING: B = Calculating aggregation for POSTS + COMMENTS\"\n",
      "09:59:48 | INFO | \"-- Start (df_posts_agg_c) _agg_posts_comments_and_sub_descriptions_to_post_level() method --\"\n",
      "09:59:48 | INFO | \"Getting count of comments per post...\"\n",
      "09:59:49 | INFO | \"     15,087 <- Posts that need weighted average\"\n",
      "09:59:49 | INFO | \"Comments per post summary:\n",
      "  comment_count_  posts_count  percent_of_posts  cumulative_percent_of_posts\n",
      "0            0.0       440953          0.966917                     0.966917\n",
      "1            1.0         2929          0.006423                     0.973340\n",
      "2            2.0         2202          0.004829                     0.978169\n",
      "3            3.0         1754          0.003846                     0.982015\n",
      "4             4+         8202          0.017985                     1.000000\"\n",
      "09:59:49 | INFO | \"Create df with weights for weighted-average calculation\"\n",
      "09:59:52 | INFO | \"Get weighted average for POST + COMMENT + SUBREDDIT-META\"\n",
      "100%|##################################| 456040/456040 [09:11<00:00, 826.25it/s]\n",
      "10:09:27 | INFO | \"  (456040, 512) <- df_agg_posts_w_sub.shape (only posts with comments)\"\n",
      "10:09:27 | INFO | \"Re-append multi-index so it's the same in original and new output\"\n",
      "10:09:35 | INFO | \"Check that post-ID is unique...\"\n",
      "10:09:36 | INFO | \"  (456040, 515) <- df_posts_agg_c shape after aggregation\"\n",
      "10:09:36 | INFO | \"  0:09:47.922873 <- Total posts+comments+subs agg time elapsed\"\n",
      "10:09:38 | INFO | \"RAM stats:\n",
      "{'memory_used_percent': '6.41%', 'memory_used': '124,093'}\"\n",
      "10:09:38 | INFO | \"-- Start _agg_post_aggregates_to_subreddit_level() method --\"\n",
      "10:09:38 | INFO | \"No column to weight comments, simple mean to roll up posts to subreddit-level...\"\n",
      "10:09:38 | INFO | \"A - posts only\"\n",
      "10:09:41 | INFO | \"  (1530, 514) <- df_subs_agg_a.shape (only posts)\"\n",
      "10:09:41 | INFO | \"C - posts + comments + sub descriptions\"\n",
      "10:09:45 | INFO | \"  (1530, 514) <- df_subs_agg_c.shape (posts + comments + sub description)\"\n",
      "10:09:45 | INFO | \"  0:00:06.566528 <- Total for all subreddit-level agg time elapsed\"\n",
      "10:09:46 | INFO | \"RAM stats:\n",
      "{'memory_used_percent': '6.41%', 'memory_used': '124,090'}\"\n",
      "10:09:46 | INFO | \"-- Start _save_and_log_aggregate_and_similarity_dfs() method --\"\n",
      "10:09:46 | INFO | \"Dictionary of dfs to log & save (only dfs that have been created):\n",
      "{'df_sub_level_agg_c_post_comments_and_sub_desc': 'df_sub_level_agg_c_post_comments_and_sub_desc', 'df_post_level_agg_c_post_comments_sub_desc': 'df_post_level_agg_c_post_comments_sub_desc', 'df_sub_level_agg_a_post_only': 'df_sub_level_agg_a_post_only'}\"\n",
      "10:09:46 | INFO | \"  Saving config to local path...\"\n",
      "10:09:46 | INFO | \"  Logging config to mlflow with joblib...\"\n",
      "10:09:47 | INFO | \"  Logging config to mlflow with YAML...\"\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]10:09:47 | INFO | \"** df_sub_level_agg_c_post_comments_and_sub_desc **\"\n",
      "10:09:47 | INFO | \"  Saving locally...\"\n",
      "10:09:47 | INFO | \"Converting pandas to dask...\"\n",
      "10:09:47 | INFO | \"     6.2 MB <- Memory usage\"\n",
      "10:09:47 | INFO | \"       1\t<- target Dask partitions\t   50.0 <- target MB partition size\"\n",
      "10:09:48 | INFO | \"  Logging df shape...\"\n",
      "10:09:48 | INFO | \"  Logging artifact to mlflow...\"\n",
      "10:09:48 | INFO | \"  0:00:01.114498 <- Total for saving & logging ** df_sub_level_agg_c_post_comments_and_sub_desc ** time elapsed\"\n",
      "10:09:48 | INFO | \"** df_post_level_agg_c_post_comments_sub_desc **\"\n",
      "10:09:48 | INFO | \"  Saving locally...\"\n",
      "10:09:49 | INFO | \"Converting pandas to dask...\"\n",
      "10:09:49 | INFO | \"  1,872.1 MB <- Memory usage\"\n",
      "10:09:49 | INFO | \"      10\t<- target Dask partitions\t  200.0 <- target MB partition size\"\n",
      "10:09:56 | INFO | \"  Logging df shape...\"\n",
      "10:09:56 | INFO | \"  Logging artifact to mlflow...\"\n",
      "10:10:31 | INFO | \"  0:00:43.004064 <- Total for saving & logging ** df_post_level_agg_c_post_comments_sub_desc ** time elapsed\"\n",
      " 67%|##############################               | 2/3 [00:44<00:22, 22.06s/it]10:10:31 | INFO | \"** df_sub_level_agg_a_post_only **\"\n",
      "10:10:31 | INFO | \"  Saving locally...\"\n",
      "10:10:31 | INFO | \"Converting pandas to dask...\"\n",
      "10:10:31 | INFO | \"     3.2 MB <- Memory usage\"\n",
      "10:10:31 | INFO | \"       1\t<- target Dask partitions\t   50.0 <- target MB partition size\"\n",
      "10:10:32 | INFO | \"  Logging df shape...\"\n",
      "10:10:32 | INFO | \"  Logging artifact to mlflow...\"\n",
      "10:10:33 | INFO | \"  0:00:01.402821 <- Total for saving & logging ** df_sub_level_agg_a_post_only ** time elapsed\"\n",
      "100%|#############################################| 3/3 [00:45<00:00, 15.18s/it]\n",
      "10:10:33 | INFO | \"  0:00:46.275647 <- Total for _save_and_log_aggregate_and_similarity_dfs() time elapsed\"\n",
      "10:10:34 | INFO | \"RAM stats:\n",
      "{'memory_used_percent': '6.40%', 'memory_used': '124,079'}\"\n",
      "10:10:34 | INFO | \"-- Start _calculate_subreddit_similarities() method --\"\n",
      "10:10:34 | INFO | \"A...\"\n",
      "10:10:34 | INFO | \"  (1530, 1530) <- df_subs_agg_a_similarity.shape\"\n",
      "10:10:37 | INFO | \"Merge distance + metadata...\"\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['manual_topic_and_rating'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/home/david.bermejo/repos/subreddit_clustering_i18n/subclu/models/aggregate_embeddings_pd.py\u001b[0m in \u001b[0;36mrun_aggregation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;31m# ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_similarites\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_subreddit_similarities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_ram_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monly_memory_used\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/david.bermejo/repos/subreddit_clustering_i18n/subclu/models/aggregate_embeddings_pd.py\u001b[0m in \u001b[0;36m_calculate_subreddit_similarities\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1132\u001b[0m             \u001b[0mdf_distance_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_subs_agg_a_similarity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m             \u001b[0mdf_sub_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_subs_meta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1134\u001b[0;31m             \u001b[0mtop_subs_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_keep_top\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1135\u001b[0m         )\n\u001b[1;32m   1136\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/david.bermejo/repos/subreddit_clustering_i18n/subclu/data/transform_distance_data_for_bq.py\u001b[0m in \u001b[0;36mreshape_distances_to_pairwise_bq\u001b[0;34m(df_distance_matrix, df_sub_metadata, col_new_manual_topic, index_name, top_subs_to_keep)\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mdf_dist_pair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             .merge(\n\u001b[0;32m--> 270\u001b[0;31m                 \u001b[0mdf_sub_metadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml_meta_basic\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'subreddit_name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m                 \u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subreddit_name_a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3028\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3029\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3030\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3032\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1314\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['manual_topic_and_rating'] not in index\""
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "try:\n",
    "    job_agg_test._send_log_file_to_mlflow()\n",
    "    mlflow.end_run(\"FAILED\")\n",
    "    # run setup_logging() to remove logging to the file of a failed job\n",
    "    setup_logging()\n",
    "    \n",
    "    del job_agg_test\n",
    "except NameError:\n",
    "    pass\n",
    "gc.collect()\n",
    "\n",
    "mlflow.end_run(\"FAILED\")\n",
    "\n",
    "\n",
    "job_agg_test = aggregate_embeddings_pd.AggregateEmbeddings(\n",
    "    run_name=f\"agg_test_lc_false_pd-{datetime.utcnow().strftime('%Y-%m-%d_%H%M%S')}\",\n",
    "    **config_test_sample_lc_false.config_flat\n",
    ")\n",
    "job_agg_test.run_aggregation()\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "98d6248d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<subclu.models.aggregate_embeddings_pd.AggregateEmbeddings at 0x7f134e293050>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_agg_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "061485d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:40:54 | INFO | \"Create df with weights for weighted-average calculation\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.37 s, sys: 982 ms, total: 2.35 s\n",
      "Wall time: 2.35 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(927167, 516)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "col_weights = '_col_method_weight_'\n",
    "\n",
    "info(f\"Create df with weights for weighted-average calculation\")\n",
    "df_posts_for_weights = pd.concat(\n",
    "    [\n",
    "        job_agg_test.df_v_posts.assign(\n",
    "            **{col_weights: job_agg_test.agg_post_post_weight}\n",
    "        ),\n",
    "        job_agg_test.df_v_com_agg.assign(\n",
    "            **{col_weights: job_agg_test.agg_post_comment_weight}\n",
    "        ),\n",
    "        # For each post: add one row of subreddit metadata\n",
    "        (\n",
    "            job_agg_test.df_v_posts[job_agg_test.l_ix_post_level]\n",
    "            .merge(\n",
    "                job_agg_test.df_v_sub,\n",
    "                how='left',\n",
    "                left_on=job_agg_test.l_ix_sub_level,\n",
    "                right_on=job_agg_test.l_ix_sub_level,\n",
    "            )\n",
    "        ).assign(\n",
    "            **{col_weights: job_agg_test.agg_post_subreddit_desc_weight}\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "df_posts_for_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c171aafb",
   "metadata": {},
   "source": [
    "### piping functions\n",
    "https://pandas.pydata.org/pandas-docs/dev/user_guide/groupby.html#piping-function-calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2d7811d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f1d5c037550>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_posts_for_weights.head(1000).groupby('post_id')[job_agg_test.l_embedding_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "184c77c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pipe_template\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m     \u001b[0mplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproperty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGroupByPlot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(obj, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(grp)\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36maverage\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36maverage\u001b[0;34m(a, axis, weights, returned)\u001b[0m\n\u001b[1;32m    410\u001b[0m                 \"Weights sum to zero, can't be normalized\")\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mscl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'str'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# the time to compare is ~9 minutes\n",
    "\n",
    "\n",
    "(\n",
    "    df_posts_for_weights.head(1000).groupby('post_id')\n",
    "    .pipe(\n",
    "        lambda grp: np.average(\n",
    "            grp[job_agg_test.l_embedding_cols],\n",
    "            weights=grp[col_weights],\n",
    "            axis=0,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b79406b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9 / 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f0dbccd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46,358\n",
      "CPU times: user 50.2 s, sys: 359 ms, total: 50.6 s\n",
      "Wall time: 50.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "post_id\n",
       "t3_q7nxrt    [0.005173432175070047, -0.04249882698059082, 0.06282028555870056, 0.004041563719511032, 0.020344318822026253, 0.05887889489531517, 0.025653112679719925, 0.01699175499379635, 0.009449150413274765, 0.011669213883578777, 0.0428733564913272...\n",
       "t3_q7nyfn    [-0.059484802186489105, 0.04459403455257416, -0.08658625185489655, -0.04349858686327934, -0.0011724033392965794, -0.044737089425325394, 0.03139304742217064, 0.0018960057059302926, -0.03238798677921295, -0.05040803924202919, 0.0536521039...\n",
       "t3_q7nyq3    [-0.02391538955271244, 0.002337999641895294, 0.04435169696807861, 0.018625501543283463, 0.024183524772524834, 0.07496833056211472, -0.027850400656461716, 0.046770427376031876, -0.04380057752132416, -0.014158650301396847, 0.0424765311181...\n",
       "t3_q7o021    [-0.020432401448488235, -0.0282297320663929, 0.01715364307165146, 0.002324985107406974, -0.037785910069942474, 0.05924432352185249, -0.05497536063194275, 0.039222147315740585, -0.05581115558743477, -0.05569520592689514, 0.06140409037470...\n",
       "t3_q7o03g    [-0.08813737332820892, 0.008276513777673244, 0.023345138877630234, -0.03127323463559151, 0.07655736804008484, -0.0023008682765066624, 0.08460064977407455, -0.009157819673418999, -0.03945697098970413, 0.06617201864719391, 0.0874877050518...\n",
       "                                                                                                                                  ...                                                                                                                       \n",
       "t3_rgkvga    [-0.04892977327108383, 0.037094905972480774, -0.008026494644582272, 0.02573126181960106, 0.018851295113563538, 1.6628297089482658e-05, -0.01803612895309925, 0.04906206205487251, -0.08416087180376053, 0.0012167878448963165, 0.01412869989...\n",
       "t3_rgkx6p    [-0.056153252720832825, -0.05229385569691658, 0.00015354996139649302, 0.03454820439219475, -0.07760951668024063, -0.056820906698703766, 0.0038936843629926443, -0.009261847473680973, -0.014751172624528408, 0.019533833488821983, -0.040282...\n",
       "t3_rgl0gv    [-0.04813374578952789, 0.04587854444980621, 0.03193465620279312, -0.04849390685558319, -0.07518744468688965, 0.06614907830953598, -0.0023757575545459986, -0.016795430332422256, -0.03627796471118927, -0.031145775690674782, 0.005633739754...\n",
       "t3_rgl0zv    [-0.02450241893529892, -0.048359211534261703, 0.02942158281803131, 0.003730312455445528, -0.09413575381040573, 0.0583372637629509, 0.032204706221818924, 0.034150347113609314, -0.035626545548439026, -0.02616429515182972, 0.05513064563274...\n",
       "t3_rgl1go    [-0.01799018867313862, 0.03461641073226929, 0.0815986916422844, -0.05579942464828491, 0.008385999128222466, 0.05228671059012413, -0.0019327625632286072, -0.04918894171714783, -0.03600696101784706, 0.07016148418188095, -0.066941365599632...\n",
       "Length: 46358, dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# the time to compare is ~9 minutes for full data\n",
    "\n",
    "n_sample_ = int(len(df_posts_for_weights) / 20)\n",
    "print(f\"{n_sample_:,.0f}\")\n",
    "(\n",
    "    df_posts_for_weights.head(n_sample_)\n",
    "    .groupby('post_id')\n",
    "    .apply(\n",
    "        lambda grp: np.average(\n",
    "            grp[job_agg_test.l_embedding_cols],\n",
    "            weights=grp[col_weights],\n",
    "            axis=0,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae2ea12",
   "metadata": {},
   "source": [
    "# Run Full data with `lower_case=False`\n",
    "\n",
    "The logic for sampling files and download/`caching` files locally lives in the `mlf` custom function.\n",
    "\n",
    "Caching can save 9+ minutes if we try to download the files from GCS every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdf5e0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow_experiment: \tv0.4.1_mUSE_aggregates\n",
      "n_sample_posts_files: \tNone\n",
      "n_sample_comments_files: \tNone\n",
      "\n",
      "aggregate_params:\n",
      "  min_comment_text_len: \t4\n",
      "  agg_comments_to_post_weight_col: \tNone\n",
      "  agg_post_to_subreddit_weight_col: \tNone\n",
      "  agg_post_post_weight: \t70\n",
      "  agg_post_comment_weight: \t20\n",
      "  agg_post_subreddit_desc_weight: \t10\n",
      "calculate_similarites: \tTrue\n"
     ]
    }
   ],
   "source": [
    "keys_to_check_in_config = ['mlflow_experiment', 'n_sample_posts_files', 'n_sample_comments_files', 'aggregate_params', 'calculate_similarites']\n",
    "\n",
    "for k_ in keys_to_check_in_config:\n",
    "    v_ = config_full_lc_false.config_dict.get(k_)\n",
    "    if isinstance(v_, dict):\n",
    "        print(f\"\\n{k_}:\")\n",
    "        [print(f\"  {k2_}: \\t{v2_}\") for k2_, v2_ in v_.items()]\n",
    "    else:\n",
    "        print(f\"{k_}: \\t{v_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abda2a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aggregate_params': {'agg_comments_to_post_weight_col': None,\n",
      "                      'agg_post_comment_weight': 20,\n",
      "                      'agg_post_post_weight': 70,\n",
      "                      'agg_post_subreddit_desc_weight': 10,\n",
      "                      'agg_post_to_subreddit_weight_col': None,\n",
      "                      'min_comment_text_len': 4},\n",
      " 'calculate_similarites': True,\n",
      " 'data_embeddings_to_aggregate': {'col_comment_id': 'comment_id',\n",
      "                                  'col_post_id': 'post_id',\n",
      "                                  'col_subreddit_id': 'subreddit_id',\n",
      "                                  'col_text_comment_word_count': 'comment_text_word_count',\n",
      "                                  'col_text_post_word_count': 'text_word_count',\n",
      "                                  'comments_folder_embeddings': 'df_vect_comments',\n",
      "                                  'comments_uuid': ['26c8fcf422a9403ba4a844c8e380bf7f',\n",
      "                                                    '54ba724869bf4ec9a2cad2a4f7eca048',\n",
      "                                                    'e7ed11ccdc0b45abbdf3bf19605d4498',\n",
      "                                                    'a69d1b259875458283124ffdaa6efbb6'],\n",
      "                                  'posts_folder_embeddings': 'df_vect_posts_extra_text',\n",
      "                                  'posts_uuid': '559a8f13264245b3923ab5699ef55bfe',\n",
      "                                  'subreddit_desc_folder_embeddings': 'df_vect_subreddits_description',\n",
      "                                  'subreddit_desc_uuid': '559a8f13264245b3923ab5699ef55bfe'},\n",
      " 'data_text_and_metadata': {'bucket_name': 'i18n-subreddit-clustering',\n",
      "                            'dataset_name': 'v0.4.1 inputs FIX remove dupe '\n",
      "                                            'posts - 50k subreddits - Active '\n",
      "                                            'Subreddits (no Geo) + '\n",
      "                                            'Geo-relevant users_l28>=100 & '\n",
      "                                            'posts_l28>=4',\n",
      "                            'folder_comments_text_and_meta': 'comments/top/2021-12-14',\n",
      "                            'folder_posts_text_and_meta': 'posts/top/2021-12-14_fix',\n",
      "                            'folder_subreddits_text_and_meta': 'subreddits/top/2021-12-14',\n",
      "                            'folder_subreddits_text_and_meta_filter': 'subreddits/top/2021-09-24'},\n",
      " 'mlflow_experiment': 'v0.4.1_mUSE_aggregates',\n",
      " 'mlflow_tracking_uri': 'sqlite',\n",
      " 'n_sample_comments_files': None,\n",
      " 'n_sample_posts_files': None}\n"
     ]
    }
   ],
   "source": [
    "pprint(config_full_lc_false.config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a52dfdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "BREAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4db403",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:20:55 | INFO | \"== Start run_aggregation() method ==\"\n",
      "11:20:55 | INFO | \"MLflow tracking URI: sqlite:////home/jupyter/subreddit_clustering_i18n/mlflow_sync/djb-100-2021-04-28-djb-eda-german-subs/mlruns.db\"\n",
      "11:20:55 | INFO | \"host_name: djb-100-2021-04-28-djb-eda-german-subs\"\n",
      "11:20:55 | INFO | \"cpu_count: 80\"\n",
      "11:20:55 | INFO | \"RAM stats:\n",
      "{'memory_used_percent': '0.10%', 'memory_total': '1,937,274', 'memory_used': '2,000', 'memory_free': '1,690,826'}\"\n",
      "11:20:55 | INFO | \"  Local model saving directory: /home/jupyter/subreddit_clustering_i18n/data/models/aggregate_embeddings/2021-12-23_112055-agg_full_lc_false_pd-2021-12-23_112054\"\n",
      "11:20:55 | INFO | \"  Saving config to local path...\"\n",
      "11:20:55 | INFO | \"  Logging config to mlflow with joblib...\"\n",
      "11:20:56 | INFO | \"  Logging config to mlflow with YAML...\"\n",
      "11:20:56 | INFO | \"-- Start _load_raw_embeddings() method --\"\n",
      "11:20:56 | INFO | \"Loading subreddit description embeddings...\"\n",
      "11:20:58 | INFO | \"Local folder to download artifact(s):\n",
      "  /home/jupyter/subreddit_clustering_i18n/data/local_cache/mlflow/mlruns/20/559a8f13264245b3923ab5699ef55bfe/artifacts/df_vect_subreddits_description\"\n",
      "100%|###########################################| 5/5 [00:00<00:00, 5998.72it/s]\n",
      "11:20:58 | INFO | \"  Parquet files found:     2\"\n",
      "11:20:58 | INFO | \"  Parquet files to use:     2\"\n",
      "11:20:58 | INFO | \"      49,705 | 514 <- Raw vectorized subreddit description shape\"\n",
      "11:20:58 | INFO | \"  Unique check for subreddit description...\"\n",
      "11:20:58 | INFO | \"Loading POSTS embeddings...\"\n",
      "11:21:00 | INFO | \"Local folder to download artifact(s):\n",
      "  /home/jupyter/subreddit_clustering_i18n/data/local_cache/mlflow/mlruns/20/559a8f13264245b3923ab5699ef55bfe/artifacts/df_vect_posts\"\n",
      "100%|########################################| 40/40 [00:00<00:00, 28055.55it/s]\n",
      "11:21:00 | INFO | \"  Parquet files found:    40\"\n",
      "11:21:00 | INFO | \"  Parquet files to use:    40\"\n",
      "11:22:18 | INFO | \"  Getting df_v_posts.shape ...\"\n",
      "11:22:18 | INFO | \"  15,629,958 |  515 <- Raw POSTS shape\"\n",
      "11:22:18 | INFO | \"  Checking that posts are unique...\"\n",
      "11:22:32 | INFO | \"Loading COMMENTS embeddings...\"\n",
      "11:22:32 | INFO | \"  Found 4 run UUIDs with COMMENT embeddings...\"\n",
      "11:22:34 | INFO | \"Local folder to download artifact(s):\n",
      "  /home/jupyter/subreddit_clustering_i18n/data/local_cache/mlflow/mlruns/20/26c8fcf422a9403ba4a844c8e380bf7f/artifacts/df_vect_comments\"\n",
      "100%|########################################| 20/20 [00:00<00:00, 17165.15it/s]\n",
      "11:22:34 | INFO | \"  Parquet files found:    19\"\n",
      "11:22:34 | INFO | \"  Parquet files to use:    19\"\n",
      "11:23:39 | INFO | \"Local folder to download artifact(s):\n",
      "  /home/jupyter/subreddit_clustering_i18n/data/local_cache/mlflow/mlruns/20/54ba724869bf4ec9a2cad2a4f7eca048/artifacts/df_vect_comments\"\n",
      "100%|########################################| 20/20 [00:00<00:00, 17719.92it/s]\n",
      "11:23:39 | INFO | \"  Parquet files found:    19\"\n",
      "11:23:39 | INFO | \"  Parquet files to use:    19\"\n",
      "11:24:47 | INFO | \"Local folder to download artifact(s):\n",
      "  /home/jupyter/subreddit_clustering_i18n/data/local_cache/mlflow/mlruns/20/e7ed11ccdc0b45abbdf3bf19605d4498/artifacts/df_vect_comments\"\n",
      "100%|########################################| 20/20 [00:00<00:00, 29736.29it/s]\n",
      "11:24:48 | INFO | \"  Parquet files found:    19\"\n",
      "11:24:48 | INFO | \"  Parquet files to use:    19\"\n",
      "11:25:55 | INFO | \"Local folder to download artifact(s):\n",
      "  /home/jupyter/subreddit_clustering_i18n/data/local_cache/mlflow/mlruns/20/a69d1b259875458283124ffdaa6efbb6/artifacts/df_vect_comments\"\n",
      "100%|########################################| 17/17 [00:00<00:00, 17697.49it/s]\n",
      "11:25:55 | INFO | \"  Parquet files found:    16\"\n",
      "11:25:55 | INFO | \"  Parquet files to use:    16\"\n",
      "11:27:49 | INFO | \"  54,407,324 |  516 <- Raw COMMENTS shape\"\n",
      "11:27:49 | INFO | \"  Keep only comments for posts with embeddings\"\n",
      "11:29:54 | INFO | \"  54,407,324 |  516 <- COMMENTS shape, after keeping only comments to loaded posts\"\n",
      "11:31:57 | INFO | \"  0:11:00.327080 <- Total raw embeddings load time elapsed\"\n",
      "11:32:00 | INFO | \"RAM stats:\n",
      "{'memory_used_percent': '13.51%', 'memory_used': '261,675'}\"\n",
      "11:32:00 | INFO | \"-- Start _load_metadata() method --\"\n",
      "11:32:00 | INFO | \"Loading POSTS metadata...\"\n",
      "11:32:00 | INFO | \"Reading raw data...\"\n",
      "11:32:00 | INFO | \"  Local folder to download artifact(s):\n",
      "  /home/jupyter/subreddit_clustering_i18n/data/local_cache/posts/top/2021-12-14_fix\"\n",
      "100%|##############################| 39/39 [00:00<00:00, 32715.57it/s]\n",
      "11:32:29 | INFO | \"  Applying transformations...\"\n",
      "11:32:40 | ERROR | \"Error creating manual topic... 'combined_topic_and_rating'\"\n",
      "11:33:37 | INFO | \"  (15629958, 13) <- Raw META POSTS shape\"\n",
      "11:33:37 | INFO | \"Loading subs metadata...\"\n",
      "11:33:37 | INFO | \"  reading sub-level data & merging with aggregates...\"\n",
      "11:33:37 | INFO | \"Reading raw data...\"\n",
      "11:33:37 | INFO | \"  Local folder to download artifact(s):\n",
      "  /home/jupyter/subreddit_clustering_i18n/data/local_cache/subreddits/top/2021-12-14\"\n",
      "100%|#################################| 1/1 [00:00<00:00, 4922.89it/s]\n",
      "11:33:37 | INFO | \"  Applying transformations...\"\n",
      "11:33:37 | ERROR | \"Error creating manual topic... 'combined_topic_and_rating'\"\n",
      "11:34:14 | INFO | \"  (49705, 125) <- Raw META subreddit description shape\"\n",
      "11:34:14 | INFO | \"Loading COMMENTS metadata...\"\n",
      "11:34:14 | INFO | \"Reading raw data...\"\n",
      "11:34:14 | INFO | \"  Local folder to download artifact(s):\n",
      "  /home/jupyter/subreddit_clustering_i18n/data/local_cache/comments/top/2021-12-14\"\n",
      "100%|##############################| 73/73 [00:00<00:00, 38679.16it/s]\n",
      "11:34:57 | INFO | \"  (54407324, 8) <- Raw META COMMENTS shape\"\n",
      "11:34:57 | INFO | \"  0:02:57.360821 <- Total metadata loading time elapsed\"\n",
      "11:35:01 | INFO | \"RAM stats:\n",
      "{'memory_used_percent': '14.06%', 'memory_used': '272,290'}\"\n",
      "11:35:01 | INFO | \"4 <- Removing comments shorter than 4 characters.\"\n",
      "11:36:38 | INFO | \"  (54407324, 516) <- df_v_comments.shape AFTER removing short comments\"\n",
      "11:36:38 | INFO | \"-- Start _agg_comments_to_post_level() method --\"\n",
      "11:36:38 | INFO | \"No column to weight comments, simple mean for comments at post level\"\n",
      "11:46:17 | INFO | \"  (11155334, 515) <- df_v_com_agg shape after aggregation\"\n",
      "11:46:17 | WARNING | \"  TODO(djb): DELETE df_v_com (raw) to free up memory...\"\n",
      "11:46:17 | INFO | \"  0:09:38.155272 <- Total comments to post agg loading time elapsed\"\n",
      "11:46:20 | INFO | \"RAM stats:\n",
      "{'memory_used_percent': '15.20%', 'memory_used': '294,551'}\"\n",
      "11:46:20 | INFO | \"SKIPPING: B = Calculating aggregation for POSTS + COMMENTS\"\n",
      "11:46:20 | INFO | \"-- Start (df_posts_agg_c) _agg_posts_comments_and_sub_descriptions_to_post_level() method --\"\n",
      "11:46:20 | INFO | \"Getting count of comments per post...\"\n",
      "11:48:50 | INFO | \"  11,155,334 <- Posts that need weighted average\"\n",
      "11:48:50 | INFO | \"Create df with weights for weighted-average calculation\"\n",
      "11:50:43 | INFO | \"Get weighted average for POST + COMMENT + SUBREDDIT-META\"\n",
      " 98%|###########################3| 15240890/15629958 [5:08:17<07:55, 817.76it/s]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "try:\n",
    "    job_agg1._send_log_file_to_mlflow()\n",
    "    mlflow.end_run(\"FAILED\")\n",
    "    # run setup_logging() to remove logging to the file of a failed job\n",
    "    setup_logging()\n",
    "    \n",
    "    del job_agg1\n",
    "    del d_dfs1\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "gc.collect()\n",
    "mlflow.end_run(\"FAILED\")\n",
    "\n",
    "\n",
    "try:\n",
    "    job_agg1 = aggregate_embeddings_pd.AggregateEmbeddings(\n",
    "        run_name=f\"agg_full_lc_false_pd-{datetime.utcnow().strftime('%Y-%m-%d_%H%M%S')}\",\n",
    "        **config_full_lc_false.config_flat\n",
    "    )\n",
    "    job_agg1.run_aggregation()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    job_agg1._send_log_file_to_mlflow()\n",
    "    mlflow.end_run(\"FAILED\")\n",
    "    # run setup_logging() to remove logging to the file of a failed job\n",
    "    setup_logging()\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f456c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_agg1._send_log_file_to_mlflow()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665ca563",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7cc6f3",
   "metadata": {},
   "source": [
    "# Run full data, `lower_case=True`\n",
    "\n",
    "Looks like the problem I ran into with the file being corrupted might've been a problem with downloading the file(s). Fix: delete the local cache and download the files again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01dc7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BREAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f763178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# mlflow.end_run(\"FAILED\")\n",
    "# gc.collect()\n",
    "# try:\n",
    "#     # run setup_logging() to remove logging to the file of a failed job\n",
    "#     setup_logging()\n",
    "    \n",
    "#     del job_agg2\n",
    "#     del d_dfs2\n",
    "# except NameError:\n",
    "#     pass\n",
    "# gc.collect()\n",
    "\n",
    "# job_agg2 = AggregateEmbeddings(\n",
    "#     run_name=f\"full_lc_true-{datetime.utcnow().strftime('%Y-%m-%d_%H%M%S')}\",\n",
    "#     **config_full_lc_true.config_flat\n",
    "# )\n",
    "# job_agg2.run_aggregation()\n",
    "\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bcf60156",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run(\"FAILED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e10acff",
   "metadata": {},
   "source": [
    "# Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53eaa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BREAK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15504ae",
   "metadata": {},
   "source": [
    "### Check computed dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add7521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "150 * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63af14f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k_, v_ in {k_: v_ for k_, v_ in vars(job_agg1).items() if 'df_' in k_}.items():\n",
    "    print(f\"\\n{k_}\")\n",
    "    try:\n",
    "        print(f\"  {v_.shape}\")\n",
    "        display(v_.iloc[:8, :10])\n",
    "        if not ('meta' in k_):\n",
    "            print(v_.info())\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c75004b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0a38ea16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_agg_test._save_and_log_aggregate_and_similarity_dfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f90abaaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2794"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.end_run(\"FAILED\")\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m65"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
