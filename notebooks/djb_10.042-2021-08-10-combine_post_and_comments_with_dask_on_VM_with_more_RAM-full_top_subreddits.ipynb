{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99c1f89f",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "2021-08-10: Finally completed testing with sampling <= 10 files. Now ready to run process on full data!\n",
    "\n",
    "Ended up doing it all in dask + pandas + numpy because of problems installing `cuDF`.\n",
    "\n",
    "---\n",
    "2021-08-02: Now that I'm processing millions of comments and posts, I need to re-write the functions to try to do some work in parallel and reduce the amount of data loaded in RAM.\n",
    "\n",
    "- `Dask` seems like a great option to load data and only compute some of it as needed.\n",
    "- `cuDF` could be a way to speed up some computation using GPUs\n",
    "- `Dask-delayed` could be a way to create a task DAG lazily before computing all the aggregates.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "In notebook 09 I combined embeddings from posts & subreddits (`djb_09.00-combine_post_and_comments_and_visualize_for_presentation.ipynb`).\n",
    "\n",
    "In this notebook I'll be testing functions that include mlflow so that it's easier to try a lot of different weights to find better respresentations.\n",
    "\n",
    "Take embeddings created by other models & combine them:\n",
    "```\n",
    "new post embeddings = post + comments + subreddit description\n",
    "\n",
    "new subreddit embeddings = new posts (weighted by post length or upvotes?)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905bbff5",
   "metadata": {},
   "source": [
    "# Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f710c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b415be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\t\tv 3.7.10\n",
      "===\n",
      "dask\t\tv: 2021.06.0\n",
      "hydra\t\tv: 1.1.0\n",
      "mlflow\t\tv: 1.16.0\n",
      "numpy\t\tv: 1.19.5\n",
      "pandas\t\tv: 1.2.4\n",
      "plotly\t\tv: 4.14.3\n",
      "seaborn\t\tv: 0.11.1\n",
      "subclu\t\tv: 0.3.2\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import gc\n",
    "import os\n",
    "import logging\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "import dask\n",
    "from dask import dataframe as dd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import mlflow\n",
    "import hydra\n",
    "\n",
    "import subclu\n",
    "from subclu.models.aggregate_embeddings import (\n",
    "    AggregateEmbeddings, AggregateEmbeddingsConfig,\n",
    "    load_config_agg_jupyter, get_dask_df_shape,\n",
    ")\n",
    "\n",
    "from subclu.utils import set_working_directory\n",
    "from subclu.utils.eda import (\n",
    "    setup_logging, counts_describe, value_counts_and_pcts,\n",
    "    notebook_display_config, print_lib_versions,\n",
    "    style_df_numeric\n",
    ")\n",
    "from subclu.utils.mlflow_logger import MlflowLogger, save_pd_df_to_parquet_in_chunks\n",
    "from subclu.eda.aggregates import (\n",
    "    compare_raw_v_weighted_language\n",
    ")\n",
    "from subclu.utils.data_irl_style import (\n",
    "    get_colormap, theme_dirl\n",
    ")\n",
    "\n",
    "\n",
    "print_lib_versions([dask, hydra, mlflow, np, pd, plotly, sns, subclu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7636735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.dates as mdates\n",
    "plt.style.use('default')\n",
    "\n",
    "setup_logging()\n",
    "notebook_display_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f663e3",
   "metadata": {},
   "source": [
    "# Set sqlite database as MLflow URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3521bb79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sqlite:////home/jupyter/subreddit_clustering_i18n/mlflow_sync/djb-100-2021-04-28-djb-eda-german-subs/mlruns.db'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use new class to initialize mlflow\n",
    "mlf = MlflowLogger(tracking_uri='sqlite')\n",
    "mlflow.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a7f604",
   "metadata": {},
   "source": [
    "## Get list of experiments with new function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c03339f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>name</th>\n",
       "      <th>artifact_location</th>\n",
       "      <th>lifecycle_stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Default</td>\n",
       "      <td>./mlruns/0</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>fse_v1</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/1</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>fse_vectorize_v1</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/2</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>subreddit_description_v1</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/3</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>fse_vectorize_v1.1</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/4</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>use_multilingual_v0.1_test</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/5</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>use_multilingual_v1</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/6</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>use_multilingual_v1_aggregates_test</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/7</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>use_multilingual_v1_aggregates</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/8</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>v0.3.2_use_multi_inference_test</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/9</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>v0.3.2_use_multi_inference</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/10</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>v0.3.2_use_multi_aggregates_test</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/11</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>v0.3.2_use_multi_aggregates</td>\n",
       "      <td>gs://i18n-subreddit-clustering/mlflow/mlruns/12</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   experiment_id                                 name                                artifact_location lifecycle_stage\n",
       "0              0                              Default                                       ./mlruns/0          active\n",
       "1              1                               fse_v1   gs://i18n-subreddit-clustering/mlflow/mlruns/1          active\n",
       "2              2                     fse_vectorize_v1   gs://i18n-subreddit-clustering/mlflow/mlruns/2          active\n",
       "3              3             subreddit_description_v1   gs://i18n-subreddit-clustering/mlflow/mlruns/3          active\n",
       "4              4                   fse_vectorize_v1.1   gs://i18n-subreddit-clustering/mlflow/mlruns/4          active\n",
       "5              5           use_multilingual_v0.1_test   gs://i18n-subreddit-clustering/mlflow/mlruns/5          active\n",
       "6              6                  use_multilingual_v1   gs://i18n-subreddit-clustering/mlflow/mlruns/6          active\n",
       "7              7  use_multilingual_v1_aggregates_test   gs://i18n-subreddit-clustering/mlflow/mlruns/7          active\n",
       "8              8       use_multilingual_v1_aggregates   gs://i18n-subreddit-clustering/mlflow/mlruns/8          active\n",
       "9              9      v0.3.2_use_multi_inference_test   gs://i18n-subreddit-clustering/mlflow/mlruns/9          active\n",
       "10            10           v0.3.2_use_multi_inference  gs://i18n-subreddit-clustering/mlflow/mlruns/10          active\n",
       "11            11     v0.3.2_use_multi_aggregates_test  gs://i18n-subreddit-clustering/mlflow/mlruns/11          active\n",
       "12            12          v0.3.2_use_multi_aggregates  gs://i18n-subreddit-clustering/mlflow/mlruns/12          active"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlf.list_experiment_meta(output_format='pandas')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb92bda5",
   "metadata": {},
   "source": [
    "## Get runs that we can use for embeddings aggregation jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e76e9c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 254 ms, sys: 12.5 ms, total: 266 ms\n",
      "Wall time: 266 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(110, 101)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_mlf_runs =  mlf.search_all_runs(experiment_ids=[9, '10', 11, 12])\n",
    "df_mlf_runs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10fcfa45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 101)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_finished = df_mlf_runs['status'] == 'FINISHED'\n",
    "mask_output_over_1M_rows = (\n",
    "    (df_mlf_runs['metrics.df_vect_posts_rows'] >= 1e6) |\n",
    "    (df_mlf_runs['metrics.df_vect_comments'] >= 1e6)\n",
    ")\n",
    "# df_mlf_runs[mask_finished].shape\n",
    "\n",
    "df_mlf_use_for_agg = df_mlf_runs[mask_output_over_1M_rows]\n",
    "df_mlf_use_for_agg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "196273eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_bc821_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >run id</th>        <th class=\"col_heading level0 col1\" >experiment id</th>        <th class=\"col_heading level0 col2\" >status</th>        <th class=\"col_heading level0 col3\" >start time</th>        <th class=\"col_heading level0 col4\" >metrics.df vect subreddits description rows</th>        <th class=\"col_heading level0 col5\" >metrics.vectorizing time minutes posts</th>        <th class=\"col_heading level0 col6\" >metrics.total comment files processed</th>        <th class=\"col_heading level0 col7\" >metrics.vectorizing time minutes subreddit meta</th>        <th class=\"col_heading level0 col8\" >metrics.df vect comments</th>        <th class=\"col_heading level0 col9\" >metrics.df vect subreddits description cols</th>        <th class=\"col_heading level0 col10\" >metrics.vectorizing time minutes comments</th>        <th class=\"col_heading level0 col11\" >metrics.vectorizing time minutes full function</th>        <th class=\"col_heading level0 col12\" >metrics.df vect posts rows</th>        <th class=\"col_heading level0 col13\" >metrics.df vect posts cols</th>        <th class=\"col_heading level0 col14\" >params.tf batch inference rows</th>        <th class=\"col_heading level0 col15\" >params.tokenize lowercase</th>        <th class=\"col_heading level0 col16\" >params.tf limit first n chars</th>        <th class=\"col_heading level0 col17\" >params.batch comment files</th>        <th class=\"col_heading level0 col18\" >params.posts path</th>        <th class=\"col_heading level0 col19\" >params.subreddits path</th>        <th class=\"col_heading level0 col20\" >tags.mlflow.source.git.commit</th>        <th class=\"col_heading level0 col21\" >tags.mlflow.runName</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_bc821_level0_row0\" class=\"row_heading level0 row0\" >87</th>\n",
       "                        <td id=\"T_bc821_row0_col0\" class=\"data row0 col0\" >a948e9fd651545f997430cddc6b529eb</td>\n",
       "                        <td id=\"T_bc821_row0_col1\" class=\"data row0 col1\" >10</td>\n",
       "                        <td id=\"T_bc821_row0_col2\" class=\"data row0 col2\" >FINISHED</td>\n",
       "                        <td id=\"T_bc821_row0_col3\" class=\"data row0 col3\" >2021-07-29 23:02:33.997000+00:00</td>\n",
       "                        <td id=\"T_bc821_row0_col4\" class=\"data row0 col4\" >3,767.00</td>\n",
       "                        <td id=\"T_bc821_row0_col5\" class=\"data row0 col5\" >14.74</td>\n",
       "                        <td id=\"T_bc821_row0_col6\" class=\"data row0 col6\" >37.00</td>\n",
       "                        <td id=\"T_bc821_row0_col7\" class=\"data row0 col7\" >0.08</td>\n",
       "                        <td id=\"T_bc821_row0_col8\" class=\"data row0 col8\" >19,168,154.00</td>\n",
       "                        <td id=\"T_bc821_row0_col9\" class=\"data row0 col9\" >514.00</td>\n",
       "                        <td id=\"T_bc821_row0_col10\" class=\"data row0 col10\" >145.73</td>\n",
       "                        <td id=\"T_bc821_row0_col11\" class=\"data row0 col11\" >176.77</td>\n",
       "                        <td id=\"T_bc821_row0_col12\" class=\"data row0 col12\" >1,649,929.00</td>\n",
       "                        <td id=\"T_bc821_row0_col13\" class=\"data row0 col13\" >515.00</td>\n",
       "                        <td id=\"T_bc821_row0_col14\" class=\"data row0 col14\" >2000</td>\n",
       "                        <td id=\"T_bc821_row0_col15\" class=\"data row0 col15\" >True</td>\n",
       "                        <td id=\"T_bc821_row0_col16\" class=\"data row0 col16\" >1000</td>\n",
       "                        <td id=\"T_bc821_row0_col17\" class=\"data row0 col17\" >True</td>\n",
       "                        <td id=\"T_bc821_row0_col18\" class=\"data row0 col18\" >posts/top/2021-07-16</td>\n",
       "                        <td id=\"T_bc821_row0_col19\" class=\"data row0 col19\" >subreddits/top/2021-07-16</td>\n",
       "                        <td id=\"T_bc821_row0_col20\" class=\"data row0 col20\" >63f5f420fb6b48d8243749cba183071757dac531</td>\n",
       "                        <td id=\"T_bc821_row0_col21\" class=\"data row0 col21\" >new_batch_fxn-2021-07-29_230233</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_bc821_level0_row1\" class=\"row_heading level0 row1\" >89</th>\n",
       "                        <td id=\"T_bc821_row1_col0\" class=\"data row1 col0\" >e66c5db26bd64f6da09c012eea700d0a</td>\n",
       "                        <td id=\"T_bc821_row1_col1\" class=\"data row1 col1\" >10</td>\n",
       "                        <td id=\"T_bc821_row1_col2\" class=\"data row1 col2\" >FINISHED</td>\n",
       "                        <td id=\"T_bc821_row1_col3\" class=\"data row1 col3\" >2021-07-29 18:59:48.715000+00:00</td>\n",
       "                        <td id=\"T_bc821_row1_col4\" class=\"data row1 col4\" >-</td>\n",
       "                        <td id=\"T_bc821_row1_col5\" class=\"data row1 col5\" >-</td>\n",
       "                        <td id=\"T_bc821_row1_col6\" class=\"data row1 col6\" >37.00</td>\n",
       "                        <td id=\"T_bc821_row1_col7\" class=\"data row1 col7\" >-</td>\n",
       "                        <td id=\"T_bc821_row1_col8\" class=\"data row1 col8\" >19,200,854.00</td>\n",
       "                        <td id=\"T_bc821_row1_col9\" class=\"data row1 col9\" >-</td>\n",
       "                        <td id=\"T_bc821_row1_col10\" class=\"data row1 col10\" >117.47</td>\n",
       "                        <td id=\"T_bc821_row1_col11\" class=\"data row1 col11\" >133.16</td>\n",
       "                        <td id=\"T_bc821_row1_col12\" class=\"data row1 col12\" >-</td>\n",
       "                        <td id=\"T_bc821_row1_col13\" class=\"data row1 col13\" >-</td>\n",
       "                        <td id=\"T_bc821_row1_col14\" class=\"data row1 col14\" >6100</td>\n",
       "                        <td id=\"T_bc821_row1_col15\" class=\"data row1 col15\" >False</td>\n",
       "                        <td id=\"T_bc821_row1_col16\" class=\"data row1 col16\" >850</td>\n",
       "                        <td id=\"T_bc821_row1_col17\" class=\"data row1 col17\" >True</td>\n",
       "                        <td id=\"T_bc821_row1_col18\" class=\"data row1 col18\" >None</td>\n",
       "                        <td id=\"T_bc821_row1_col19\" class=\"data row1 col19\" >None</td>\n",
       "                        <td id=\"T_bc821_row1_col20\" class=\"data row1 col20\" >64f49e85a8ef56a6795edf9da9a6f5964cb6830b</td>\n",
       "                        <td id=\"T_bc821_row1_col21\" class=\"data row1 col21\" >new_batch_fxn_2021-07-29_185948</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_bc821_level0_row2\" class=\"row_heading level0 row2\" >98</th>\n",
       "                        <td id=\"T_bc821_row2_col0\" class=\"data row2 col0\" >614a38e6690c4f3ba08725b1585b2ee9</td>\n",
       "                        <td id=\"T_bc821_row2_col1\" class=\"data row2 col1\" >9</td>\n",
       "                        <td id=\"T_bc821_row2_col2\" class=\"data row2 col2\" >KILLED</td>\n",
       "                        <td id=\"T_bc821_row2_col3\" class=\"data row2 col3\" >2021-07-29 11:49:53.924000+00:00</td>\n",
       "                        <td id=\"T_bc821_row2_col4\" class=\"data row2 col4\" >3,767.00</td>\n",
       "                        <td id=\"T_bc821_row2_col5\" class=\"data row2 col5\" >10.01</td>\n",
       "                        <td id=\"T_bc821_row2_col6\" class=\"data row2 col6\" >-</td>\n",
       "                        <td id=\"T_bc821_row2_col7\" class=\"data row2 col7\" >0.07</td>\n",
       "                        <td id=\"T_bc821_row2_col8\" class=\"data row2 col8\" >-</td>\n",
       "                        <td id=\"T_bc821_row2_col9\" class=\"data row2 col9\" >514.00</td>\n",
       "                        <td id=\"T_bc821_row2_col10\" class=\"data row2 col10\" >-</td>\n",
       "                        <td id=\"T_bc821_row2_col11\" class=\"data row2 col11\" >-</td>\n",
       "                        <td id=\"T_bc821_row2_col12\" class=\"data row2 col12\" >1,649,929.00</td>\n",
       "                        <td id=\"T_bc821_row2_col13\" class=\"data row2 col13\" >515.00</td>\n",
       "                        <td id=\"T_bc821_row2_col14\" class=\"data row2 col14\" >2100</td>\n",
       "                        <td id=\"T_bc821_row2_col15\" class=\"data row2 col15\" >False</td>\n",
       "                        <td id=\"T_bc821_row2_col16\" class=\"data row2 col16\" >1000</td>\n",
       "                        <td id=\"T_bc821_row2_col17\" class=\"data row2 col17\" >None</td>\n",
       "                        <td id=\"T_bc821_row2_col18\" class=\"data row2 col18\" >posts/top/2021-07-16</td>\n",
       "                        <td id=\"T_bc821_row2_col19\" class=\"data row2 col19\" >subreddits/top/2021-07-16</td>\n",
       "                        <td id=\"T_bc821_row2_col20\" class=\"data row2 col20\" >64f49e85a8ef56a6795edf9da9a6f5964cb6830b</td>\n",
       "                        <td id=\"T_bc821_row2_col21\" class=\"data row2 col21\" >test_new_fxn2021-07-29_114953</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f4e23919110>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_with_multiple_vals = df_mlf_use_for_agg.columns[df_mlf_use_for_agg.nunique(dropna=False) > 1]\n",
    "# len(cols_with_multiple_vals)\n",
    "\n",
    "style_df_numeric(\n",
    "    df_mlf_use_for_agg\n",
    "    [cols_with_multiple_vals]\n",
    "    .drop(['artifact_uri', 'end_time',\n",
    "           # 'start_time',\n",
    "           ], \n",
    "          axis=1)\n",
    "    .dropna(axis='columns', how='all')\n",
    "    .iloc[:, :30]\n",
    "    ,\n",
    "    rename_cols_for_display=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124c2ce4",
   "metadata": {},
   "source": [
    "# Load configs for aggregation jobs\n",
    "\n",
    "`n_sample_comments_files` and `n_sample_posts_files` allow us to only load a few files at a time (e.g., 2 instead of 50) to test the process end-to-end.\n",
    "\n",
    "---\n",
    "Note that by default `hydra` is a cli tool. If we want to call use it in jupyter, we need to manually initialize configs & compose the configuration. See my custom function `load_config_agg_jupyter`. Also see:\n",
    "- [Notebook with `Hydra` examples in a notebook](https://github.com/facebookresearch/hydra/blob/master/examples/jupyter_notebooks/compose_configs_in_notebook.ipynb).\n",
    "- [Hydra docs, Hydra in Jupyter](https://hydra.cc/docs/next/advanced/jupyter_notebooks/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63529f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_experiment_test = 'v0.3.2_use_multi_aggregates_test'\n",
    "mlflow_experiment_full = 'v0.3.2_use_multi_aggregates'\n",
    "\n",
    "config_test_sample_lc_false = AggregateEmbeddingsConfig(\n",
    "    config_path=\"../config\",\n",
    "    config_name='aggregate_embeddings',\n",
    "    overrides=[f\"mlflow_experiment={mlflow_experiment_test}\",\n",
    "               'n_sample_posts_files=5',     # 51 total\n",
    "               'n_sample_comments_files=10',  # 34 total\n",
    "               'data_embeddings_to_aggregate=top_subs-2021_07_16-use_multi_lower_case_false',\n",
    "              ]\n",
    ")\n",
    "config_test_full_lc_false = AggregateEmbeddingsConfig(\n",
    "    config_path=\"../config\",\n",
    "    config_name='aggregate_embeddings',\n",
    "    overrides=[f\"mlflow_experiment={mlflow_experiment_test}\",\n",
    "               'n_sample_posts_files=null', \n",
    "               'n_sample_comments_files=null',\n",
    "               'data_embeddings_to_aggregate=top_subs-2021_07_16-use_multi_lower_case_false',\n",
    "              ]\n",
    ")\n",
    "\n",
    "config_full_lc_false = AggregateEmbeddingsConfig(\n",
    "    config_path=\"../config\",\n",
    "    config_name='aggregate_embeddings',\n",
    "    overrides=[f\"mlflow_experiment={mlflow_experiment_full}\",\n",
    "               'n_sample_posts_files=null', \n",
    "               'n_sample_comments_files=null',\n",
    "               'data_embeddings_to_aggregate=top_subs-2021_07_16-use_multi_lower_case_false',\n",
    "              ]\n",
    ")\n",
    "\n",
    "config_full_lc_true = AggregateEmbeddingsConfig(\n",
    "    config_path=\"../config\",\n",
    "    config_name='aggregate_embeddings',\n",
    "    overrides=[f\"mlflow_experiment={mlflow_experiment_full}\",\n",
    "               'n_sample_posts_files=null', \n",
    "               'n_sample_comments_files=null',\n",
    "               'data_embeddings_to_aggregate=top_subs-2021_07_16-use_multi_lower_case_true',\n",
    "              ]\n",
    ")\n",
    "# pprint(config_test_sample_lc_false.config_dict, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e45645a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments_uuid</th>\n",
       "      <th>posts_uuid</th>\n",
       "      <th>subreddit_desc_uuid</th>\n",
       "      <th>mlflow_experiment</th>\n",
       "      <th>n_sample_posts_files</th>\n",
       "      <th>n_sample_comments_files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e66c5db26bd64f6da09c012eea700d0a</td>\n",
       "      <td>614a38e6690c4f3ba08725b1585b2ee9</td>\n",
       "      <td>614a38e6690c4f3ba08725b1585b2ee9</td>\n",
       "      <td>v0.3.2_use_multi_aggregates_test</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e66c5db26bd64f6da09c012eea700d0a</td>\n",
       "      <td>614a38e6690c4f3ba08725b1585b2ee9</td>\n",
       "      <td>614a38e6690c4f3ba08725b1585b2ee9</td>\n",
       "      <td>v0.3.2_use_multi_aggregates_test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e66c5db26bd64f6da09c012eea700d0a</td>\n",
       "      <td>614a38e6690c4f3ba08725b1585b2ee9</td>\n",
       "      <td>614a38e6690c4f3ba08725b1585b2ee9</td>\n",
       "      <td>v0.3.2_use_multi_aggregates</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a948e9fd651545f997430cddc6b529eb</td>\n",
       "      <td>a948e9fd651545f997430cddc6b529eb</td>\n",
       "      <td>a948e9fd651545f997430cddc6b529eb</td>\n",
       "      <td>v0.3.2_use_multi_aggregates</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      comments_uuid                        posts_uuid               subreddit_desc_uuid                 mlflow_experiment  n_sample_posts_files  n_sample_comments_files\n",
       "0  e66c5db26bd64f6da09c012eea700d0a  614a38e6690c4f3ba08725b1585b2ee9  614a38e6690c4f3ba08725b1585b2ee9  v0.3.2_use_multi_aggregates_test                   5.0                     10.0\n",
       "1  e66c5db26bd64f6da09c012eea700d0a  614a38e6690c4f3ba08725b1585b2ee9  614a38e6690c4f3ba08725b1585b2ee9  v0.3.2_use_multi_aggregates_test                   NaN                      NaN\n",
       "2  e66c5db26bd64f6da09c012eea700d0a  614a38e6690c4f3ba08725b1585b2ee9  614a38e6690c4f3ba08725b1585b2ee9       v0.3.2_use_multi_aggregates                   NaN                      NaN\n",
       "3  a948e9fd651545f997430cddc6b529eb  a948e9fd651545f997430cddc6b529eb  a948e9fd651545f997430cddc6b529eb       v0.3.2_use_multi_aggregates                   NaN                      NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_configs = pd.DataFrame(\n",
    "    [config_test_sample_lc_false.config_flat,\n",
    "     config_test_full_lc_false.config_flat,\n",
    "     config_full_lc_false.config_flat,\n",
    "     config_full_lc_true.config_flat,\n",
    "    ]\n",
    ")\n",
    "cols_with_diffs_config = df_configs.columns[df_configs.nunique(dropna=False) > 1]\n",
    "df_configs[cols_with_diffs_config]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ce9dfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'agg_comments_to_post_weight_col': None,\n",
      "  'agg_post_comment_weight': 20,\n",
      "  'agg_post_post_weight': 70,\n",
      "  'agg_post_subreddit_desc_weight': 10,\n",
      "  'agg_post_to_subreddit_weight_col': None,\n",
      "  'bucket_name': 'i18n-subreddit-clustering',\n",
      "  'col_comment_id': 'comment_id',\n",
      "  'col_post_id': 'post_id',\n",
      "  'col_subreddit_id': 'subreddit_id',\n",
      "  'col_text_comment_word_count': 'comment_text_word_count',\n",
      "  'col_text_post_word_count': 'text_word_count',\n",
      "  'comments_folder_embeddings': 'df_vect_comments',\n",
      "  'comments_uuid': 'e66c5db26bd64f6da09c012eea700d0a',\n",
      "  'dataset_name': 'Top Subreddits (no Geo) + German Subs 2021-07-16, comments: '\n",
      "                  '2021-07-09',\n",
      "  'folder_comments_text_and_meta': 'comments/top/2021-07-09',\n",
      "  'folder_posts_text_and_meta': 'posts/top/2021-07-16',\n",
      "  'folder_subreddits_text_and_meta': 'subreddits/top/2021-07-16',\n",
      "  'min_comment_text_len': 10,\n",
      "  'mlflow_experiment': 'v0.3.2_use_multi_aggregates_test',\n",
      "  'mlflow_tracking_uri': 'sqlite',\n",
      "  'n_sample_comments_files': 10,\n",
      "  'n_sample_posts_files': 5,\n",
      "  'posts_folder_embeddings': 'df_vect_posts',\n",
      "  'posts_uuid': '614a38e6690c4f3ba08725b1585b2ee9',\n",
      "  'subreddit_desc_folder_embeddings': 'df_vect_subreddits_description',\n",
      "  'subreddit_desc_uuid': '614a38e6690c4f3ba08725b1585b2ee9'}\n"
     ]
    }
   ],
   "source": [
    "pprint(config_test_sample_lc_false.config_flat, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd460b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "BREAK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85048c1c",
   "metadata": {},
   "source": [
    "# Initialize a local dask client\n",
    "so that we can see the progress/process for dask jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8b81a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 345 ms, sys: 173 ms, total: 517 ms\n",
      "Wall time: 1.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "# dask default: 8 workers with 64 CPUs present, 16 -> runs out of RAM per worker...\n",
    "cluster = LocalCluster(n_workers=8)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c005b017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://127.0.0.1:8787/status'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.dashboard_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cfd405",
   "metadata": {},
   "source": [
    "# Run Full data with `lower_case=False`\n",
    "\n",
    "The logic for sampling files and download/`caching` files locally lives in the `mlf` custom function.\n",
    "\n",
    "Caching can save 9+ minutes if we try to download the files from GCS every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a57b6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BREAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93064423",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:02:28 | INFO | \"== Start run_aggregation() method ==\"\n",
      "07:02:28 | INFO | \"MLflow tracking URI: sqlite:////home/jupyter/subreddit_clustering_i18n/mlflow_sync/djb-100-2021-04-28-djb-eda-german-subs/mlruns.db\"\n",
      "07:02:29 | INFO | \"  Local model saving directory: /home/jupyter/subreddit_clustering_i18n/data/models/aggregate_embeddings/2021-08-10_070229-full_lc_false-2021-08-10_070228\"\n",
      "07:02:29 | INFO | \"  Saving config to local path...\"\n",
      "07:02:29 | INFO | \"  Logging config to mlflow...\"\n",
      "07:02:29 | INFO | \"-- Start _load_raw_embeddings() method --\"\n",
      "07:02:29 | INFO | \"Loading subreddit description embeddings...\"\n",
      "07:02:30 | INFO | \"Local folder to download artifact(s):\n",
      "  /home/jupyter/subreddit_clustering_i18n/data/local_cache/mlflow/mlruns/9/614a38e6690c4f3ba08725b1585b2ee9/artifacts/df_vect_subreddits_description\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec89d35884b4a948403369d47dd204e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:02:30 | INFO | \"  Reading 1 files\"\n",
      "07:02:31 | INFO | \"       3,767 |  513 <- Raw vectorized subreddit description shape\"\n",
      "07:02:32 | INFO | \"Loading POSTS embeddings...\"\n",
      "07:02:33 | INFO | \"Local folder to download artifact(s):\n",
      "  /home/jupyter/subreddit_clustering_i18n/data/local_cache/mlflow/mlruns/9/614a38e6690c4f3ba08725b1585b2ee9/artifacts/df_vect_posts\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00edc32ef06146a5a7afab3b751c1fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:02:33 | INFO | \"  Reading 48 files\"\n",
      "07:02:35 | INFO | \"   1,649,929 |  514 <- Raw POSTS shape\"\n",
      "07:02:38 | INFO | \"Loading COMMENTS embeddings...\"\n",
      "07:02:39 | INFO | \"Local folder to download artifact(s):\n",
      "  /home/jupyter/subreddit_clustering_i18n/data/local_cache/mlflow/mlruns/10/e66c5db26bd64f6da09c012eea700d0a/artifacts/df_vect_comments\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac6e520ec9f4c33b27750bb1048816e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:02:39 | INFO | \"  Reading 37 files\"\n",
      "07:02:39 | INFO | \"  0:00:09.844584 <- Total raw embeddings load time elapsed\"\n",
      "07:02:39 | INFO | \"-- Start _agg_comments_to_post_level() method --\"\n",
      "07:02:40 | INFO | \"Getting count of comments per post...\"\n",
      "07:02:55 | WARNING | \"Error creating summary of comments per post.\n",
      "'<=' not supported between instances of 'NoneType' and 'int'\"\n",
      "07:02:55 | INFO | \"Filtering which comments need to be averaged...\"\n",
      "07:04:23 | INFO | \"      128,716 <- Comments that DON'T need to be averaged\"\n",
      "07:04:24 | INFO | \"   19,072,138 <- Comments that need to be averaged\"\n",
      "07:04:24 | INFO | \"No column to weight comments, simple mean for comments at post level\"\n",
      "07:06:14 | INFO | \"      985,894 |  514 <- df_v_com_agg SHAPE\"\n",
      "07:06:14 | INFO | \"  0:03:34.315443 <- Total comments to post agg loading time elapsed\"\n",
      "07:06:14 | INFO | \"-- Start (df_posts_agg_b) _agg_posts_and_comments_to_post_level() method --\"\n",
      "07:06:15 | INFO | \"DEFINE agg_posts_w_comments...\"\n",
      "07:06:16 | INFO | \"  (Delayed('int-e8e786da-22e6-4893-a586-2b056bcc6e58'), 513) <- df_agg_posts_w_comments.shape (only posts with comments)\"\n",
      "07:06:16 | INFO | \"Concat aggregated comments+posts with posts-without comments\"\n",
      "07:35:35 | INFO | \"    1,656,122 |  514 <- df_posts_agg_c shape after aggregation\"\n",
      "07:35:35 | INFO | \"  0:20:20.180715 <- Total (df_posts_agg_c) posts+comments+subs agg time elapsed\"\n",
      "07:35:35 | INFO | \"-- Start _agg_post_aggregates_to_subreddit_level() method --\"\n",
      "07:35:35 | INFO | \"No column to weight comments, simple mean to roll up posts to subreddit-level...\"\n",
      "07:35:35 | INFO | \"A - posts only\"\n",
      "07:35:35 | INFO | \"  (Delayed('int-469b0268-ba05-4e8d-b605-4d2bebfad899'), 513) <- df_subs_agg_a.shape (only posts)\"\n",
      "07:35:35 | INFO | \"B - posts + comments\"\n",
      "07:35:35 | INFO | \"  (Delayed('int-19f9a462-ed52-4058-a47b-5ca04846b710'), 513) <- df_subs_agg_b.shape (posts + comments)\"\n",
      "07:35:35 | INFO | \"C - posts + comments + sub descriptions\"\n",
      "07:35:36 | INFO | \"  (Delayed('int-6b352dc6-bd2a-4db2-9c27-d02ab6ad52fa'), 513) <- df_subs_agg_c.shape (posts + comments + sub description)\"\n",
      "07:35:36 | INFO | \"  0:00:01.213991 <- Total for ALL subreddit-level agg time elapsed\"\n",
      "07:35:36 | INFO | \"-- Start _calculate_subreddit_similarities() method --\"\n",
      "07:35:36 | INFO | \"A...\"\n",
      "07:35:46 | INFO | \"  (3767, 3767) <- df_subs_agg_a_similarity.shape\"\n",
      "07:36:01 | INFO | \"Create new df to keep only top 20 subs by distance...\"\n",
      "07:36:06 | INFO | \"  (14186522, 3) <- df_dist_pair_meta.shape (before setting index)\"\n",
      "07:36:06 | INFO | \"  (75340, 3) <- df_dist_pair_meta_top_only.shape (before setting index)\"\n",
      "07:36:06 | INFO | \"B...\"\n",
      "07:54:24 | INFO | \"  (3849, 3849) <- df_subs_agg_b_similarity.shape\"\n",
      "07:54:40 | INFO | \"Create new df to keep only top 20 subs by distance...\"\n",
      "07:54:45 | INFO | \"  (14810952, 3) <- df_dist_pair_meta.shape (before setting index)\"\n",
      "07:54:45 | INFO | \"  (76980, 3) <- df_dist_pair_meta_top_only.shape (before setting index)\"\n",
      "07:54:46 | INFO | \"C...\"\n",
      "08:36:25 | INFO | \"  (3767, 3767) <- df_subs_agg_c_similarity.shape\"\n",
      "08:36:40 | INFO | \"Create new df to keep only top 20 subs by distance...\"\n",
      "08:36:45 | INFO | \"  (14186522, 3) <- df_dist_pair_meta.shape (before setting index)\"\n",
      "08:36:45 | INFO | \"  (75340, 3) <- df_dist_pair_meta_top_only.shape (before setting index)\"\n",
      "08:36:46 | INFO | \"  1:01:09.967860 <- Total for _calculate_subreddit_similarities() time elapsed\"\n",
      "08:36:46 | INFO | \"-- Start _save_and_log_aggregate_and_similarity_dfs() method --\"\n",
      "08:36:46 | INFO | \"  Saving config to local path...\"\n",
      "08:36:46 | INFO | \"  Logging config to mlflow...\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d847b25b399e40e78c75be7047f60acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:36:46 | INFO | \"** df_post_level_agg_b_post_and_comments **\"\n",
      "08:36:46 | INFO | \"Saving locally...\"\n",
      "08:54:18 | INFO | \"Logging artifact to mlflow...\"\n",
      "08:55:34 | INFO | \"** df_post_level_agg_c_post_comments_sub_desc **\"\n",
      "08:55:34 | INFO | \"Saving locally...\"\n",
      "09:16:16 | INFO | \"     268\t<- EXISTING Dask partitions\"\n",
      "09:38:02 | INFO | \"Logging artifact to mlflow...\"\n",
      "09:39:58 | INFO | \"** df_sub_level_agg_a_post_only **\"\n",
      "09:39:58 | INFO | \"Saving locally...\"\n",
      "09:40:04 | INFO | \"       1\t<- EXISTING Dask partitions\"\n",
      "09:40:12 | INFO | \"Logging artifact to mlflow...\"\n",
      "09:40:13 | INFO | \"** df_sub_level_agg_a_post_only_similarity **\"\n",
      "09:40:13 | INFO | \"Saving locally...\"\n",
      "09:40:13 | INFO | \"Keeping index intact...\"\n",
      "09:40:13 | INFO | \"Converting pandas to dask...\"\n",
      "09:40:13 | INFO | \"   108.6 MB <- Memory usage\"\n",
      "09:40:13 | INFO | \"       3\t<- target Dask partitions\t   40.0 <- target MB partition size\"\n",
      "09:40:16 | INFO | \"Logging artifact to mlflow...\"\n",
      "09:40:18 | INFO | \"** df_sub_level_agg_a_post_only_similarity_pair **\"\n",
      "09:40:18 | INFO | \"Saving locally...\"\n",
      "09:40:19 | INFO | \"Converting pandas to dask...\"\n",
      "09:40:21 | INFO | \"  2,022.0 MB <- Memory usage\"\n",
      "09:40:21 | INFO | \"      34\t<- target Dask partitions\t   60.0 <- target MB partition size\"\n",
      "09:40:25 | INFO | \"Logging artifact to mlflow...\"\n",
      "09:40:36 | INFO | \"** df_sub_level_agg_b_post_and_comments **\"\n",
      "09:40:36 | INFO | \"Saving locally...\"\n",
      "09:49:38 | INFO | \"       1\t<- EXISTING Dask partitions\"\n",
      "09:59:01 | INFO | \"Logging artifact to mlflow...\"\n",
      "09:59:02 | INFO | \"** df_sub_level_agg_b_post_and_comments_similarity **\"\n",
      "09:59:02 | INFO | \"Saving locally...\"\n",
      "09:59:02 | INFO | \"Keeping index intact...\"\n",
      "09:59:02 | INFO | \"Converting pandas to dask...\"\n",
      "09:59:02 | INFO | \"   113.4 MB <- Memory usage\"\n",
      "09:59:02 | INFO | \"       3\t<- target Dask partitions\t   40.0 <- target MB partition size\"\n",
      "09:59:05 | INFO | \"Logging artifact to mlflow...\"\n",
      "09:59:08 | INFO | \"** df_sub_level_agg_b_post_and_comments_similarity_pair **\"\n",
      "09:59:08 | INFO | \"Saving locally...\"\n",
      "09:59:08 | INFO | \"Converting pandas to dask...\"\n",
      "09:59:11 | INFO | \"  2,111.9 MB <- Memory usage\"\n",
      "09:59:11 | INFO | \"      36\t<- target Dask partitions\t   60.0 <- target MB partition size\"\n",
      "09:59:15 | INFO | \"Logging artifact to mlflow...\"\n",
      "09:59:28 | INFO | \"** df_sub_level_agg_c_post_comments_and_sub_desc **\"\n",
      "09:59:28 | INFO | \"Saving locally...\"\n",
      "10:19:26 | INFO | \"       1\t<- EXISTING Dask partitions\"\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mlflow.end_run(\"FAILED\")\n",
    "gc.collect()\n",
    "try:\n",
    "    del job_agg1\n",
    "    del d_dfs1\n",
    "except NameError:\n",
    "    pass\n",
    "gc.collect()\n",
    "\n",
    "job_agg1 = AggregateEmbeddings(\n",
    "    run_name=f\"full_lc_false-{datetime.utcnow().strftime('%Y-%m-%d_%H%M%S')}\",\n",
    "    **config_full_lc_false.config_flat\n",
    ")\n",
    "job_agg1.run_aggregation()\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f27d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "mlflow.end_run(\"FAILED\")\n",
    "gc.collect()\n",
    "try:\n",
    "    del job_agg2\n",
    "    del d_dfs2\n",
    "except NameError:\n",
    "    pass\n",
    "gc.collect()\n",
    "\n",
    "job_agg2 = AggregateEmbeddings(\n",
    "    run_name=f\"full_lc_true-{datetime.utcnow().strftime('%Y-%m-%d_%H%M%S')}\",\n",
    "    **config_full_lc_true.config_flat\n",
    ")\n",
    "job_agg2.run_aggregation()\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a51c7e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run(\"FAILED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9372ea86",
   "metadata": {},
   "source": [
    "## Check output dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16760960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "340c156770a84dcd96499193283b3075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "df_v_sub\n",
      "(Delayed('int-d9fa5280-15a7-4cb5-b1d7-29e87e661c24'), 513) <- df shape\n",
      "1 <- dask partitions\n",
      "\n",
      "df_v_posts\n",
      "(Delayed('int-16cc4711-5229-4556-b28a-df08e562ad30'), 514) <- df shape\n",
      "5 <- dask partitions\n",
      "\n",
      "df_v_comments\n",
      "(Delayed('int-64852139-ad50-4e52-a77b-aeb6d5b6155d'), 515) <- df shape\n",
      "10 <- dask partitions\n",
      "\n",
      "df_subs_agg_a\n",
      "(Delayed('int-0267d822-1516-4476-a40f-6c6f0796d8dc'), 513) <- df shape\n",
      "1 <- dask partitions\n",
      "\n",
      "df_subs_agg_b\n",
      "(Delayed('int-0a0377af-db4d-4ad5-8c9f-e1a3685df967'), 513) <- df shape\n",
      "1 <- dask partitions\n",
      "\n",
      "df_subs_agg_c\n",
      "(Delayed('int-7685a498-cfc8-49e1-b91a-a797d70dbb88'), 513) <- df shape\n",
      "1 <- dask partitions\n",
      "\n",
      "df_posts_agg_b\n",
      "(Delayed('int-0598994f-435b-450c-9565-bc875b98f4dc'), 514) <- df shape\n",
      "21 <- dask partitions\n",
      "\n",
      "df_posts_agg_c\n",
      "(Delayed('int-2ed0f6f0-1efc-48e6-9621-7310bc0b6030'), 514) <- df shape\n",
      "42 <- dask partitions\n",
      "CPU times: user 33.4 ms, sys: 9.03 ms, total: 42.4 ms\n",
      "Wall time: 37.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "d_dfs2 = dict()\n",
    "(\n",
    "    d_dfs2['df_v_sub'], d_dfs2['df_v_posts'], d_dfs2['df_v_comments'],\n",
    "#     d_dfs2['df_subs_meta'], d_dfs2['df_posts_meta'], d_dfs2['df_comments_meta'],\n",
    "    \n",
    "    # Aggs don't get computed until run_aggergation() method gets called\n",
    "    d_dfs2['df_subs_agg_a'], d_dfs2['df_subs_agg_b'], d_dfs2['df_subs_agg_c'], \n",
    "    d_dfs2['df_posts_agg_b'], d_dfs2['df_posts_agg_c'], \n",
    "    # d_dfs2['df_posts_agg_d'],\n",
    "\n",
    ") = (\n",
    "    job_agg2.df_v_sub, job_agg2.df_v_posts, job_agg2.df_v_comments,\n",
    "#     job_agg2.df_subs_meta, job_agg2.df_posts_meta, job_agg2.df_comments_meta,\n",
    "    \n",
    "    job_agg2.df_subs_agg_a, job_agg2.df_subs_agg_b, job_agg2.df_subs_agg_c, \n",
    "    job_agg2.df_posts_agg_b, job_agg2.df_posts_agg_c,\n",
    "    # job_agg2.df_posts_agg_d,  # D doesn't exist yet\n",
    ")\n",
    "\n",
    "for k2, df_2 in tqdm(d_dfs2.items()):\n",
    "    print(f\"\\n{k2}\")\n",
    "    try:\n",
    "        print(f\"{df_2.shape} <- df shape\")\n",
    "        print(f\"{df_2.npartitions} <- dask partitions\")\n",
    "        # print(f\"{get_dask_df_shape(df_2)} <- df.shape\")\n",
    "        # print(f\"  {df_2.memory_usage(deep=True).sum() / 1048576:4,.1f} MB <- Memory usage\")\n",
    "        if any(['meta' in k2, '_v_' in k2]):\n",
    "            pass\n",
    "        else:\n",
    "            pass\n",
    "            # display(df_2.iloc[:5, :15])\n",
    "\n",
    "    except (TypeError, AttributeError):\n",
    "        if isinstance(df_2, pd.DataFrame):\n",
    "            print(f\"{df_2.shape} <- df shape\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
